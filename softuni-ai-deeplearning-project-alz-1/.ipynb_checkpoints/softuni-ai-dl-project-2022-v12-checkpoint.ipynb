{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1644739490161,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "iT9IlWKuPrjJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6859,
     "status": "ok",
     "timestamp": 1644739497012,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "LU2dGmWEjgqG",
    "outputId": "a36f0909-11d2-4d0e-8506-217cc8c71325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (0.15.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: opencv-python in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from opencv-python) (1.21.4)\n",
      "Requirement already satisfied: pyntcloud in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (0.1.6)\n",
      "Requirement already satisfied: scipy in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from pyntcloud) (1.7.3)\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from pyntcloud) (1.3.4)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from pyntcloud) (1.21.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from pandas->pyntcloud) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from pandas->pyntcloud) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->pyntcloud) (1.15.0)\n",
      "Requirement already satisfied: open3d in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (0.14.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from open3d) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from open3d) (1.21.4)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from open3d) (6.0)\n",
      "Requirement already satisfied: pillow>=8.2.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from open3d) (8.4.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from open3d) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from open3d) (58.0.4)\n",
      "Requirement already satisfied: matplotlib>=3 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from open3d) (3.5.0)\n",
      "Requirement already satisfied: pandas>=1.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from open3d) (1.3.4)\n",
      "Requirement already satisfied: addict in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from open3d) (2.4.0)\n",
      "Requirement already satisfied: wheel>=0.36.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from open3d) (0.37.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from matplotlib>=3->open3d) (20.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from matplotlib>=3->open3d) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from matplotlib>=3->open3d) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from matplotlib>=3->open3d) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from matplotlib>=3->open3d) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from matplotlib>=3->open3d) (0.11.0)\n",
      "Requirement already satisfied: six in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from packaging>=20.0->matplotlib>=3->open3d) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from pandas>=1.0->open3d) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from scikit-learn>=0.21->open3d) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from scikit-learn>=0.21->open3d) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from scikit-learn>=0.21->open3d) (1.7.3)\n",
      "Requirement already satisfied: mlflow in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (1.23.1)\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (1.3.4)\n",
      "Requirement already satisfied: gunicorn in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: sqlalchemy in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (1.4.31)\n",
      "Requirement already satisfied: Flask in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (2.0.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (20.4)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (0.4.2)\n",
      "Requirement already satisfied: querystring-parser in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (1.21.4)\n",
      "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (3.15.8)\n",
      "Requirement already satisfied: pytz in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (2021.3)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (4.11.0)\n",
      "Requirement already satisfied: scipy in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (1.7.3)\n",
      "Requirement already satisfied: entrypoints in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: requests>=2.17.3 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (2.26.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (2.0.0)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (0.16.4)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (3.1.26)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (8.0.3)\n",
      "Requirement already satisfied: prometheus-flask-exporter in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (0.18.7)\n",
      "Requirement already satisfied: alembic in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (1.7.6)\n",
      "Requirement already satisfied: docker>=4.0.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from mlflow) (5.0.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from docker>=4.0.0->mlflow) (1.2.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from gitpython>=2.1.0->mlflow) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (5.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (2.0.9)\n",
      "Requirement already satisfied: Mako in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from alembic->mlflow) (1.1.6)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from alembic->mlflow) (5.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from sqlalchemy->mlflow) (1.1.2)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from Flask->mlflow) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from Flask->mlflow) (2.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from Flask->mlflow) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from Jinja2>=3.0->Flask->mlflow) (2.0.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from gunicorn->mlflow) (58.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from packaging->mlflow) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from pandas->mlflow) (2.8.1)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/anaconda3/envs/tfenv/lib/python3.8/site-packages (from prometheus-flask-exporter->mlflow) (0.8.0)\n"
     ]
    }
   ],
   "source": [
    "### Some necesary installs:\n",
    "\n",
    "!pip install tensorflow_addons\n",
    "\n",
    "### Point cloud installs:\n",
    "\n",
    "!pip install opencv-python\n",
    "\n",
    "!pip install pyntcloud\n",
    "\n",
    "!pip install open3d\n",
    "\n",
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1644740583120,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "au-TJsR5PrjL"
   },
   "outputs": [],
   "source": [
    "### Usual imports:\n",
    "import pandas as pd\n",
    "import sympy\n",
    "import math\n",
    "import cmath\n",
    "import numpy as np\n",
    "import numpy.polynomial.polynomial as p\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import skimage.io\n",
    "import time\n",
    "import unittest\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1644740757680,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "R-T36e52jKlI"
   },
   "outputs": [],
   "source": [
    "### Deep Learning imports:\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "### Other imports:\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from distutils.dir_util import copy_tree, remove_tree\n",
    "\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef as MCC\n",
    "from sklearn.metrics import balanced_accuracy_score as BAS\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
    "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.metrics import *\n",
    "\n",
    "import keras\n",
    "from keras import models, layers, regularizers, metrics, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Point cloud imports:\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1644739503005,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "1uvtgEaZMYFk",
    "outputId": "dfa4d0b1-a35f-4f15-a241-baa323445d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "### Verifying versions:\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1644739572077,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "HkRQOAXfMYFy"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1644739573964,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "mMDVS9kdbmFM",
    "outputId": "31628d62-6b58-4fd7-fd9d-187a2bb0fb51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18474,
     "status": "ok",
     "timestamp": 1644739521468,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "kd-l1v2WeUe9",
    "outputId": "b16fe5a0-215b-4d8b-bae2-d15286dd4182"
   },
   "outputs": [],
   "source": [
    "### Setting up Google Drive to work with Google Colab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1644739522223,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "aj2dOYokeWyD",
    "outputId": "fa4e7964-94b7-4976-f80c-841ad25e0bb9"
   },
   "outputs": [],
   "source": [
    "# %cd /content/gdrive/MyDrive/Colab-Notebooks/softuni-ai-deeplearning-project-alz-1/\n",
    "# %ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aComvLFmPrjM"
   },
   "source": [
    "# Alzheimer's Disease Classification using Deep Learning\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDnI8gX3PrjN"
   },
   "source": [
    "![header-image](https://storage.googleapis.com/kaggle-datasets-images/457093/861496/0e1367b46c9e96bdf3823ec7833b965d/dataset-cover.jpg)\n",
    "\n",
    "<div style=\"text-align: center\">Image referenced below.</div>\n",
    "\n",
    "[[Reference]](#Alzheimer's-Dataset-(-4-class-of-Images)---Header-image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJIuF8w-PrjO"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtqCiH5JPrjO"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "***Author:*** Atanas Kuzmanov\n",
    "\n",
    "***Date:*** 2022-February-20\n",
    "\n",
    "*This is an article developed as a scientific notebook for an exam project assignment for a Deep Learning course from an Artificial Intelligence module.*\n",
    "\n",
    "*One of the aims of this article is to understand and demonstrate some Deep Learning (DL) basics, more specifically to understand Neural Networks (NNs) and how to improve them, so we can create models, train them, test them and extract predictions, classifications and information we might be interested in.*\n",
    "\n",
    "_We will demonstrate some of the following basic but key concepts of Deep Learning:_\n",
    "\n",
    "- _Convolutional Neural Network_\n",
    "\n",
    "\n",
    "- _Building a Neural Network architecture_\n",
    "\n",
    "\n",
    "- _Compiling a model with optimizers and loss functions_\n",
    "\n",
    "\n",
    "- _Training a model_\n",
    "\n",
    "\n",
    "- _Evaluating a model_\n",
    "\n",
    "\n",
    "- _Improving a model with Transfer Learning_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1_kToStLowjokojIQ7pY2ynQ.jpeg](./resources/images/1_kToStLowjokojIQ7pY2ynQ.jpeg)\n",
    "\n",
    "_Image source:_ https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n",
    "\n",
    "[[Reference]](#A-Comprehensive-Guide-to-Convolutional-Neural-Networks-—-the-ELI5-way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fM43thEPrjP"
   },
   "source": [
    "_Deep Learning has a phenomenal range of application in the health sciences._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fM43thEPrjP"
   },
   "source": [
    "_This notebook implements a neural network model to predict the status (non-demented, moderate demented, very mild demented, mild demented) associated to the brain captured in MRI images._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![brain1.jpg](./resources/images/brain1.jpeg)\n",
    "\n",
    "_Schematics of a healthy brain (left) and an Alzheimer affected brain (right)._\n",
    "\n",
    "Image source: https://en.wikipedia.org/wiki/Alzheimer%27s_disease#/media/File:Alzheimer's_disease_brain_comparison.jpg\n",
    "\n",
    "[[Reference]](#Alzheimer's-disease---Wikipedia)\n",
    "\n",
    "![mri-scan.jpg](./resources/images/mri-scan.jpeg)\n",
    "\n",
    "An MRI device.\n",
    "\n",
    "Image source: https://www.medicalnewstoday.com/articles/146309\n",
    "\n",
    "[[Reference]](#What-to-know-about-MRI-scans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKYmmexiPrjO"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fA_YM_0VPrjP"
   },
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fM43thEPrjP"
   },
   "source": [
    "_This notebook implements a neural network model to predict the status (non-demented, moderate demented, very mild demented, mild demented) associated to the brain captured in MRI images._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WK3xLtmPPrja"
   },
   "source": [
    "_One of my main ideas about this article is to use some ground work from other articles, to set up a standard base for an Alzhemier's Dataset, and after that try to expand and build on top of this with my innovative ideas._\n",
    "\n",
    "_Some of my innovative ideas include:_\n",
    "\n",
    "- _Instead of the standard way of loading an image data set with a generator and then passing the generator to a model's `fit()` function directly, I want to load the images and actually build a `Tensorflow` data set. The reasoning behind this is - what if you have a model, whose layers cannot or should not be changed for one reason or another. For example, this way you would not be able to add augmentation layers to the model, so if you need to do `image augmentations`, or any other data `pre-processing` for that matter, you would need to do them beforehand, applied on the dataset itself. You can do image augmentations in the generators, however there could be something else which I cannot think of on the spot, which might require pre-processing on the dataset._\n",
    "\n",
    "\n",
    "- _Turn the medical 2D images in 3D images, for example using `point clouds` and then using the new 3D images to train the model. A 3D view of a disease in the brain such as Alzheimer's Disease might give additional insights to the model which it has been previously missing._\n",
    "\n",
    "\n",
    "- _Again using 2D image to 3D image conversion to get `depth estimation` images of a disease in the brain such as Alzheimer's Disease, and then use the new images to train the model. This might give additional insights to the model which it has been previously missing._\n",
    "\n",
    "\n",
    "- _Once you have the 3D images build a new model using a `3D Convolutional Neural Network`._\n",
    "\n",
    "\n",
    "- _Once all the previous ideas are implemented, the next one is to build a pipeline which can consist of several Neural Networks, `2D CNNs` and `3D CNNs`, and others, and have an `ensemble of Neural Networks`, which can be trained on different medical topics, such as Alzheimer's disease, lung diseases, retina diseases, and then be used to generalize and classify diseases._ _This last idea is inspired from this paper - MULTI-DISEASE DETECTION IN RETINAL IMAGING BASED ON ENSEMBLING HETEROGENEOUS DEEP LEARNING MODELS [[Reference]](#MULTI-DISEASE-DETECTION-IN-RETINAL-IMAGING-PDF)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ7Ftu9uPrjP"
   },
   "source": [
    "*This article is an exploration and extension inspired by the following articles:*\n",
    "\n",
    "**Main inspiration articles:**\n",
    "\n",
    "- mri_image_classification_using_transfer_learning [[Reference]](#mri_image_classification_using_transfer_learning)\n",
    "\n",
    "- Alzheimer's-Disease-Classification---InceptionV3 [[Reference]](#Alzheimer's-Disease-Classification---InceptionV3)\n",
    "\n",
    "- Alzheimer-MRI-Model-+-TensorFlow-2.3-Data-Loading [[Reference]](#Alzheimer-MRI-Model-+-TensorFlow-2.3-Data-Loading)\n",
    "\n",
    "- TensorFlow-Pneumonia-Classification-on-X-rays [[Reference]](#TensorFlow-Pneumonia-Classification-on-X-rays)\n",
    "\n",
    "- CNN-Alzheimer-MRI-images [[Reference]](#CNN-Alzheimer-MRI-images)\n",
    "\n",
    "**Data:**\n",
    "\n",
    "- Alzheimer's-Dataset-(-4-class-of-Images) [[Reference]](#Alzheimer's-Dataset-(-4-class-of-Images))\n",
    "\n",
    "**Other inspiration articles:**\n",
    "\n",
    "- The-Alzheimer's-Disease-Prediction-Of-Longitudinal-Evolution-(TADPOLE)-Challenge:-Results-after-1-Year-Follow-up [[Reference]](#The-Alzheimer's-Disease-Prediction-Of-Longitudinal-Evolution-(TADPOLE)-Challenge:-Results-after-1-Year-Follow-up---arxiv.org)\n",
    "\n",
    "- Preclinical-Stage-Alzheimer’s-Disease-Detection-Using-MRI-Scans [[Reference]](#Preclinical-Stage-Alzheimer’s-Disease-Detection-Using-MRI-Scans)\n",
    "\n",
    "- OASIS-Brains-project [[Reference]](#OASIS-Brains-project)\n",
    "\n",
    "- Deep-Learning-in-Alzheimer's-disease:-Diagnostic-Classification-and-Prognostic-Prediction-using-Neuroimaging-Data [[Reference]](#Deep-Learning-in-Alzheimer's-disease:-Diagnostic-Classification-and-Prognostic-Prediction-using-Neuroimaging-Data)\n",
    "\n",
    "- Automatic-Assessment-of-Alzheimer's-Disease-Diagnosis-Based-on-Deep-Learning-Techniques [[Reference]](#Automatic-Assessment-of-Alzheimer's-Disease-Diagnosis-Based-on-Deep-Learning-Techniques)\n",
    "\n",
    "- An-explainable-two-dimensional-single-model-deep-learning-approach-for-Alzheimer's-disease-diagnosis-and-brain-atrophy-localization [[References]](#An-explainable-two-dimensional-single-model-deep-learning-approach-for-Alzheimer's-disease-diagnosis-and-brain-atrophy-localization)\n",
    "\n",
    "- Convolutional-Neural-Networks-for-Classification-of-Alzheimer's-Disease:-Overview-and-Reproducible-Evaluation [[References]](#Convolutional-Neural-Networks-for-Classification-of-Alzheimer's-Disease:-Overview-and-Reproducible-Evaluation)\n",
    "\n",
    "- Improving-3D-convolutional-neural-network-comprehensibility-via-interactive-visualization-of-relevance-maps:-Evaluation-in-Alzheimer's-disease [[Reference]](#Improving-3D-convolutional-neural-network-comprehensibility-via-interactive-visualization-of-relevance-maps:-Evaluation-in-Alzheimer's-disease)\n",
    "\n",
    "- Diagnosis-of-Alzheimer's-Disease-via-Multi-modality-3D-Convolutional-Neural-Network [[Reference]](#Diagnosis-of-Alzheimer's-Disease-via-Multi-modality-3D-Convolutional-Neural-Network)\n",
    "\n",
    "- Detection-of-Alzheimers-Disease-from-MRI-using-Convolutional-Neural-Networks,-Exploring-Transfer-Learning-And-BellCNN [[Reference]](#Detection-of-Alzheimers-Disease-from-MRI-using-Convolutional-Neural-Networks,-Exploring-Transfer-Learning-And-BellCNN)\n",
    "\n",
    "- Detecting-Alzheimer's-Disease-Using-Gated-Convolutional-Neural-Network-from-Audio-Data [[Reference]](#Detecting-Alzheimer's-Disease-Using-Gated-Convolutional-Neural-Network-from-Audio-Data)\n",
    "\n",
    "- Deep-Convolutional-Neural-Network-based-Classification-of-Alzheimer's-Disease-using-MRI-data [[Reference]](#Deep-Convolutional-Neural-Network-based-Classification-of-Alzheimer's-Disease-using-MRI-data)\n",
    "\n",
    "\n",
    "**Another huge inspiration has been the following paper:**\n",
    "\n",
    "MULTI-DISEASE DETECTION IN RETINAL IMAGING\n",
    "\n",
    "BASED ON ENSEMBLING HETEROGENEOUS DEEP LEARNING MODELS\n",
    "\n",
    "*Dominik Müller1, Iñaki Soto-Rey1,2 and Frank Kramer1*\n",
    "\n",
    "1 IT-Infrastructure for Translational Medical Research, University of\n",
    "Augsburg, Germany\n",
    "\n",
    "2 Medical Data Integration Center, University Hospital Augsburg, Germany\n",
    "\n",
    "Published: `[v1] Fri, 26 Mar 2021 18:02:17 UTC (757 KB)`\n",
    "\n",
    "`References:`\n",
    "\n",
    "\n",
    "Paper:\n",
    "\n",
    "- MULTI-DISEASE DETECTION IN RETINAL IMAGING BASED ON ENSEMBLING HETEROGENEOUS DEEP LEARNING MODELS\n",
    "[[Reference]](#MULTI-DISEASE-DETECTION-IN-RETINAL-IMAGING-PDF)\n",
    "\n",
    "- Multi-Disease Detection in Retinal Imaging - papers with code\n",
    "[[Reference]](#Multi-Disease-Detection-in-Retinal-Imaging---papers-with-code)\n",
    "\n",
    "Code:\n",
    "\n",
    "- Multi-Disease Detection in Retinal Imaging - GitHub\n",
    "[[Reference]](#Multi-Disease-Detection-in-Retinal-Imaging---GitHub)\n",
    "\n",
    "- AUCMEDI - A Framework for Automated Classification of Medical Images\n",
    "[[Reference]](#AUCMEDI---A-Framework-for-Automated-Classification-of-Medical-Images)\n",
    "\n",
    "Data:\n",
    "\n",
    "- RETINAL FUNDUS MULTI-DISEASE IMAGE DATASET (RFMID)\n",
    "[[Reference]](#RETINAL-FUNDUS-MULTI-DISEASE-IMAGE-DATASET-(RFMID))\n",
    "\n",
    "- RFMiD Train Dataset - kaggle\n",
    "[[Reference]](#RFMiD-Train-Dataset---kaggle)\n",
    "\n",
    "Other:\n",
    "\n",
    "- Retinal Image Analysis for multi-Disease Detection Challenge website\n",
    "[[Reference]](#Retinal-Image-Analysis-for-multi-Disease-Detection-Challenge-website)\n",
    "\n",
    "- IEEE ISBI 2021 International Symposium on Biomedical Imaging April 13-16 2021\n",
    "[[Reference]](#IEEE-ISBI-2021-International-Symposium-on-Biomedical-Imaging-April-13-16-2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Yr5HCZWPrjP"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Running this Notebook\n",
    "\n",
    "_This is a Jupyter Notebook developed and meant to be run in `Google Colab` [[Reference]](#Google-Colab)._\n",
    "\n",
    "_It is quite feature packed and it might take a bit longer to load, depending on the machine on which you are running it on. Please allow sufficient time for all of it to run all the way, until the last LaTeX formula, Markdown, Python, graphs, plots, images, etc. have loaded and executed. This also valid if you use `Kernel -> Restart & Run All`, however in this case this is not meant to be used for this notebook, as some of the cells are Deep Learning model experiments which run for hours, and also running them again will lose some of the results from the experiments._\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Tensorflow 2.7.0\n",
    "- Keras 2.7.0\n",
    "\n",
    "### Google Drive\n",
    "\n",
    "_Because this notebook is developed as a scientific notebook for an exam project assignment for a Deep Learning course from an Artificial Intelligence module, in order to be assessed you will need to access and download the contents of this shared `Google Drive` folder in order to be able to run it:_\n",
    "\n",
    "___Note: The contents of this folder are around 3GB.___\n",
    "\n",
    "[Google Drive Project Shared folder - softuni-ai-deeplearning-project-alz-1](https://drive.google.com/drive/folders/1XkOpL7N6T2WtDKNacesf77o-m9Aw4AUs?usp=sharing)\n",
    "\n",
    "https://drive.google.com/drive/folders/1XkOpL7N6T2WtDKNacesf77o-m9Aw4AUs?usp=sharing\n",
    "\n",
    "_The contents should look like this or similar:_\n",
    "\n",
    "```\n",
    "data/                                       --> Original dataset\n",
    "dataset/                                    --> Modified dataset for relevant function in notebook\n",
    "dataset copy/                               --> Copy of modified dataset for relevant function in notebook\n",
    "dataset-4-aug/                              --> Copy of modified dataset for relevant function in notebook\n",
    "dataset-4-aug-all/                          --> Copy of modified dataset for relevant function in notebook\n",
    "dataset-split/                              --> Copy of modified dataset for relevant function in notebook\n",
    ".ipynb_checkpoints/                         --> MacOS folder for Jupyter Notebook checkpoints for this notebook\n",
    "models/                                     --> Saved models and model related files\n",
    "pointcloud-experiment-notebooks/            --> Other draft work notebooks used for this notebook\n",
    "resources/                                  --> Images and other resources\n",
    "screenshots/                                --> Screenshots\n",
    "softuni-ai-dl-project-2022-notebooks-bkps/  --> Backup copies of previous versions of this notebook\n",
    "softuni-ai-dl-project-2022-Final-Version.ipynb --> The final version of this project notebook\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "_My experience in trying to develop, debug, train, fit, test etc. models in Google Colab has been not good and less than efficient. I do not mean to say that Google Colab is not good or efficient, it might as well be me doing something wrong or using it in the wrong way._\n",
    "\n",
    "_As a result I have not had sufficient computing power at my disposal for proper hyperparameters._\n",
    "\n",
    "_If I did, I could have used a good `batch number` and calculations such as the ones below to get good numbers for how many `steps` should we perform for training and validation per each of our `epochs` according to the `batches` of our dataset would have been suitable to get good or even state of the art results._\n",
    "\n",
    "_As proof of this, please refer to the `screenshots/` directory, mentioned in the previous section and check out my pains, struggles and frustrations with running anything in Google Colab._\n",
    "\n",
    "_Things to look out for in the screenshots:_\n",
    "\n",
    "\n",
    "- _Check out the computer clock and see what time it is in between screenshots (the screenshots are also automatically timestamped) of executing one cell and se **how ridiculously long** it takes for it to execute. And I mean this for normal cells which either process a batch from the dataset or try to train a model, not some cell which is executing something obscure which ends up in an infinite loop or crashes Google Colab._\n",
    "\n",
    "\n",
    "- _Check out how often Google Colab has crashed on me for no particular reason._\n",
    "\n",
    "\n",
    "- _Check out how often the Google Colab session has been taken away from me, before I could save my model or before it has reached a checkpoint so it would save itself._\n",
    "\n",
    "- _Check out how often the Google Colab has become unresponsive for long periods of times, sometimes hours, until I have had to manually interrupt my session, lose everything in my session as a result and have to start over._\n",
    "\n",
    "- _The GPU allocation would be removed as a capability after about an hour worth of working in Google Colab._\n",
    "\n",
    "\n",
    "- _... etc._\n",
    "\n",
    "\n",
    "_Because of the above, I have lost more than half of my time for this project in struggling with Google Colab issues, rather than actually working and developing the project._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Yr5HCZWPrjP"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3RwxqLQPrjQ"
   },
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abd4996a"
   },
   "source": [
    "### Foreword\n",
    "\n",
    "_One of the aims of this article is to understand some Deep Learning (DL) basics, basic concepts and intuitions._\n",
    "\n",
    "_Because of that goal it is important to be able to train and test models multiple times, so we can determine the best hyperparameters and tune models to improve them. Unfortunately at the time of writing this article, in the year 2022, I am using my personal laptop from 2015. I thought this machine has fared rather well for it's age, and have great respect for it and what I have put it through, as we have been together through thick and thin. That was until I had to actually do DL on it for this article when I realized it is not going to fare well for this purpose. Most of the models were unable to run or finish running once I tried to train them, or once I tried to change the hyperparameters to improve them. My machine would just heat up with fans running at the highest rpms and still seem stuck on executing a cell for more than 30min. If I had carried on like this I would not have been able to finish this article, so instead most or all of the hyperparameters for the models are set to severely low or high, depending on the context, in order to reduce iterations or features of the data, so that this notebook would work and I would be able to demonstrate or give an example of the idea I am trying to explain. Please keep this in mind when going through the article._\n",
    "\n",
    "_This will be sufficient for the purpose of this article, just to demonstrate and help understand DL basics, basic concepts and intuitions, but if you need to try out some of the examples and extend and improve them for actual Deep Learning keep in mind you need a powerful machine with a good GPU, or you can use a cloud platform suitable for DL, such as Google Colab._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fed2f6a"
   },
   "source": [
    "### References Notes\n",
    "\n",
    "_Any and all references, citations, resources or other materials used to understand and explain, provide examples, and build this article have been referenced in order to give credit where credit is due and avoid plagiarism._\n",
    "_If a citation is the bigger part of a section, and has been edited, added to, modified, etc. the reference to that section would be at the end of it, separated with a horizontal line, like this example:_\n",
    "\n",
    "> ---\n",
    "> [[Example Reference]](#ExampleReference)\n",
    "\n",
    "_If a citation has been inserted and is relatively short, the relevant reference will be at the end of the sentence or paragraph, for example:_\n",
    "\n",
    "> Example. [[Example Reference]](#ExampleReference)\n",
    "\n",
    "_In case a reference is missed due to human error, all references can be found in the [References](#References) section. Anything which is found in the [References](#References) should be considered as a valid reference for everything in this paper, even if not explicitly referenced._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48827ba5"
   },
   "source": [
    "### Narrative\n",
    "\n",
    "_I have tried to provide a nice flow, ease of read and a friendly and humorous tone of the article, and at the same time clear and understandable communication. In order to aid this I have provided a narrative to this article. In order to distinguish it I have used italics for it throughout the article. Please consider any text in italics, such as the one you are currently reading, as narrative. It can also be both in bold and italics._\n",
    "\n",
    "> _Example narrative._\n",
    "\n",
    "### Code\n",
    "\n",
    "_Currently most of the code in the article has been refactored into separate functions and most of the other code in the article is left fragmented throughout. There is a very good reason for this, which is that one of the aims of this article is to also understand a bit of Deep Learning. This is why the fragments of code throughout this article are used to help us and illustrate and demonstrate different parts of ML as a whole._\n",
    "\n",
    "_Some of the code quality has been improved by making some functions idempotent with special checks, so that they have the same effect, no matter how many times they are ran._\n",
    "\n",
    "_Most of the commented out code in this article is left on purpose to serve as information, as part of the intent for this article is for it to be a knowledgebase._\n",
    "\n",
    "### Table of Contents (TOC)\n",
    "\n",
    "_Please refer to the [Table of Contents](#Table-of-Contents) section in [Appendix A](#Appendix-A) for instructions on how you can use get a Table of Contents for this article in Jupyter Notebook._\n",
    "\n",
    "### Testing\n",
    "\n",
    "#### Project tests\n",
    "\n",
    "- _Any mathematics in the project for which I have had doubts or have not understood I have tested using Wolfram Alpha._\n",
    "\n",
    "- _I have repeatedly ran \"Kernel -> Restart & Run All\" to confirm all is working and have fixed bugs when things have been broken._\n",
    "\n",
    "#### Code tests\n",
    "\n",
    "- _There are code test, however the focus of this notebook is not on code tests. Due to the nature of this notebook, being focused on ML, most of the tests of this note book are actually metrics, scoring, score analysis, model testing and cross-validation._\n",
    "\n",
    "- _There are tests in the project. Since code tests are outside of the focus of this project most of the tests are visual print outs of the data and visual confirmations._\n",
    "\n",
    "- _Most of the tests in this project are visual and are marked with this \"`### Test`\" comment above it._\n",
    "\n",
    "- _There are also tests which are more functional and for example print a message if an assertion error is not thrown._\n",
    "\n",
    "_I consider this amount of test coverage adequate for the purpose of this article._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtWaiAcgPrjR"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vElrEnYhPrjR"
   },
   "source": [
    "### Hypothesis<a id=\"Hypothesis\"></a>\n",
    "\n",
    "#### Null hypothesis $(H_{0})$<a id=\"NullHypothesis\"></a>\n",
    "\n",
    "*The Null hypothesis $(H_{0})$ tells us that the status quo is real, that nothing interesting happens.*\n",
    "\n",
    "*This is the hypothesis we are going to try and disprove, by demonstrating that an Alternative hypothesis $(H_{1})$ is true with experiments.*\n",
    "\n",
    "#### Alternative hypothesis $(H_{1})$<a id=\"AlternativeHypothesis\"></a>\n",
    "\n",
    "*The Alternative hypothesis $(H_{1})$ is what we are trying to demonstrate.*\n",
    "\n",
    "_**For the purpose of this article/notebook we will state the following topic, with it's Null and Alternative hypothesis.**_\n",
    "\n",
    "#### Topic: Alzheimer's Disease Classification using Deep Learning\n",
    "\n",
    "##### Null hypothesis 1 $(H_{0})$<a id=\"NullHypothesis1\"></a>\n",
    "\n",
    "- Null hypothesis 1 $(H_{0})$:\n",
    "\n",
    "    **Deep Learning and Convolutional Neural Networks are not suitable for Alzheimer's disease classification, as they do not achieve a state of the art AUROC of 0.93 or above.**\n",
    "\n",
    "##### Alternative hypothesis 1 $(H_{1})$<a id=\"AlternativeHypothesis1\"></a>\n",
    "\n",
    "- Alternative hypothesis 2 $(H_{1})$:\n",
    "\n",
    "    **Deep Learning and Convolutional Neural Networks are suitable for Alzheimer's disease classification, as they do achieve a state of the art AUROC of 0.93 or above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDBXzl9-PrjT"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LKTaAbePrjT"
   },
   "source": [
    "## Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jbDiHWBPrjT"
   },
   "source": [
    "- The-Alzheimer's-Disease-Prediction-Of-Longitudinal-Evolution-(TADPOLE)-Challenge:-Results-after-1-Year-Follow-up [[Reference]](#The-Alzheimer's-Disease-Prediction-Of-Longitudinal-Evolution-(TADPOLE)-Challenge:-Results-after-1-Year-Follow-up---arxiv.org)\n",
    "\n",
    "- Preclinical-Stage-Alzheimer’s-Disease-Detection-Using-MRI-Scans [[Reference]](#Preclinical-Stage-Alzheimer’s-Disease-Detection-Using-MRI-Scans)\n",
    "\n",
    "- OASIS-Brains-project [[Reference]](#OASIS-Brains-project)\n",
    "\n",
    "- Deep-Learning-in-Alzheimer's-disease:-Diagnostic-Classification-and-Prognostic-Prediction-using-Neuroimaging-Data [[Reference]](#Deep-Learning-in-Alzheimer's-disease:-Diagnostic-Classification-and-Prognostic-Prediction-using-Neuroimaging-Data)\n",
    "\n",
    "- Automatic-Assessment-of-Alzheimer's-Disease-Diagnosis-Based-on-Deep-Learning-Techniques [[Reference]](#Automatic-Assessment-of-Alzheimer's-Disease-Diagnosis-Based-on-Deep-Learning-Techniques)\n",
    "\n",
    "- An-explainable-two-dimensional-single-model-deep-learning-approach-for-Alzheimer's-disease-diagnosis-and-brain-atrophy-localization [[References]](#An-explainable-two-dimensional-single-model-deep-learning-approach-for-Alzheimer's-disease-diagnosis-and-brain-atrophy-localization)\n",
    "\n",
    "- Convolutional-Neural-Networks-for-Classification-of-Alzheimer's-Disease:-Overview-and-Reproducible-Evaluation [[References]](#Convolutional-Neural-Networks-for-Classification-of-Alzheimer's-Disease:-Overview-and-Reproducible-Evaluation)\n",
    "\n",
    "- Improving-3D-convolutional-neural-network-comprehensibility-via-interactive-visualization-of-relevance-maps:-Evaluation-in-Alzheimer's-disease [[Reference]](#Improving-3D-convolutional-neural-network-comprehensibility-via-interactive-visualization-of-relevance-maps:-Evaluation-in-Alzheimer's-disease)\n",
    "\n",
    "- Diagnosis-of-Alzheimer's-Disease-via-Multi-modality-3D-Convolutional-Neural-Network [[Reference]](#Diagnosis-of-Alzheimer's-Disease-via-Multi-modality-3D-Convolutional-Neural-Network)\n",
    "\n",
    "- Detection-of-Alzheimers-Disease-from-MRI-using-Convolutional-Neural-Networks,-Exploring-Transfer-Learning-And-BellCNN [[Reference]](#Detection-of-Alzheimers-Disease-from-MRI-using-Convolutional-Neural-Networks,-Exploring-Transfer-Learning-And-BellCNN)\n",
    "\n",
    "- Detecting-Alzheimer's-Disease-Using-Gated-Convolutional-Neural-Network-from-Audio-Data [[Reference]](#Detecting-Alzheimer's-Disease-Using-Gated-Convolutional-Neural-Network-from-Audio-Data)\n",
    "\n",
    "- Deep-Convolutional-Neural-Network-based-Classification-of-Alzheimer's-Disease-using-MRI-data [[Reference]](#Deep-Convolutional-Neural-Network-based-Classification-of-Alzheimer's-Disease-using-MRI-data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acZES9aSPrjU"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pATWw5nPrjU"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyq_bh_cPrjU"
   },
   "source": [
    "_The data:_\n",
    "\n",
    "_Here is a data set from [[kaggle.com]](#kaggle.com)_\n",
    "\n",
    "- Alzheimer's-Dataset-(-4-class-of-Images) [[Reference]](#Alzheimer's-Dataset-(-4-class-of-Images))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WK3xLtmPPrja"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WK3xLtmPPrja"
   },
   "source": [
    "## Predicting Alzheimer's disease with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WK3xLtmPPrja"
   },
   "source": [
    "_In this section we will build a complete pipeline to build a model that can predict the dementia level of an Alzheimer's patient from their MRI image._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WK3xLtmPPrja"
   },
   "source": [
    "_The work in the following section is inspired and heavily based on the following articles._\n",
    "_They are used for groundwork for setting up, and for demonstrating some of the Deep Learning concepts outlined in this article._\n",
    "\n",
    "- mri_image_classification_using_transfer_learning [[Reference]](#mri_image_classification_using_transfer_learning)\n",
    "\n",
    "- Alzheimer's-Disease-Classification---InceptionV3 [[Reference]](#Alzheimer's-Disease-Classification---InceptionV3)\n",
    "\n",
    "- Alzheimer-MRI-Model-+-TensorFlow-2.3-Data-Loading [[Reference]](#Alzheimer-MRI-Model-+-TensorFlow-2.3-Data-Loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_clfA7FPrjV"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28wLUB0FPrjU"
   },
   "source": [
    "_It's always a good idea to set constant variables instead of hard coding numbers into your code. It saves time later when you want to change certain parameters._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1644739565665,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "YxVZhKI87GRo"
   },
   "outputs": [],
   "source": [
    "root_dir = \"./\"\n",
    "base_dir = \"/content/gdrive/MyDrive/Colab-Notebooks/softuni-ai-deeplearning-project-alz-1/data/\"\n",
    "test_dir = base_dir + \"test/\"\n",
    "train_dir = base_dir + \"train/\"\n",
    "work_dir = root_dir + \"dataset/\"\n",
    "WORK_DIR = work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hY0HNRE75IjN"
   },
   "outputs": [],
   "source": [
    "### The code below is to be used only if you are building the dataset from scratch:\n",
    "\n",
    "# if os.path.exists(work_dir):\n",
    "#     remove_tree(work_dir)\n",
    "    \n",
    "\n",
    "# os.mkdir(work_dir)\n",
    "# copy_tree(train_dir, work_dir)\n",
    "# copy_tree(test_dir, work_dir)\n",
    "# print(\"Working Directory Contents:\", os.listdir(work_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1644739759256,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "0JLXvF4V6NXY",
    "outputId": "4926989f-d32b-4c39-a3f4-a12d576b013b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-89dc1d128fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_replicas_in_sync\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mSTEPS_PER_EPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train_ds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">>> STEPS_PER_EPOCH: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "CLASSES = [ 'NonDemented',\n",
    "            'VeryMildDemented',\n",
    "            'MildDemented',\n",
    "            'ModerateDemented']\n",
    "\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "IMG_SIZE = 176\n",
    "IMAGE_SIZE = [176, 176]\n",
    "DIM = (IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "EPOCHS = 4\n",
    "\n",
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3HAkq-BMYFz"
   },
   "source": [
    "_Use the below to clear the session and reset models:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SDaqM_9MYFz"
   },
   "outputs": [],
   "source": [
    "### Use the below to clear the session and reset models:\n",
    "\n",
    "# tf.keras.backend.clear_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9p97fEdPrjb"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjTVdyyaGwng"
   },
   "source": [
    "_Initially I was planning to read the data like this and have only two data sets - train and validation one._\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiQKBJSMINmD"
   },
   "outputs": [],
   "source": [
    "# diy_train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     base_dir+\"train\",\n",
    "#     validation_split=0.2,\n",
    "#     subset=\"training\",\n",
    "#     seed=1337,\n",
    "#     image_size=IMAGE_SIZE,\n",
    "#     color_mode=\"rgb\"\n",
    "# )\n",
    "\n",
    "# diy_val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     base_dir+\"train\",\n",
    "#     validation_split=0.2,\n",
    "#     subset=\"validation\",\n",
    "#     seed=1337,\n",
    "#     image_size=IMAGE_SIZE,\n",
    "#     color_mode=\"rgb\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKlC_oRLebTY"
   },
   "outputs": [],
   "source": [
    "# print(type(train_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4XEBqqpJJiL"
   },
   "source": [
    "_I was thinking I would like to have a `test` dataset as well, so I went on to see what I can do._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ausB-UJPrjb"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Esswg1sJZdh"
   },
   "source": [
    "_I also wanted to do image augmentations to have more data samples._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQOULO1nPrjV"
   },
   "source": [
    "_I know I can add an augmentation layer to the model, but I wanted to explore a way where the augmentation is done on the data set._\n",
    "\n",
    "_This is for the scenario where you have a pre-trained model which you cannot change for one reason or the other, and you still want to do some custom image augmentations._\n",
    "\n",
    "_So, for this goal we will be using an image generator below._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1644739577143,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "atxajii66NXa"
   },
   "outputs": [],
   "source": [
    "#Performing Image Augmentation to have more data samples\n",
    "\n",
    "ZOOM = [.99, 1.01]\n",
    "BRIGHT_RANGE = [0.8, 1.2]\n",
    "HORZ_FLIP = True\n",
    "FILL_MODE = \"constant\"\n",
    "DATA_FORMAT = \"channels_last\"\n",
    "\n",
    "image_gen = IDG(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiIQJSJjPrjb"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkNti53MMYF3"
   },
   "source": [
    "_I decided to use `image_gen.flow_from_directory`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1644739784420,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "Bd5BTzgm_2sU",
    "outputId": "543b18d5-eff1-4c00-9c72-7e512702974d"
   },
   "outputs": [],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(directory=WORK_DIR, \n",
    "                                               target_size=DIM, \n",
    "                                               batch_size=BATCH_SIZE, \n",
    "                                               shuffle=True, \n",
    "                                               seed=9)\n",
    "\n",
    "print(type(image_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyIX5HkxIfsf"
   },
   "source": [
    "_Then I was planning on having two separate image generators, however that took forever and caused me sync problems with GoogleDrive._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otrJoBNJ5IPJ"
   },
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "# train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnbaRwDN8VE1"
   },
   "outputs": [],
   "source": [
    "# test_data, test_labels = test_data_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cLaDQ_Z5Ilc"
   },
   "outputs": [],
   "source": [
    "# test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "# test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QY4fpXywI5p_"
   },
   "source": [
    "_So I decided to go with just one image generator._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12355,
     "status": "ok",
     "timestamp": 1644739612937,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "PsKvXJiy8U7u"
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = train_data_gen.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4uMh_0RHBbG"
   },
   "source": [
    "_However, albeit not entierly elegant, I tried using `train_test_split`, as this way I would get train, validation and test data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1644739778962,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "SoC3jI1RKvZb"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into train, test, and validation sets:\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1644739780042,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "SBMiYDFWSMDW",
    "outputId": "78581215-9703-4cd4-b60a-c923a5a77e82"
   },
   "outputs": [],
   "source": [
    "print(\">>> train_data.shape: \", train_data.shape)\n",
    "print(\">>> train_labels.shape: \", train_labels.shape)\n",
    "print(\">>> test_data.shape: \", test_data.shape)\n",
    "print(\">>> test_labels.shape: \", test_labels.shape)\n",
    "print(\">>> val_data.shape: \", val_data.shape)\n",
    "print(\">>> val_labels.shape: \", val_labels.shape)\n",
    "\n",
    "print(train_data[0][0][0][0])\n",
    "print(type(train_data[0][0][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oldrJxWMYF3"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yR3zEMRK6MX"
   },
   "source": [
    "_I wanted to do oversampling, but the below code crashed my Google Colab session each time I tried to execute it._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qE_4qy4aKvZb"
   },
   "outputs": [],
   "source": [
    "# new_train_ds\n",
    "\n",
    "# Performing over-sampling of the data, since the classes are imbalanced\n",
    "\n",
    "# sm = SMOTE(random_state=42)\n",
    "\n",
    "# train_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n",
    "\n",
    "# train_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dONkIB-SZvGB"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVn4t4AAMYF3"
   },
   "source": [
    "_Initially I tried building the dataset using `slices` but that did not work out well._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQCKTuXf5IoJ"
   },
   "outputs": [],
   "source": [
    "# Retrieving the data from the ImageDataGenerator iterator\n",
    "\n",
    "# train_data, train_labels = train_data_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASocAqIOKvZa"
   },
   "outputs": [],
   "source": [
    "# Getting to know the dimensions of our dataset\n",
    "\n",
    "# print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfRaYhGYHM4v"
   },
   "outputs": [],
   "source": [
    "# new_train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EkyX1zAEHhYM"
   },
   "outputs": [],
   "source": [
    "# print(new_train_dataset)\n",
    "# print(len(new_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzCmCKMk1PZa"
   },
   "outputs": [],
   "source": [
    "# new_train_dataset = new_train_dataset.cache().prefetch(buffer_size=AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BSCpm9S1VpG"
   },
   "outputs": [],
   "source": [
    "# print(new_train_dataset)\n",
    "# print(len(new_train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5zgsuIbMYF5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmK7l1hGMYF3"
   },
   "source": [
    "_I wanted to see what else can I use, other than `train_test_split`._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "163KQ0Z3MYF5"
   },
   "source": [
    "_I decided to use `image_gen.flow_from_directory`._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGCiftawMYF5"
   },
   "source": [
    "_Below we are building a dataset from the image generator._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1644739612938,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "SRAQIJWtU6-3",
    "outputId": "f976064f-7d06-4cf2-958c-eeedd1fb4d2c"
   },
   "outputs": [],
   "source": [
    "### Building a dataset from the image generator:\n",
    "\n",
    "tr_datset = tf.data.Dataset.from_generator(lambda: train_data_gen,\n",
    "                                           output_types = (tf.float32, tf.float32),\n",
    "                                            output_shapes = ([None, 176, 176, 3], [None, 4]))\n",
    "\n",
    "tr_datset = tr_datset.apply(tf.data.experimental.assert_cardinality(6400)) # number of samples\n",
    "\n",
    "print(tr_datset)\n",
    "print(len(tr_datset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1644739612939,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "fx4d8hsWFtbq"
   },
   "outputs": [],
   "source": [
    "### Setting up repeat() for the dataset:\n",
    "\n",
    "tr_datset_rep = tr_datset.repeat(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1644739612939,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "rbBEPQSeGz9_"
   },
   "outputs": [],
   "source": [
    "# Reference: https://towardsdatascience.com/how-to-split-a-tensorflow-dataset-into-train-validation-and-test-sets-526c8dd29438\n",
    "\n",
    "def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=9)\n",
    "\n",
    "    # Use when BATCH_SIZE > 1:\n",
    "    train_size = int(train_split * ds_size) // BATCH_SIZE\n",
    "    val_size = int(val_split * ds_size) // BATCH_SIZE\n",
    "    test_size = int(test_split * ds_size) // BATCH_SIZE\n",
    "\n",
    "    # Use when BATCH_SIZE == 1:\n",
    "    # train_size = int(train_split * ds_size)\n",
    "    # val_size = int(val_split * ds_size)\n",
    "    # test_size = int(test_split * ds_size)\n",
    "\n",
    "    print(\">>> train_size \", train_size)\n",
    "    print(\">>> val size \", val_size)\n",
    "    print(\">>> test size \", test_size)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    train_ds = ds.take(train_size)\n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size).take(test_size)\n",
    "\n",
    "    print(\">>> new_train_ds: \", train_ds)\n",
    "    print(\">>> new_val_ds: \", val_ds)\n",
    "    print(\">>> new_test_ds: \", test_ds)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\">>> len new_train_ds: \", len(train_ds))\n",
    "    print(\">>> len new_val_ds: \",  len(val_ds))\n",
    "    print(\">>> len new_test_ds: \",  len(test_ds))\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1644739613285,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "Wp_R-zsFFz80",
    "outputId": "d3f6f080-5c6b-4b84-c92e-d0b6e78905ef"
   },
   "outputs": [],
   "source": [
    "new_train_ds, new_val_ds, new_test_ds = get_dataset_partitions_tf(tr_datset_rep, len(tr_datset_rep), shuffle=False, shuffle_size=len(tr_datset_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LR1whNrrFUxt"
   },
   "outputs": [],
   "source": [
    "# ### Repeat:\n",
    "\n",
    "# num_epochs = 4\n",
    "\n",
    "# new_train_ds_rep = new_train_ds.repeat(num_epochs)\n",
    "\n",
    "# new_val_ds_rep = new_val_ds.repeat(num_epochs)\n",
    "\n",
    "# new_test_ds_rep = new_test_ds.repeat(num_epochs)\n",
    "\n",
    "# print(\">>> new_train_ds_rep: \", new_train_ds_rep)\n",
    "# print(\">>> new_val_ds_rep: \", new_val_ds_rep)\n",
    "# print(\">>> new_test_ds_rep: \", new_test_ds_rep)\n",
    "\n",
    "# print(\">>> len new_train_ds_rep: \", len(new_train_ds_rep))\n",
    "# print(\">>> len new_val_ds_rep: \",  len(new_val_ds_rep))\n",
    "# print(\">>> len new_test_ds_rep: \",  len(new_test_ds_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = len(new_train_ds) // BATCH_SIZE\n",
    "print(\">>> STEPS_PER_EPOCH: \", STEPS_PER_EPOCH)\n",
    "\n",
    "VAL_STEPS_PER_EPOCH = len(new_val_ds) // BATCH_SIZE\n",
    "print(\">>> VAL_STEPS_PER_EPOCH: \", VAL_STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWjYPVaLMYF7"
   },
   "source": [
    "_Like mentioned in the introductory notes, we currently do not have sufficient computing power at our disposal for proper hyperparameters._\n",
    "\n",
    "_If we did, we could use calculations such as the ones below to get good numbers for how many `steps` should we perform for `training` and `validation` per each of our `epochs` according to the `batches` of our `dataset`._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdh4KyOrPrja"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhtCeQNEMYF8"
   },
   "source": [
    "## Data visualization\n",
    "\n",
    "_Visualizing a bit of our data, just to get an idea._\n",
    "\n",
    "_Now that our data has been loaded in, the next step is to visualize our images. This helps us understand what is being used as an input for our model. It also serves as a check to see if our images have been loaded in correctly._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 4646,
     "status": "ok",
     "timestamp": 1644678930044,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "jzThwZUMKvZU",
    "outputId": "b7221b3d-bad4-4b83-985b-1f250b6e13b3"
   },
   "outputs": [],
   "source": [
    "def show_images(generator,y_pred=None):\n",
    "    \"\"\"\n",
    "    Input: An image generator,predicted labels (optional)\n",
    "    Output: Displays a grid of 9 images with lables\n",
    "    \"\"\"\n",
    "    \n",
    "    # get image lables\n",
    "    labels =dict(zip([0,1,2,3], CLASSES))\n",
    "    \n",
    "    # get a batch of images\n",
    "    x,y = generator.next()\n",
    "    \n",
    "    # display a grid of 9 images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    if y_pred is None:\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            idx = randint(0, BATCH_SIZE-1)\n",
    "            plt.imshow(x[idx])\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Class:{}\".format(labels[np.argmax(y[idx])]))\n",
    "                                                     \n",
    "    else:\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(x[i])\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))\n",
    "    \n",
    "# Display Train Images\n",
    "show_images(train_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3j2BO4X9Prja"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8Zy5xLj5Jrw"
   },
   "source": [
    "## Inception v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JR2NtuA6KvZb"
   },
   "source": [
    "_We will be using the InceptionV3 model as a base model for the task._\n",
    "\n",
    "_Let's create the base model from the pre-trained InceptionV3 architecture._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeCXmecwMYF-"
   },
   "source": [
    "### Base Inception v3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0jW_5gZKvZc"
   },
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained InceptionV3 architecture\n",
    "\n",
    "base_inception_model = InceptionV3(input_shape=(176, 176, 3),\n",
    "                              include_top=False, \n",
    "                              weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRxTFUZTagTw"
   },
   "source": [
    "_We need to freeze the base model layers to prevent its weights from being modified._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDjq26xdKvZc"
   },
   "outputs": [],
   "source": [
    "### Freezing base_model layers:\n",
    "### This would also do: `base_inception_model.trainable = false`\n",
    "for layer in base_inception_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lu-HqMGprJ1l"
   },
   "source": [
    "_Let's check the base model's architecture._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1644678937624,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "8xNyCTIFKcmh",
    "outputId": "54abe969-3ae2-481a-9392-d7e055b3c7f4"
   },
   "outputs": [],
   "source": [
    "base_inception_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwS9BE33KvZd"
   },
   "source": [
    "### Transfer learning and a custom Inception v3 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4KYA1NWeTod"
   },
   "source": [
    "_By using transfer learnign we will build our custom architecture on top of the base model._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1CwfknKMYF_"
   },
   "source": [
    "_We will be using the `base model's` input shape, which we have previously specified, to fit our images._\n",
    "\n",
    "_As a final output we will be using a `Dense` layer with output shape of `4` as we have `4` classes between which we need to classify, with an `activation` of `softmax`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aISdGhPLhNJ"
   },
   "outputs": [],
   "source": [
    "### custom_inception_model with global_average_layer\n",
    "\n",
    "custom_inception_model = Sequential([\n",
    "        base_inception_model,\n",
    "        Dropout(0.5),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        BatchNormalization(),\n",
    "        Dense(4, activation='softmax')        \n",
    "    ], name = \"inception_cnn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiRaBxT8MYF_"
   },
   "source": [
    "_Let's check the base model's architecture._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1644678939090,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "uF-kETrbDpXc",
    "outputId": "7d5005b8-e01a-4d0d-e432-b49fa4c46bec"
   },
   "outputs": [],
   "source": [
    "custom_inception_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDsjxwJwLQqW"
   },
   "source": [
    "### Defining our callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FG5ZNuoNE1JG"
   },
   "source": [
    "_Ideally we would be defining a custom callback function to stop training our model when accuracy goes above 99%, however due to the aforementioned difficulties and lack of power on my personal machine and on Google Colab, we would lower all of our metrics and hyperparameters._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1644747182628,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "5bhgB_uLtjKi"
   },
   "outputs": [],
   "source": [
    "# Defining a custom callback function to stop training our model when accuracy goes above a certain level.\n",
    "# Ideally we would be defining a custom callback function to stop training our model when accuracy goes above 99%,\n",
    "# but because we are doing this as a project with not a lot of computing power,\n",
    "# let set it for when accuracy goes above 65%:\n",
    "\n",
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('acc') > 0.65:\n",
    "            print(\"\\nReached accuracy threshold! Terminating training.\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "my_callback = MyCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qgw1va3dFEdE"
   },
   "outputs": [],
   "source": [
    "# Using ReduceLROnPlateau to stabilize the training process of the model\n",
    "rop_callback = ReduceLROnPlateau(monitor=\"val_loss\", patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbUh2VRLtjKn"
   },
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(root_dir+\"models/model-inceptionv3-1/alzheimer_model-inceptionv3-1.h5\",\n",
    "                                                    save_best_only=True, \n",
    "                                                   monitor=\"val_loss\", \n",
    "                                                   mode='min')\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                     restore_best_weights=True, \n",
    "                                                     monitor=\"val_loss\", \n",
    "                                                     mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_B6aiIoOtjKo",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "METRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
    "           tf.keras.metrics.AUC(name='auc'),\n",
    "           tfa.metrics.F1Score(num_classes=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ztiNbntT0j3"
   },
   "outputs": [],
   "source": [
    "CALLBACKS = [checkpoint_cb, early_stopping_cb, my_callback, rop_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpz34KolMYGB"
   },
   "source": [
    "### Compiling our custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Q1TU30fT0hC"
   },
   "source": [
    "_It's time to compile our custom model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zq8b6TjJtjKp"
   },
   "outputs": [],
   "source": [
    "custom_inception_model.compile(optimizer='rmsprop',\n",
    "                               loss=tf.losses.CategoricalCrossentropy(),\n",
    "                               metrics=METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pg7Lhg5rFTrF"
   },
   "source": [
    "_Let's check our compiled custom models' architecture._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1644678939524,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "t8idxslZAphn",
    "outputId": "262fcdd2-7be4-4f69-b177-4e6e355c5ecb"
   },
   "outputs": [],
   "source": [
    "custom_inception_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YixSithwMYGB"
   },
   "source": [
    "### Training our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1644594977594,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "kFl1PNZnevhi",
    "outputId": "a652e2aa-1200-4040-b653-7a77e5b98942"
   },
   "source": [
    "### Let's fit our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuPT2DUFtjKp"
   },
   "source": [
    "_It's time to fit our model with the training data and validate it using the validation data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1722676,
     "status": "ok",
     "timestamp": 1644680662193,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "LP-TQZDW_IUo",
    "outputId": "016163e7-ec8b-4a63-b12b-26bb5b6b9caa"
   },
   "outputs": [],
   "source": [
    "# Fit the training data to the model and validate it using the validation data\n",
    "\n",
    "history_inception_3 = custom_inception_model.fit(new_train_ds,\n",
    "                                     validation_data=new_val_ds, \n",
    "                                     callbacks=CALLBACKS, \n",
    "                                     epochs=EPOCHS,\n",
    "                                     steps_per_epoch=16,\n",
    "                                     validation_steps=VAL_STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Well these results do not look as good as expected, the `loss` function is high, and the `accuracy` is low, and these should really be the other way around.___\n",
    "\n",
    "___This is to be expected considering the sacrifices we have had to make and reduce our hyperparameters with Google Colab training.___\n",
    "\n",
    "___The `epoch` hyperparameter should really be much bigger, around `512` for example, and the `steps_per_epoch` should really be around `256` for example. Unfortunately we are limited by the `BATCH_SIZE` constant, as it is correlated to the `epoch` and `steps_per_epoch` hyperparameters and the way they are calculated. We have set the `BATCH_SIZE` constant to a low number, only due to the Google Colab limitations.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vq6MzfD0EoxN"
   },
   "source": [
    "_Saving the model for future use._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1644746822201,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "Vhayrk2DTMB6"
   },
   "outputs": [],
   "source": [
    "# Saving the model for future use\n",
    "def save_model(model_to_save, dir_name):\n",
    "    model_save_dir = root_dir + dir_name\n",
    "    model_to_save.save(model_save_dir, save_format='h5')\n",
    "    os.listdir(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TEaWZOJMYGE"
   },
   "outputs": [],
   "source": [
    "save_model(custom_inception_model, \"models/alzheimer_inception_model_2022_02_12_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Let's plot the trend of the metrics during training._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rQh-WOVSxJA"
   },
   "outputs": [],
   "source": [
    "# Plotting the trend of the metrics during training\n",
    "\n",
    "def plot_history_metrics(history_to_plot):\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (30, 5))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n",
    "        ax[i].plot(history_to_plot.history[metric])\n",
    "        ax[i].plot(history_to_plot.history[\"val_\" + metric])\n",
    "        ax[i].set_title(\"Model {}\".format(metric))\n",
    "        ax[i].set_xlabel(\"Epochs\")\n",
    "        ax[i].set_ylabel(metric)\n",
    "        ax[i].legend([\"train\", \"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "executionInfo": {
     "elapsed": 2288,
     "status": "ok",
     "timestamp": 1644682221862,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "7APmABJ4MYGD",
    "outputId": "e79eb345-b5f1-4d84-ec55-6450481f651b"
   },
   "outputs": [],
   "source": [
    "plot_history_metrics(history_inception_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4uIPcZXu2CF"
   },
   "source": [
    "___Well these results do not look as good as expected, the `auc roc curve` does not have a good \"curve\".___\n",
    "\n",
    "___This is to be expected considering the sacrifices we have had to make and reduce our hyperparameters with Google Colab training.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4uIPcZXu2CF"
   },
   "source": [
    "_Give the cell below a bit of time, takes about 6 minutes in Google Colab._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YetWMGkStQTd"
   },
   "outputs": [],
   "source": [
    "# If you want to retrieve more elements of the dataset, just increase the number inside the take method.\n",
    "# If you want all elements, just insert -1.\n",
    "\n",
    "for test_images_split, test_labels_split in new_test_ds.take(-1):\n",
    "    numpy_test_images = test_images_split.numpy()\n",
    "    numpy_test_labels = test_labels_split.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4uIPcZXu2CF"
   },
   "source": [
    "_Let's evaluate our model on the test data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6019,
     "status": "ok",
     "timestamp": 1644682810079,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "d6-mFvm9u79e",
    "outputId": "a0af43f1-7736-47a5-c875-3e815777d8cf"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on the data\n",
    "\n",
    "test_scores = custom_inception_model.evaluate(numpy_test_images, numpy_test_labels)\n",
    "\n",
    "print(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4uIPcZXu2CF"
   },
   "source": [
    "___Well these results do not look as good as expected, the `Accuracy` is very low.___\n",
    "\n",
    "___This is to be expected considering the sacrifices we have had to make and reduce our hyperparameters with Google Colab training.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPo2iUarv3ha"
   },
   "source": [
    "_Let's do some predictions and print some classification reports._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPo2iUarv3ha"
   },
   "source": [
    "_Give the cell below a bit of time, takes about 10 minutes in Google Colab._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyMMlmfzzD65"
   },
   "outputs": [],
   "source": [
    "# Predicting the test data\n",
    "\n",
    "pred_labels = custom_inception_model.predict(numpy_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1644684023279,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "7xR734NRSgCu",
    "outputId": "c83de3c2-936f-4063-efeb-fe3c7c00f78e"
   },
   "outputs": [],
   "source": [
    "# Print the classification report of the tested data\n",
    "\n",
    "# Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n",
    "# similar to the test_labels\n",
    "def roundoff(arr):\n",
    "    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n",
    "    arr[np.argwhere(arr != arr.max())] = 0\n",
    "    arr[np.argwhere(arr == arr.max())] = 1\n",
    "    return arr\n",
    "\n",
    "for labels in pred_labels:\n",
    "    labels = roundoff(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1644684028505,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "k6cYCtFFx4uT",
    "outputId": "d4dc57af-e750-46a6-f9d5-15f28cb3aa05"
   },
   "outputs": [],
   "source": [
    "print(classification_report(numpy_test_labels, pred_labels, target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1644684182698,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "1PziSxdqyxL_",
    "outputId": "65bdbb28-b58c-4002-8c86-37968aed9a99"
   },
   "outputs": [],
   "source": [
    "numpy_test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "executionInfo": {
     "elapsed": 904,
     "status": "ok",
     "timestamp": 1644684241059,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "Rvi_biHsD0TD",
    "outputId": "ffe5d405-5759-493c-bca3-298a3671a725"
   },
   "outputs": [],
   "source": [
    "#Plot the confusion matrix to understand the classification in detail\n",
    "\n",
    "def plot_confusion_matrix(pred_labels, test_labels):\n",
    "  pred_ls = np.argmax(pred_labels, axis=1)\n",
    "  test_ls = np.argmax(test_labels, axis=1)\n",
    "\n",
    "  conf_arr = confusion_matrix(test_ls, pred_ls)\n",
    "\n",
    "  plt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "  ax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=CLASSES,\n",
    "                  yticklabels=CLASSES)\n",
    "\n",
    "  plt.title('Alzheimer\\'s Disease Diagnosis')\n",
    "  plt.xlabel('Prediction')\n",
    "  plt.ylabel('Truth')\n",
    "  plt.show(ax)\n",
    "\n",
    "plot_confusion_matrix(pred_labels, numpy_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1644684254526,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "EKFjluflXjr5",
    "outputId": "298e3483-2d67-4ee2-dd11-31217719a70b"
   },
   "outputs": [],
   "source": [
    "#Printing some other classification metrics\n",
    "\n",
    "print(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\n",
    "print(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4uIPcZXu2CF"
   },
   "source": [
    "___Well these results do not look as good as expected, the `Confusion Matrix` is even missing some of it's dimensions.___\n",
    "\n",
    "___This is to be expected considering the sacrifices we have had to make and reduce our hyperparameters with Google Colab training.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSs7IuMVkJH7"
   },
   "source": [
    "### Loading the saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4uIPcZXu2CF"
   },
   "source": [
    "_Let's load our model and print it's architecture, so we can have a better visual representation of it._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = tf.keras.models.load_model(root_dir+\"models/alzheimer_inception_model_2022_02_12_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSs7IuMVkJH7"
   },
   "source": [
    "### Plotting the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 15447,
     "status": "ok",
     "timestamp": 1644684345239,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "NENpS-qhcpRa",
    "outputId": "5d208930-fe1a-4400-d204-be4fd09608eb"
   },
   "outputs": [],
   "source": [
    "# Plot model architecture:\n",
    "\n",
    "plot_model(pretrained_model, to_file=root_dir + \"models/alzheimer_inception_model_2022_02_12_1.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Here is an image just in case the above cell does not work.___\n",
    "\n",
    "![alzheimer_inception_model_2022_02_12_1](./models/alzheimer_inception_model_2022_02_12_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Although these results do not look good, in a real-world more powerful environment, as opposed to a project (Google Colab, or similar) environment, with powerful GPUs or TPUs, these results will greatly improved, and this architecture will prove efficient at predictions with good scores.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___I am not satisfied with the performance of the current architecture and model in Google Colab, and therefore there is no point in me extending it at the moment with my innovative ideas. Let's see if we can do something else which will allow us to do that in the next section.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmCCglr25iv0"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykAe7IiaSweO"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NX18hUNb5iv4"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1644594977592,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "vgCxaFqoecRF",
    "outputId": "95b60000-e27f-4bc3-cf37-4a288d5293d9"
   },
   "source": [
    "## Building our own DIY model MK1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1644594977592,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "vgCxaFqoecRF",
    "outputId": "95b60000-e27f-4bc3-cf37-4a288d5293d9"
   },
   "source": [
    "_I was not happy with the results in the previous section._\n",
    "\n",
    "_I credit the bad results mainly to the restrictions of Google Colab and partially to the innovative way I am building the dataset._\n",
    "\n",
    "_So, this is why I wanted to try building the dataset in a more standard way, and also building my own model architecture without transfer learning of a big model, hoping that a smaller model would train quicker in Google Colab._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The work in the following section is inspired and heavily based on the following articles._\n",
    "_They are used for groundwork for setting up, and for demonstrating some of the Deep Learning concepts outlined in this article._\n",
    "\n",
    "- Alzheimer-MRI-Model-+-TensorFlow-2.3-Data-Loading [[Reference]](#Alzheimer-MRI-Model-+-TensorFlow-2.3-Data-Loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The model architecture from this Notebook is modular in functions and is easily changed and extended which is exactly what I needed._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "_We'll be using a Kaggle Alzheimer's dataset for our tutorial. tf.keras has a new preprocessing function that can easily load in images for a directory. In order for this function to work, the data has to be structured in a file directory format._\n",
    "\n",
    "```\n",
    "main_directory/\n",
    "    class1/\n",
    "        class1_images\n",
    "    class2/\n",
    "        class2_images\n",
    "```\n",
    "\n",
    "_If you input the main_directory into the tf.keras function, it will figure out the rest! In our case, the train directory is our main directory._\n",
    "\n",
    "_We are also specifying a 80:20 split for our training and validation datasets._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1920,
     "status": "ok",
     "timestamp": 1644696594049,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "6x_z3exBGGsx",
    "outputId": "82433ce3-d83a-482f-9044-0b4aeee593b5"
   },
   "outputs": [],
   "source": [
    "diy_train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    base_dir+\"train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "diy_val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    base_dir+\"train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "diy_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    base_dir+\"test\",\n",
    "    seed=1337,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We'll be renaming the class names and specifying the number of classes. In this case, we have 4 classes of dementia._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXedFjDg5BUD"
   },
   "outputs": [],
   "source": [
    "diy_train_ds.class_names = CLASSES\n",
    "diy_val_ds.class_names = CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRXqLX195iv2"
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-s22Lncp5iv3"
   },
   "source": [
    "_Because we are working with categorical and noncontinuous data, we want to convert our model into one-hot encodings._\n",
    "\n",
    "_One-hot encodings are a way for the model to understand that we're looking at categorical instead of continuous data._\n",
    "\n",
    "_Transforming features so that they'll be more understandable is called feature engineering._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1644696596748,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "6MrF4NMs5iv3",
    "outputId": "0405078f-be4f-4748-f1dc-3865f54a5a74"
   },
   "outputs": [],
   "source": [
    "# Assigning one hot encoding of labels to train and val dataset:\n",
    "\n",
    "def one_hot_label(image, label):\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_dataset_ohe = diy_train_ds.map(one_hot_label)\n",
    "print(type(train_dataset_ohe))\n",
    "print(train_dataset_ohe)\n",
    "print(len(train_dataset_ohe))\n",
    "\n",
    "\n",
    "\n",
    "val_dataset_ohe = diy_val_ds.map(one_hot_label) \n",
    "print(type(val_dataset_ohe))\n",
    "print(val_dataset_ohe)\n",
    "print(len(val_dataset_ohe))\n",
    "\n",
    "test_ds_ohe = diy_test_ds.map(one_hot_label)\n",
    "print(type(test_ds_ohe))\n",
    "print(test_ds_ohe)\n",
    "print(len(test_ds_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeaQHQleAW0j"
   },
   "outputs": [],
   "source": [
    "train_dataset_ohe = train_dataset_ohe.repeat(BATCH_SIZE)\n",
    "val_dataset_ohe = val_dataset_ohe.repeat(BATCH_SIZE)\n",
    "test_ds_ohe = test_ds_ohe.repeat(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7xg23QNTV0d"
   },
   "source": [
    "### Deciding a Metric\n",
    "\n",
    "The most conventional metric to use is probably accuracy. Accuracy, however, cannot be used for imbalanced datasets. Let's check how many images are in each class for our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1644696604717,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "wfTVfFKCTm-T",
    "outputId": "13eab88c-993d-4302-9312-a276bae296bf"
   },
   "outputs": [],
   "source": [
    "NUM_IMAGES_PER_CLASS = []\n",
    "\n",
    "for label in CLASSES:\n",
    "    dir_name = base_dir+\"train/\" + label[:-2] + 'ed'\n",
    "    NUM_IMAGES_PER_CLASS.append(len([name for name in os.listdir(dir_name)]))\n",
    "\n",
    "NUM_IMAGES_PER_CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GScKKODaTm-U"
   },
   "source": [
    "Our dataset is not balanced, so we cannot use accuracy as our metric. For this tutorial, we will be using ROC AUC. Intuitively, ROC AUC gives a score, with higher scores closer to 1 indicating that the different classes can be distinguishable for the model. A lower score closer indicates that the the model cannot distinguish between different classes. A score of 0.5 indicates that the ordering the images is pretty much random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8a3E_V16JNL"
   },
   "source": [
    "### Building the model\n",
    "\n",
    "_We'll be using the same architecture for our model as my [Pneumonia Classification NB](#TensorFlow-Pneumonia-Classification-on-X-rays). Using tf.keras, we can easily build up the layers of our CNN._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULuW_lLvxPg3"
   },
   "outputs": [],
   "source": [
    "def conv_block(filters):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D()\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6N5DZsIy_n9"
   },
   "outputs": [],
   "source": [
    "def dense_block(units, dropout_rate):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZUC4EgeK3Je"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(*IMAGE_SIZE, 3)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        \n",
    "        conv_block(32),\n",
    "        conv_block(64),\n",
    "        \n",
    "        conv_block(128),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        conv_block(256),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_block(512, 0.7),\n",
    "        dense_block(128, 0.5),\n",
    "        dense_block(64, 0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmLB7YYW8wyg"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = build_model()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.losses.CategoricalCrossentropy(),\n",
    "        metrics=METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1644594977593,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "sEMg0Uqw9DTj",
    "outputId": "c5f484ac-036b-412b-b679-34f431a467c4"
   },
   "source": [
    "### Training the Model\n",
    "\n",
    "_To more efficiently train our model. We will be using callbacks to adjust our learning rate and to stop our model once it converges._\n",
    "\n",
    "_The [learning rate](https://developers.google.com/machine-learning/glossary#learning-rate) is a very important hyperparameter in the model. Having a LR that is too high will prevent the model from converging. Having a LR that is too slow will make the process too long. Stopping our model early is one mechanism that prevents overfitting._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1644687489332,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "xebzDlK79qFe",
    "outputId": "7e617dfd-d51e-4ef6-b4ff-4d7cb29ccd1d"
   },
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 **(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(0.01, 20)\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "NEW_CALLBACKS = [checkpoint_cb, early_stopping_cb, my_callback, rop_callback, lr_scheduler]\n",
    "\n",
    "print(NEW_CALLBACKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1644594977594,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "kFl1PNZnevhi",
    "outputId": "a652e2aa-1200-4040-b653-7a77e5b98942"
   },
   "source": [
    "### Let's fit our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3802248,
     "status": "ok",
     "timestamp": 1644691450811,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "Yx8g0zaQtjKp",
    "outputId": "ac635bdb-3b4b-453f-df5e-576513270445"
   },
   "outputs": [],
   "source": [
    "diy_model_history = model.fit(train_dataset_ohe,\n",
    "                              validation_data=val_dataset_ohe,\n",
    "                              callbacks=NEW_CALLBACKS,\n",
    "                              epochs=4,\n",
    "                              steps_per_epoch=16,\n",
    "                              validation_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Well these results do not look as good as expected, the `loss` function is high, and the `accuracy` is low, and these should really be the other way around.___\n",
    "\n",
    "___This is to be expected considering the sacrifices we have had to make and reduce our hyperparameters with Google Colab training.___\n",
    "\n",
    "___The `epoch` hyperparameter should really be much bigger, around `512` for example, and the `steps_per_epoch` should really be around `256` for example. Unfortunately we are limited by the `BATCH_SIZE` constant, as it is correlated to the `epoch` and `steps_per_epoch` hyperparameters and the way they are calculated. We have set the `BATCH_SIZE` constant to a low number, only due to the Google Colab limitations.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSueRmNXKcvA"
   },
   "outputs": [],
   "source": [
    "save_model(model, \"models/diy_model_2022_02_12_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize model metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's graph the `ROC AUC` metric and loss after each epoch for the training and validation data. Although we didn't use a random seed for our notebook, the results may slightly vary, generally the scores for the validataion data is similar, if not better, than the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1644691452876,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "3QMcIg-OKc1T",
    "outputId": "243c7aba-db31-40b4-959e-00e8eea2ce9e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_history_metrics(diy_model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4uIPcZXu2CF"
   },
   "source": [
    "___Well these results do not look as good as expected, the `auc roc curve` does not have a good \"curve\".___\n",
    "\n",
    "___This is to be expected considering the sacrifices we have had to make and reduce our hyperparameters with Google Colab training.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we used the validatation dataset to continually evaluate the model, we also have a separate testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1221826,
     "status": "ok",
     "timestamp": 1644692674699,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "oeiQsQoRKc3M",
    "outputId": "b5a9d164-2e1a-4d44-eeb3-33501f893493"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on the data\n",
    "\n",
    "diy_test_scores = model.evaluate(test_ds_ohe)\n",
    "\n",
    "print(\"Testing Accuracy: %.2f%%\"%(diy_test_scores[1] * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4uIPcZXu2CF"
   },
   "source": [
    "___Well these results do not look as good as expected, the `Accuracy` is very low.___\n",
    "\n",
    "___This is to be expected considering the sacrifices we have had to make and reduce our hyperparameters with Google Colab training.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSs7IuMVkJH7"
   },
   "source": [
    "### Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G578wZJDj-oR"
   },
   "outputs": [],
   "source": [
    "diy_model = tf.keras.models.load_model(root_dir + \"models/diy_model_2022_02_12_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSs7IuMVkJH7"
   },
   "source": [
    "### Plotting the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1717,
     "status": "ok",
     "timestamp": 1644697853719,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "rx4G1N9hYe1z",
    "outputId": "a60dfefc-d4dc-486f-e8a0-720453eb2a58"
   },
   "outputs": [],
   "source": [
    "# Plot model architecture:\n",
    "\n",
    "plot_model(diy_model, to_file=root_dir + \"models/diy_model_2022_02_12_1.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Here is an image just in case the above cell does not work.___\n",
    "\n",
    "![diy_model_2022_02_12_1.png](./models/diy_model_2022_02_12_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Although these results do not look good, in a real-world more powerful environment, as opposed to a project (Google Colab, or similar) environment, with powerful GPUs or TPUs, these results will greatly improved, and this architecture will prove efficient at predictions with good scores.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___I am not satisfied with the performance of the current architecture and model in Google Colab, and therefore there is no point in me extending it at the moment with my innovative ideas. Let's see if we can do something else which will allow us to do that in the next section.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVzCBEUZjgbL"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JicCsEOKPrjb"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ng4UGVXbPrjb"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our own DIY model MK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1644594977592,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "vgCxaFqoecRF",
    "outputId": "95b60000-e27f-4bc3-cf37-4a288d5293d9"
   },
   "source": [
    "_I was not happy with the results in the previous two experiments._\n",
    "\n",
    "_I credit the bad results mainly to the restrictions of Google Colab and partially to the innovative way I am building the dataset._\n",
    "\n",
    "_So, this is why I wanted to try building the dataset in a more better way, and also building my own model architecture without transfer learning of a big model, hoping that a smaller model would train quicker in Google Colab._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The work in the following section is inspired and heavily based on the following articles._\n",
    "_They are used for groundwork for setting up, and for demonstrating some of the Deep Learning concepts outlined in this article._\n",
    "\n",
    "- CNN-Alzheimer-MRI-images [[Reference]](#CNN-Alzheimer-MRI-images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The model architecture from this Notebook is modular in functions and is easily changed and extended which is exactly what I needed._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define auxiliary functions\n",
    "\n",
    "The following cells supplies auxiliary functions that can be used to achieve the objectives of the present script\n",
    "\n",
    "1. dataset_basic_info         -> display basic information on the data sets.\n",
    "\n",
    "\n",
    "2. build_model_ann_conv       -> return a Keras model object of a convolutional neural network built according to input specs provided by the user.\n",
    "\n",
    "\n",
    "3. build_model_pretrained_cnn -> return a Keras model object of a convolutional neural network made of a pretrained convolutional base (specified by the user) and a dense classifier (standard neural network) built according to input specs provided by the user.\n",
    "\n",
    "\n",
    "4. display_input_images       -> display batches of images from the train or test data set, credits to Amy Jang, see https://www.kaggle.com/amyjang/tensorflow-pneumonia-classification-on-x-rays/notebook#5.-Correct-for-data-imbalance [[Reference]](https://www.kaggle.com/amyjang/tensorflow-pneumonia-classification-on-x-rays/notebook#5.-Correct-for-data-imbalance)\n",
    "\n",
    "\n",
    "5. analyze_performances       -> plot the trajectories of four different performance metrics (i.e., loss, accuracy, precision and recall) recorded at the end of each epoch for both the testing and the validation phases.\n",
    "\n",
    "\n",
    "6. model_evaluation          -> evaluate the ability of the trained model to predict the labels of previously unseen samples (test set). Display the same metrics examined in the training phase and the confusion matrix.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1644740697246,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "SCKrnelfKc-k"
   },
   "outputs": [],
   "source": [
    "def dataset_basic_info(generator, name):\n",
    "        print('The ' + name + ' data set includes ' + str(generator.samples) + ' samples.')\n",
    "        print('The ' + name + ' image shapes is ' + str(generator.image_shape))\n",
    "        keys = [el for el in generator.class_indices.keys()]\n",
    "        print('The ' + name + ' data set includes the following labels: ')\n",
    "        print(keys)\n",
    "        labels     = generator.labels\n",
    "        cat_labels = []\n",
    "        for i in range(len(labels)):\n",
    "            for j in range(len(keys)):\n",
    "                if (labels[i] == j):\n",
    "                    cat_labels.append(keys[j])\n",
    "                    break\n",
    "        occurrences = []\n",
    "        for key in keys:\n",
    "            counter = 0\n",
    "            for i in range(len(cat_labels)):\n",
    "                if cat_labels[i] == key:\n",
    "                    counter += 1\n",
    "            occurrences.append(counter)\n",
    "        print(name + ' data set labels frequencies:')\n",
    "        weights = {}\n",
    "        for i in range(len(keys)):\n",
    "            print(keys[i] + ': ' + str(occurrences[i]) + ' (absolute), ' + str(round(occurrences[i]/float(generator.samples), 3)) + ' (relative).' )\n",
    "            weights[i] = generator.samples/np.array(occurrences[i])*(1.0/float(len(keys)))\n",
    "        \n",
    "        return weights\n",
    "\n",
    "\n",
    "def build_model_cnn(regression_problem, conv_filters, conv_filter_shape, conv_activation_function, conv_padding, conv_pooling_type, conv_pooling_shape, hidden_layers_neurons, hidden_activation_function, L1_coeffs, L2_coeffs, hidden_layers_dropout, final_layer_neurons, final_activation_function, shape, model_optimizer, loss_function, metrics):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    for i in range(len(conv_activation_function)):\n",
    "        \n",
    "        if (i == 0):\n",
    "            model.add(layers.Conv2D(conv_filters[i],\n",
    "                                    (conv_filter_shape[i][0],conv_filter_shape[i][1]), \n",
    "                                    activation = conv_activation_function[i], \n",
    "                                    padding    = conv_padding[i],\n",
    "                                    input_shape = (shape[0],shape[1],shape[2])))             \n",
    "        else:\n",
    "            model.add(layers.Conv2D(conv_filters[i],\n",
    "                                    (conv_filter_shape[i][0],conv_filter_shape[i][1]), \n",
    "                                    activation = conv_activation_function[i],\n",
    "                                    padding    = conv_padding[i]))\n",
    "        \n",
    "        if (conv_pooling_type[i] == 'max'):\n",
    "            model.add(layers.MaxPooling2D((conv_pooling_shape[i][0],conv_pooling_shape[i][1])))\n",
    "        elif (conv_pooling_type[i] == 'avg'):\n",
    "            model.add(layers.AveragePooling2D((conv_pooling_shape[i][0],conv_pooling_shape[i][1])))\n",
    "        else:\n",
    "            'no pooling'\n",
    "            \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    for i in range(len(hidden_activation_function)):\n",
    "\n",
    "        model.add(layers.Dense(hidden_layers_neurons[i], \n",
    "                               kernel_regularizer = regularizers.l1_l2(l1 = L1_coeffs[i], l2 =  L2_coeffs[i]),  \n",
    "                               activation=hidden_activation_function[i]))\n",
    "        if (hidden_layers_dropout[i] > 0.0):\n",
    "            model.add(layers.Dropout(hidden_layers_dropout[i]))\n",
    "    if regression_problem:\n",
    "            model.add(layers.Dense(final_layer_neurons))\n",
    "    else:\n",
    "            model.add(layers.Dense(final_layer_neurons,activation = final_activation_function))\n",
    "            \n",
    "    model.compile(optimizer = model_optimizer, loss = loss_function, metrics = metrics)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_model_pretrained_cnn(pre_trained_model, include_top, regression_problem, hidden_layers_neurons, hidden_activation_function, L1_coeffs, L2_coeffs, hidden_layers_dropout, final_layer_neurons, final_activation_function, model_optimizer, loss_function, metrics):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(pre_trained_model)\n",
    "    \n",
    "    if (include_top == False):\n",
    "        \n",
    "            model.add(layers.Flatten())\n",
    "\n",
    "            for i in range(len(hidden_activation_function)):\n",
    "\n",
    "                model.add(layers.Dense(hidden_layers_neurons[i], \n",
    "                                       kernel_regularizer = regularizers.l1_l2(l1 = L1_coeffs[i], l2 =  L2_coeffs[i]),  \n",
    "                                       activation=hidden_activation_function[i]))\n",
    "                if (hidden_layers_dropout[i] > 0.0):\n",
    "                    model.add(layers.Dropout(hidden_layers_dropout[i]))\n",
    "            if regression_problem:\n",
    "                    model.add(layers.Dense(final_layer_neurons))\n",
    "            else:\n",
    "                    model.add(layers.Dense(final_layer_neurons,activation = final_activation_function))\n",
    "            \n",
    "    model.compile(optimizer = model_optimizer, loss = loss_function, metrics = metrics)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def display_input_images(generator, max_n_figures, batch_size, grid_size, fig_size):\n",
    "    \n",
    "    fig_counter = 0\n",
    "    for image_batch, label_batch in generator: \n",
    "        plt.figure(figsize=(fig_size[0],fig_size[1]))\n",
    "        for j in range(batch_size):\n",
    "            ax   = plt.subplot(grid_size[0], grid_size[1], j + 1)\n",
    "            plt.imshow(image_batch[j])\n",
    "            if (label_batch[j][0] == 1):\n",
    "                    plt.title('MildDemented')\n",
    "            elif (label_batch[j][1] == 1):\n",
    "                    plt.title('ModerateDemented')\n",
    "            elif (label_batch[j][2] == 1):\n",
    "                    plt.title('NonDemented')\n",
    "            else:\n",
    "                    plt.title('VeryMildDemented')\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        fig_counter += 1\n",
    "        if (fig_counter == max_n_figures): break\n",
    "\n",
    "def analyze_performances(hst, epochs):\n",
    "    history_dict             = hst.history\n",
    "    loss_values              = history_dict['loss']\n",
    "    validation_loss_values   = history_dict['val_loss']\n",
    "    acc_values               = history_dict['categorical_accuracy']\n",
    "    validation_acc_values    = history_dict['val_categorical_accuracy']\n",
    "    auc_values               = history_dict['multiclass_AUC']\n",
    "    validation_auc_values    = history_dict['val_multiclass_AUC']\n",
    "    epochs                   = range(1,len(loss_values) + 1)\n",
    "    fig, axes                = plt.subplots(1,3,figsize = (30,10))\n",
    "    training_ts              = [loss_values, acc_values, auc_values]\n",
    "    validation_ts            = [validation_loss_values, validation_acc_values, validation_auc_values]\n",
    "    metric_names             = ['loss', 'categorical accuracy','average multiclass AUC']\n",
    "    for i in range(len(axes)):\n",
    "        axes[i].plot(epochs,training_ts[i],color = 'r',label = 'training')\n",
    "        axes[i].plot(epochs,validation_ts[i],color = 'b',label = 'validation')\n",
    "        axes[i].set_xlabel('epoch')\n",
    "        axes[i].set_ylabel(metric_names[i])\n",
    "        axes[i].set_title(metric_names[i] + ' analysis')\n",
    "        axes[i].set_xticks(np.arange(0,epochs[-1] + 1,5))\n",
    "        axes[i].set_yticks(np.arange(0,1.1,0.1))\n",
    "        axes[i].set_xlim([1,epochs[-1]])\n",
    "        axes[i].set_ylim([np.min([np.min(training_ts[i]),np.min(validation_ts[i])]),np.max([np.max(training_ts[i]),np.max(validation_ts[i])])])\n",
    "        axes[i].legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def model_evaluation(model, test_generator):\n",
    "    test_loss_1, test_acc_1, test_auc_1 = model.evaluate_generator(test_generator, verbose=0)\n",
    "    print('The value of the loss function on the test data set is: ' + str(round(test_loss_1,4)))\n",
    "    print('The categorical accuracy of the predictions on the test data set is: ' + str(round(test_acc_1,4)))\n",
    "    print('The categorical AUC (i.e., average curve across classes) of the predictions on the test data set is: ' + str(round(test_auc_1,4)))\n",
    "    \n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "    predictions = []\n",
    "    true        = []\n",
    "    ctr         = 0\n",
    "    for batch, label in test_generator:\n",
    "        prediction = model.predict(batch).argmax(axis = -1)\n",
    "        predictions.extend(prediction)\n",
    "        true.extend(label.argmax(axis = -1))\n",
    "        ctr += len(prediction)\n",
    "        if ctr >= len(test_generator.labels):\n",
    "            break\n",
    "            \n",
    "    matrix     = confusion_matrix(true,predictions)\n",
    "    rel_matrix = matrix/np.sum(matrix,axis = 0)\n",
    "    fig, axes  = plt.subplots(1,2,figsize = (20,40))\n",
    "\n",
    "    image1 = axes[0].imshow(matrix, cmap=plt.get_cmap('GnBu'))\n",
    "    for (i, j), e in np.ndenumerate(matrix):\n",
    "        axes[0].text(j, i, s = str(e), ha='center', va='center')\n",
    "    axes[0].set_xticks(np.arange(0,len(class_labels), 1))\n",
    "    axes[0].set_xticklabels(class_labels)\n",
    "    axes[0].set_yticks(np.arange(0,len(class_labels), 1))\n",
    "    axes[0].set_yticklabels(class_labels)\n",
    "    axes[0].set_title('Confusion Matrix')\n",
    "    \n",
    "    image2 = axes[1].imshow(matrix/np.sum(matrix,axis = 0), cmap=plt.get_cmap('GnBu'))\n",
    "    for (i, j), e in np.ndenumerate(rel_matrix):\n",
    "        axes[1].text(j, i, s = str(np.round(e,2)), ha='center', va='center')\n",
    "    axes[1].set_xticks(np.arange(0,len(class_labels), 1))\n",
    "    axes[1].set_xticklabels(class_labels)\n",
    "    axes[1].set_yticks(np.arange(0,len(class_labels), 1))\n",
    "    axes[1].set_yticklabels(class_labels)\n",
    "    plt.subplots_adjust(wspace = 0.5)\n",
    "    axes[1].set_title('Confusion Matrix (Relative)')                      \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input dashboard\n",
    "\n",
    "_We let the user set several variables that affect the estimation of the model:_\n",
    "\n",
    "* training_path -> specify the path of the training images. NOTE: the next level should include k folder, where k is the number of different possible labels (e.g. k = 2, dogs and cats).\n",
    "\n",
    "\n",
    "* test_path -> specify the path of the test images. NOTE: the next level should include k folder, where k is the number of different possible labels (e.g. k = 2, dogs and cats).\n",
    "\n",
    "\n",
    "* validation_split    -> fraction of the images in the test data folder that should be used as validation subset during the training of the model.\n",
    "\n",
    "\n",
    "* regression_problem  -> indicates whether we are facing a regression problem. If = True, the final layer of the densely connected neural network won't have any specified activation function.   \n",
    "\n",
    "\n",
    "* target_img_shape_1  -> the first desired dimension for the images; an input for the Keras function flow_from_directory that is applied to an ImageDataGenerator.\n",
    "\n",
    "\n",
    "* target_img_shape_2  -> the second desired dimension for the images; an input for the Keras function flow_from_directory that is applied to an ImageDataGenerator.\n",
    "\n",
    "\n",
    "* target_img_channels -> the number of desired channels for the images; an input for the Keras function flow_from_directory that is applied to an ImageDataGenerator. E.g. 3 channels for RGB images.\n",
    "\n",
    "\n",
    "* conv_filters        -> list including the number of different filters that are used in each convolution.\n",
    "\n",
    "\n",
    "* conv_filter_shape   -> list of k lists, where k is the number of desired convolutions. Each of these k lists includes two integers representing the dimensions (in number of cells) of each filter that slides across the picture.\n",
    "\n",
    "\n",
    "* conv_activation_function -> list including the names of the activation function that should be used in each convolution. Note: we have a product between a patch of the image and the filter. Then, the entries of the resulting matrix are summed up. This sum serves as the argument of the activation function g().\n",
    "\n",
    "\n",
    "* conv_padding -> list including the type of padding that should be used in each convolution. The string 'valid' means that no padding should be applied on the borders of the image. 'same' means that the image is padded such that the output of the convolution retains the same shape.\n",
    "\n",
    "\n",
    "* conv_pooling_type   -> list including the type of pooling that must be applied after each convolution. The string 'max' implements max pooling, the string 'avg' implements average pooling, any other string means no pooling after the current convolution.\n",
    "\n",
    "\n",
    "* conv_pooling_coeffs -> list of k lists, where k is the number of desired convolutions. Each of these k lists includes two integers representing the dimensions (in number of cells) of the pooling operation region that is applied across the convolved image.\n",
    "\n",
    "\n",
    "* augment_data -> boolean indicating whether the images in the training data set should be augmented by applying a broad range of actions, such as rotations, shearing, zooming, flipping etc.\n",
    "\n",
    "\n",
    "* rotation_range -> specifies the range (in degrees) of random rotations of the input images.\n",
    "\n",
    "\n",
    "* width_shift_range -> specifies the range (in fractions of the image width) of random horizontal shifts of the input images.\n",
    "\n",
    "\n",
    "* height_shift_range -> specifies the range (in fractions of the image height) of random vertical shifts of the input images.\n",
    "\n",
    "\n",
    "* shear_range -> specifies the symmetric range -x, x of random shears of the input images.\n",
    "\n",
    "\n",
    "* brightness_range -> list including the lower and upper extremes of the range of image brightness values that are randomly applied to the input images. \n",
    "\n",
    "\n",
    "* zoom_range -> specifies the symmetric range 1 - x, 1 + x of random zooms of the input images.\n",
    "\n",
    "\n",
    "* horizontal_flip -> boolean indicating whether the columns of the training images should be randomly flipped.\n",
    "\n",
    "\n",
    "* fill_mode -> name of the method that should be used to fill the new empty pixels emerged during data augmentation procedures.\n",
    "\n",
    "\n",
    "* print_sample_input -> boolean indicating whether a sample of the input images shall be printed.\n",
    "\n",
    "\n",
    "* hidden_activation_function -> list containing the name of the activation functions (available in Keras) used in the hidden layers of the densely connected neural network that follows the sequence of convolutions.\n",
    "\n",
    "\n",
    "* hidden_layers_neurons -> list containing the number of neurons forming each hidden layer of the densely connected neural network that follows the sequence of convolutions.\n",
    "\n",
    "\n",
    "* hidden_layers_L1_coeffs -> list containing scalars multiplying the L1-penalty terms for each hidden layer weights of the densely connected neural network that follows the sequence of convolutions. Set it to 0 to avoid L1-regularization.\n",
    "\n",
    "\n",
    "* hidden_layers_L2_coeffs -> list containing scalars multiplying the L2-penalty terms for each hidden layer weights of the densely connected neural network that follows the sequence of convolutions. Set it to 0 to avoid L2-regularization.\n",
    "\n",
    "\n",
    "* hidden_layers_dropouts ->  list containing the fractions of weights that are randomly set to zero in each hidden layer of the densely connected neural network that follows the sequence of convolutions. Set it to 0 to avoid dropout regularization.\n",
    "\n",
    "\n",
    "* final_activation_function -> name of the activation function (available in Keras) used in the terminal layer of the densely connected neural network that follows the sequence of convolutions.\n",
    "\n",
    "\n",
    "* final_layer_neurons -> number of neurons forming the terminal layer of the densely connected neural network that follows the sequence of convolutions.\n",
    "\n",
    "\n",
    "* model_optimizer -> name of the method (available in Keras) to iteratively update the search of the set of parameters that minimize the loss function.\n",
    "\n",
    "\n",
    "* loss_function -> name the loss function (available in Keras) that we seek to minimize.\n",
    "\n",
    "\n",
    "* metrics -> list containing the name of the metrics (available in Keras) that we use to assess the performances of the model.\n",
    "\n",
    "\n",
    "* n_epochs -> the times the optimization algorithm goes through the entire training data set.\n",
    "\n",
    "\n",
    "* batch_size -> the number of samples included in a single batch.\n",
    "\n",
    "\n",
    "* steps_per_epoch -> the number of batches that form an epoch during the training phase. \n",
    "\n",
    "\n",
    "* vgg_hidden_activation_function -> list containing the name of the activation functions (available in Keras) used in the hidden layers of the densely connected neural network classifier that follows the pretrained VGG19 CNN.\n",
    "\n",
    "\n",
    "* vgg_hidden_layers_neurons -> list containing the number of neurons forming each hidden layer of the densely connected neural network classifier that follows the pretrained VGG19 CNN.\n",
    "\n",
    "\n",
    "* vgg_hidden_layers_L1_coeffs -> list containing scalars multiplying the L1-penalty terms for each hidden layer weights of the densely connected neural network classifier that follows the pretrained VGG19 CNN. Set it to 0 to avoid L1-regularization.\n",
    "\n",
    "\n",
    "* vgg_hidden_layers_L2_coeffs -> list containing scalars multiplying the L2-penalty terms for each hidden layer weights of the densely connected neural network classifier that follows the pretrained VGG19 CNN. Set it to 0 to avoid L2-regularization.\n",
    "\n",
    "\n",
    "* vgg_hidden_layers_dropouts ->  list containing the fractions of weights that are randomly set to zero in each hidden layer of the densely connected neural network classifier that follows the pretrained VGG19 CNN. Set it to 0 to avoid dropout regularization.\n",
    "\n",
    "\n",
    "* vgg_final_activation_function -> name of the activation function (available in Keras) used in the terminal layer of the densely connected neural network classifier that follows the pretrained VGG19 CNN.\n",
    "\n",
    "\n",
    "* vgg_final_layer_neurons -> number of neurons forming the terminal layer of the densely connected neural network classifier that follows the pretrained VGG19 CNN.\n",
    "\n",
    "\n",
    "* vgg_n_epochs -> the times the optimization algorithm goes through the entire training data set when the VGG19 based CNN is trained.\n",
    "\n",
    "\n",
    "* vgg_steps_per_epoch -> the number of batches that form an epoch during the training phase when the VGG19 based CNN is trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1644747503132,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "tAA93Ho8KdCe"
   },
   "outputs": [],
   "source": [
    "training_path                  =  base_dir + \"/train/\"\n",
    "test_path                      =  base_dir + \"/test/\"\n",
    "validation_split               = 0.20\n",
    "regression_problem             = False\n",
    "target_img_shape_1             = 224\n",
    "target_img_shape_2             = 224\n",
    "target_img_channels            = 3\n",
    "conv_layers                    = 4\n",
    "conv_filters                   = [32,64,128,128]   \n",
    "conv_filter_shape              = [[3,3]]*conv_layers\n",
    "conv_activation_function       = ['relu']*conv_layers\n",
    "conv_padding                   = ['valid']*conv_layers\n",
    "conv_pooling_type              = ['max']*conv_layers\n",
    "conv_pooling_shape             = [[2,2]]*conv_layers\n",
    "augment_data                   = True\n",
    "rotation_range                 = 0.1\n",
    "width_shift_range              = 0.1\n",
    "height_shift_range             = 0.1\n",
    "shear_range                    = 0.1\n",
    "brightness_range               = [0.8,1.2]\n",
    "zoom_range                     = 0.1\n",
    "horizontal_flip                = False\n",
    "fill_mode                      = 'nearest'\n",
    "print_sample_input             = True\n",
    "hidden_activation_function     = ['relu']\n",
    "hidden_layers_neurons          = [128]\n",
    "hidden_layers_L1_coeffs        = [0.00]\n",
    "hidden_layers_L2_coeffs        = [0.00]\n",
    "hidden_layers_dropout          = [0.00]\n",
    "final_activation_function      = 'softmax'\n",
    "final_layer_neurons            = 4\n",
    "model_optimizer                = tf.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "loss_function                  = 'categorical_crossentropy'\n",
    "metrics                        = [keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
    "                                  keras.metrics.AUC(multi_label = True, name='multiclass_AUC')]\n",
    "n_epochs                       = 10\n",
    "batch_size                     = 128\n",
    "validation_steps               = 5\n",
    "vgg_include_top                = False\n",
    "vgg_hidden_activation_function = ['relu']\n",
    "vgg_hidden_layers_neurons      = [128]\n",
    "vgg_hidden_layers_L1_coeffs    = [0.00]\n",
    "vgg_hidden_layers_L2_coeffs    = [0.00]\n",
    "vgg_hidden_layers_dropout      = [0.00]\n",
    "vgg_final_activation_function  = 'softmax'\n",
    "vgg_final_layer_neurons        = 4\n",
    "vgg_model_optimizer            = tf.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "vgg_n_epochs                   = 2\n",
    "vgg_validation_steps           = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganize images in a new folder\n",
    "\n",
    "_We transfer the available images in three folders (training, validation, testing)._\n",
    "\n",
    "_We are forced to perfom this action because we want an augmentable training set, a non-augmentable validation set which is drawn from training images and an independent, unseen, test set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62591,
     "status": "ok",
     "timestamp": 1644741798068,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "najuROPkIY4g",
    "outputId": "e3eee898-d18b-4edc-a3f2-3c27ead26e09"
   },
   "outputs": [],
   "source": [
    "labels              = ['MildDemented','ModerateDemented','NonDemented', 'VeryMildDemented']\n",
    "new_training_path   = root_dir + \"/dataset-split/training_set/\"\n",
    "new_validation_path = root_dir + \"/dataset-split/validation_set/\"\n",
    "new_test_path       = root_dir + \"/dataset-split/test_set/\"\n",
    "shutil.rmtree(new_training_path, ignore_errors=True)\n",
    "shutil.rmtree(new_validation_path, ignore_errors=True) \n",
    "shutil.rmtree(new_test_path, ignore_errors=True)\n",
    "[os.makedirs(new_training_path + label,exist_ok=True) for label in labels]\n",
    "[os.makedirs(new_validation_path + label,exist_ok=True) for label in labels]\n",
    "[os.makedirs(new_test_path + label,exist_ok=True) for label in labels]\n",
    "training_label_frequencies   = []\n",
    "for label in labels:\n",
    "        training_filenames   = os.listdir(training_path + label + \"/\") \n",
    "        validation_filenames = random.sample(training_filenames, int(len(training_filenames)*validation_split))\n",
    "        training_filenames   = [file for file in training_filenames if file not in validation_filenames]\n",
    "        test_filenames       = os.listdir(test_path + label + \"/\") \n",
    "        for file in training_filenames:\n",
    "            shutil.copy(training_path + label + \"/\" + file, new_training_path + label + \"/\" + file)\n",
    "        print('Training images transfer complete for label: ' + label + '. # transferred images: ' + str(len(training_filenames)))\n",
    "        for file in validation_filenames:\n",
    "            shutil.copy(training_path + label + \"/\" + file, new_validation_path + label + \"/\" + file)\n",
    "        print('Validation images transfer complete for label: ' + label + '. # transferred images: '  + str(len(validation_filenames)))\n",
    "        for file in test_filenames:\n",
    "            shutil.copy(test_path + label + \"/\" + file, new_test_path + label + \"/\" + file)\n",
    "        print('Test images transfer complete for label: ' + label + '. # transferred images: '  + str(len(test_filenames)))\n",
    "        \n",
    "        training_label_frequencies.append(len(training_filenames))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct class label imbalances\n",
    "\n",
    "_We save copies of existing images belonging to the training data set until the frequencies of the available classes are balanced, e.g., 1/3, 1/3, 1/3 if we have three distinct labels.\n",
    "Later, we will use data augmentation so that even copies of the same image will end up to be different._\n",
    "\n",
    "___NOTE: validation and test images do not undergo any augmentation procedure.___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34859,
     "status": "ok",
     "timestamp": 1644741938621,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "-zylE_w0L3om"
   },
   "outputs": [],
   "source": [
    "training_label_frequencies = np.array(training_label_frequencies)\n",
    "target_n_samples           = np.max(training_label_frequencies)\n",
    "for i in range(len(labels)):\n",
    "    current_label     = labels[i]\n",
    "    n_missing_samples = target_n_samples - training_label_frequencies[i]\n",
    "    filenames         = os.listdir(new_training_path + current_label + \"/\") \n",
    "    n_filled          = np.zeros(len(filenames))\n",
    "    while (np.sum(n_filled) < n_missing_samples):\n",
    "          idx = np.random.randint(0,len(filenames))\n",
    "          shutil.copy(new_training_path + current_label + \"/\" + filenames[idx], new_training_path + current_label + \"/\" + filenames[idx].replace(\".jpg\", \"_copy_\" + str(int(n_filled[idx] + 1)) + \".jpg\"))\n",
    "          n_filled[idx] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training and test images\n",
    "\n",
    "_We create three distinct generators (training, validation, test) that we will use later to train and assess the model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1385,
     "status": "ok",
     "timestamp": 1644741989610,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "pLVsQVv5L3rS",
    "outputId": "4020b086-ed4f-47e9-b02f-24fe805dd0b1"
   },
   "outputs": [],
   "source": [
    "if augment_data:\n",
    "    train_datagen   = keras.preprocessing.image.ImageDataGenerator(rescale            = 1./255,\n",
    "                                         rotation_range     = rotation_range,\n",
    "                                         width_shift_range  = width_shift_range,\n",
    "                                         height_shift_range = height_shift_range,\n",
    "                                         shear_range        = shear_range,\n",
    "                                         brightness_range   = brightness_range,\n",
    "                                         zoom_range         = zoom_range,\n",
    "                                         horizontal_flip    = horizontal_flip,\n",
    "                                         fill_mode          = fill_mode)\n",
    "else:\n",
    "    train_datagen   = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "validation_datagen   = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen         = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "train_generator      = train_datagen.flow_from_directory(new_training_path,target_size = (target_img_shape_1, target_img_shape_2), batch_size = batch_size, class_mode = \"categorical\")  \n",
    "validation_generator = validation_datagen.flow_from_directory(new_validation_path,target_size = (target_img_shape_1, target_img_shape_2), batch_size = batch_size, class_mode = \"categorical\") \n",
    "test_generator       = test_datagen.flow_from_directory(new_test_path,target_size = (target_img_shape_1, target_img_shape_2), batch_size = batch_size, class_mode = \"categorical\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display some sample images\n",
    "\n",
    "Credits to Amy Jang, see https://www.kaggle.com/amyjang/tensorflow-pneumonia-classification-on-x-rays/notebook#5.-Correct-for-data-imbalance [[Reference]](https://www.kaggle.com/amyjang/tensorflow-pneumonia-classification-on-x-rays/notebook#5.-Correct-for-data-imbalance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1vp8BYVfBukUKfbOndknqDt213VVgruO6"
    },
    "executionInfo": {
     "elapsed": 9330,
     "status": "ok",
     "timestamp": 1644742006034,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "IJYv_5WTL3t6",
    "outputId": "c037e34f-a9c8-48ed-c151-670d5d36403f"
   },
   "outputs": [],
   "source": [
    "if print_sample_input:\n",
    "    display_input_images(train_generator, 2, batch_size, [8,5], [30,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display basic information on train and test images\n",
    "\n",
    "_We use the function \"dataset_basic_info()\" to display some basic information, e.g., # samples, image shape, labels frequencies, for each dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1644742008414,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "C365LRbHL3wI",
    "outputId": "e38d6b8f-fd92-4eb1-dfd7-db63647b77d8"
   },
   "outputs": [],
   "source": [
    "train_labels_weights_dict      = dataset_basic_info(train_generator, 'training')\n",
    "validation_labels_weights_dict = dataset_basic_info(validation_generator, 'validation')\n",
    "test_labels_weights_dict       = dataset_basic_info(test_generator, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Convolutional Neural Network (CNN) model\n",
    "\n",
    "_The input parameters set by the user serve as arguments of a function which returns a Keras model object of a convolutional neural network._\n",
    "\n",
    "![1_vkQ0hXDaQv57sALXAJquxA.jpg](https://miro.medium.com/max/1400/1*vkQ0hXDaQv57sALXAJquxA.jpeg)\n",
    "\n",
    "_Schematics of the typical structure of a neural network model for image recognition._\n",
    "\n",
    "_Image source:_ https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n",
    "\n",
    "[[Reference]](#A-Comprehensive-Guide-to-Convolutional-Neural-Networks-—-the-ELI5-way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1644742012529,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "ii1nhbcMN2Zt",
    "outputId": "f84dea97-a3f2-48c5-c377-13714953fc06"
   },
   "outputs": [],
   "source": [
    "diy_model_2 = build_model_cnn(regression_problem, conv_filters, conv_filter_shape, conv_activation_function, conv_padding, conv_pooling_type, conv_pooling_shape, hidden_layers_neurons, hidden_activation_function, \n",
    "                             hidden_layers_L1_coeffs, hidden_layers_L2_coeffs, hidden_layers_dropout, final_layer_neurons, final_activation_function, [target_img_shape_1, target_img_shape_2, target_img_channels], \n",
    "                             model_optimizer, loss_function, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1644594977594,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "kFl1PNZnevhi",
    "outputId": "a652e2aa-1200-4040-b653-7a77e5b98942"
   },
   "source": [
    "### Let's fit our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3750736,
     "status": "error",
     "timestamp": 1644746506382,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "c4LAG5UWN2dE",
    "outputId": "36d03a99-363f-4831-babe-aaf37d82f7ba"
   },
   "outputs": [],
   "source": [
    "early_exit      = EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='min')\n",
    "best_checkpoint = ModelCheckpoint(root_dir + \"models/model-diy-2-1/alzheimer_model-diy-2-1.h5\",\n",
    "                                  save_best_only=True, \n",
    "                                  monitor='val_multiclass_AUC', \n",
    "                                  mode='max')\n",
    "\n",
    "hst = diy_model_2.fit(train_generator, steps_per_epoch = train_generator.samples//batch_size,\n",
    "                      epochs = n_epochs,\n",
    "                      validation_data = validation_generator,\n",
    "                      validation_steps = validation_generator.samples//batch_size,\n",
    "                      callbacks =[early_exit, best_checkpoint])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1644746802356,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "wphr65-cjG9s"
   },
   "outputs": [],
   "source": [
    "diy_model_2.load_weights(filepath = root_dir + \"models/model-diy-2-1/alzheimer_model-diy-2-1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1644746828523,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "2bCe4t7BYjHr"
   },
   "outputs": [],
   "source": [
    "save_model(diy_model_2, \"models/diy_model_2_2022_02_13_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model - Analyze the performance of the model\n",
    "\n",
    "_We display three different metrics to assess the performances of the model._\n",
    "\n",
    "1. `loss`                  -> the value of the loss function in each epoch.\n",
    "\n",
    "\n",
    "2. `categorical accuracy`  -> \"Calculates how often predictions matches one-hot labels.\", see https://www.tensorflow.org/api_docs/python/tf/keras/metrics/categorical_accuracy [[Reference]](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/categorical_accuracy)\n",
    "\n",
    "\n",
    "3. `multiclass_AUC`        -> \"Computes the approximate AUC (Area under the curve) via a Riemann sum for each label and then takes the average.\", see https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC [[Reference]](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC)\n",
    "\n",
    "_These metrics are recorded at the end of each training epoch and plotted in epoch vs. metric diagrams. Red lines represent the pattern of these metrics during training while blue lines represent the pattern of these metrics during the validation phase._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "executionInfo": {
     "elapsed": 1138,
     "status": "ok",
     "timestamp": 1644746857627,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "ARirp9OZN2gU",
    "outputId": "8d8ec595-0274-40ca-aeb5-32b79b657a05"
   },
   "outputs": [],
   "source": [
    "analyze_performances(hst, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model - Classify the test images\n",
    "\n",
    "_We use our trained convolutional neural network to predict the labels of previously unseen images contained in the test folder._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 108333,
     "status": "ok",
     "timestamp": 1644746966219,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "TKrNoZeJN2jR",
    "outputId": "b6356706-7b0d-44e8-b19f-83b6c6d6b53e"
   },
   "outputs": [],
   "source": [
    "model_evaluation(diy_model_2, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3PZ6um8U1T4"
   },
   "source": [
    "___Well these results do not look as good as expected, the `Accuracy` is very low.___\n",
    "\n",
    "___This is to be expected considering the sacrifices we have had to make and reduce our hyperparameters with Google Colab training.___\n",
    "\n",
    "___However these results are better than our previous experiments and we can use this architecture as a base, and to change and try and improve it.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building DIY model MK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3PZ6um8U1T4"
   },
   "source": [
    "_Let's try and improve this architecture and our model by adding more image augmentations as mentioned as one of our ideas in the [Abstract](#Abstract) section._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3PZ6um8U1T4"
   },
   "source": [
    "_Let's defines some custom augmentations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1644751247180,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "oyZ_IpB6y889",
    "outputId": "b892a0a8-2ff9-49e6-c511-609dbe485fa4"
   },
   "outputs": [],
   "source": [
    "data_random_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\", seed=42),\n",
    "  layers.RandomRotation(0.2, seed=42),\n",
    "  layers.RandomContrast(0.9, seed=42),\n",
    "  layers.RandomCrop(4, 4, seed=42),\n",
    "  layers.RandomZoom(0.6, seed=42),\n",
    "])\n",
    "\n",
    "print(data_random_augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3PZ6um8U1T4"
   },
   "source": [
    "_We are going to add our custom augmentations our model architecture._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1644751503521,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "e0x8iW1qyrSs"
   },
   "outputs": [],
   "source": [
    "def build_model_cnn_custom(regression_problem, conv_filters, conv_filter_shape, conv_activation_function, conv_padding, conv_pooling_type, conv_pooling_shape, hidden_layers_neurons, hidden_activation_function, L1_coeffs, L2_coeffs, hidden_layers_dropout, final_layer_neurons, final_activation_function, shape, model_optimizer, loss_function, metrics):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(data_random_augmentation)\n",
    "    \n",
    "    for i in range(len(conv_activation_function)):\n",
    "        \n",
    "        if (i == 0):\n",
    "            model.add(layers.Conv2D(conv_filters[i],\n",
    "                                    (conv_filter_shape[i][0],conv_filter_shape[i][1]), \n",
    "                                    activation = conv_activation_function[i], \n",
    "                                    padding    = conv_padding[i],\n",
    "                                    input_shape = (shape[0],shape[1],shape[2])))             \n",
    "        else:\n",
    "            model.add(layers.Conv2D(conv_filters[i],\n",
    "                                    (conv_filter_shape[i][0],conv_filter_shape[i][1]), \n",
    "                                    activation = conv_activation_function[i],\n",
    "                                    padding    = conv_padding[i]))\n",
    "        \n",
    "        if (conv_pooling_type[i] == 'max'):\n",
    "            model.add(layers.MaxPooling2D((conv_pooling_shape[i][0],conv_pooling_shape[i][1])))\n",
    "        elif (conv_pooling_type[i] == 'avg'):\n",
    "            model.add(layers.AveragePooling2D((conv_pooling_shape[i][0],conv_pooling_shape[i][1])))\n",
    "        else:\n",
    "            'no pooling'\n",
    "            \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    for i in range(len(hidden_activation_function)):\n",
    "\n",
    "        model.add(layers.Dense(hidden_layers_neurons[i], \n",
    "                               kernel_regularizer = regularizers.l1_l2(l1 = L1_coeffs[i], l2 =  L2_coeffs[i]),  \n",
    "                               activation=hidden_activation_function[i]))\n",
    "        if (hidden_layers_dropout[i] > 0.0):\n",
    "            model.add(layers.Dropout(hidden_layers_dropout[i]))\n",
    "    if regression_problem:\n",
    "            model.add(layers.Dense(final_layer_neurons))\n",
    "    else:\n",
    "            model.add(layers.Dense(final_layer_neurons,activation = final_activation_function))\n",
    "            \n",
    "    model.compile(optimizer = model_optimizer, loss = loss_function, metrics = metrics)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93WDD7TSU1Xc"
   },
   "source": [
    "_Let's build and check our new diy custom model architecture._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1644751554601,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "HWUuw4CO1Ieo",
    "outputId": "764c2497-aac1-4bf0-dbdd-4abc38b0c504"
   },
   "outputs": [],
   "source": [
    "diy_model_2_custom = build_model_cnn_custom(regression_problem, conv_filters, conv_filter_shape, conv_activation_function, conv_padding, conv_pooling_type, conv_pooling_shape, hidden_layers_neurons, hidden_activation_function, \n",
    "                             hidden_layers_L1_coeffs, hidden_layers_L2_coeffs, hidden_layers_dropout, final_layer_neurons, final_activation_function, [target_img_shape_1, target_img_shape_2, target_img_channels], \n",
    "                             model_optimizer, loss_function, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1644594977594,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "kFl1PNZnevhi",
    "outputId": "a652e2aa-1200-4040-b653-7a77e5b98942"
   },
   "source": [
    "#### Let's fit our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3707804,
     "status": "ok",
     "timestamp": 1644755705688,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "1d6dShFTU1a8",
    "outputId": "14ce1075-6862-4914-9aa1-12a871ba623b"
   },
   "outputs": [],
   "source": [
    "early_exit      = EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='min')\n",
    "best_checkpoint = ModelCheckpoint(root_dir + \"models/model-diy-2-custom-1/alzheimer_model-diy-2-1.h5\",\n",
    "                                  save_best_only=True, \n",
    "                                  monitor='val_multiclass_AUC', \n",
    "                                  mode='max')\n",
    "\n",
    "hst_custom = diy_model_2_custom.fit(train_generator, steps_per_epoch = train_generator.samples//batch_size,\n",
    "                      epochs = n_epochs,\n",
    "                      validation_data = validation_generator,\n",
    "                      validation_steps = validation_generator.samples//batch_size,\n",
    "                      callbacks =[early_exit, best_checkpoint])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1644755705962,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "wn0gZH5O1oGq"
   },
   "outputs": [],
   "source": [
    "diy_model_2_custom.load_weights(filepath = root_dir + \"models/model-diy-2-custom-1/alzheimer_model-diy-2-1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1644755706224,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "yg5LULuX1oGy"
   },
   "outputs": [],
   "source": [
    "save_model(diy_model_2_custom, \"models/diy_model_2_custom_2022_02_13_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model - Analyze the performance of the model\n",
    "\n",
    "_We display three different metrics to assess the performances of the model._\n",
    "\n",
    "1. `loss`                  -> the value of the loss function in each epoch.\n",
    "\n",
    "\n",
    "2. `categorical accuracy`  -> \"Calculates how often predictions matches one-hot labels.\", see https://www.tensorflow.org/api_docs/python/tf/keras/metrics/categorical_accuracy [[Reference]](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/categorical_accuracy)\n",
    "\n",
    "\n",
    "3. `multiclass_AUC`        -> \"Computes the approximate AUC (Area under the curve) via a Riemann sum for each label and then takes the average.\", see https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC [[Reference]](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC)\n",
    "\n",
    "_These metrics are recorded at the end of each training epoch and plotted in epoch vs. metric diagrams. Red lines represent the pattern of these metrics during training while blue lines represent the pattern of these metrics during the validation phase._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "executionInfo": {
     "elapsed": 750,
     "status": "ok",
     "timestamp": 1644755706971,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "-7yMaXgy1oGz",
    "outputId": "218d9b15-e1d7-4498-89ed-05684afa98ad"
   },
   "outputs": [],
   "source": [
    "analyze_performances(hst_custom, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model - Classify the test images\n",
    "\n",
    "_We use our trained convolutional neural network to predict the labels of previously unseen images contained in the test folder._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 88850,
     "status": "ok",
     "timestamp": 1644755795814,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "RdtGHnvr1oGz",
    "outputId": "28f583f8-5e09-4660-9557-edd3bb74686e"
   },
   "outputs": [],
   "source": [
    "model_evaluation(diy_model_2_custom, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building DIY model MK2 - Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1644751554601,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "HWUuw4CO1Ieo",
    "outputId": "764c2497-aac1-4bf0-dbdd-4abc38b0c504"
   },
   "outputs": [],
   "source": [
    "diy_model_3_custom = build_model_cnn_custom(regression_problem, conv_filters, conv_filter_shape, conv_activation_function, conv_padding, conv_pooling_type, conv_pooling_shape, hidden_layers_neurons, hidden_activation_function, \n",
    "                             hidden_layers_L1_coeffs, hidden_layers_L2_coeffs, hidden_layers_dropout, final_layer_neurons, final_activation_function, [target_img_shape_1, target_img_shape_2, target_img_channels], \n",
    "                             model_optimizer, loss_function, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_exit      = EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='min')\n",
    "best_checkpoint = ModelCheckpoint(root_dir + \"models/diy_model_3_custom/alzheimer_model-diy-2-1.h5\",\n",
    "                                  save_best_only=True, \n",
    "                                  monitor='val_multiclass_AUC', \n",
    "                                  mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_board_cb_1 = TensorBoard(log_dir = root_dir + \"logs/logs-(experiment_id)-(run_id)\",\n",
    "                                write_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PksTy0_gL32J"
   },
   "outputs": [],
   "source": [
    "experiment_id = mlflow.create_experiment(\"diy_model_3_custom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3707804,
     "status": "ok",
     "timestamp": 1644755705688,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "1d6dShFTU1a8",
    "outputId": "14ce1075-6862-4914-9aa1-12a871ba623b"
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id = experiment_id) as run:\n",
    "    mlfow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "\n",
    "    run_id = mlflow.active_run().infor.run_id\n",
    "\n",
    "    hst_diy_model_3_custom = diy_model_3_custom.fit(train_generator,\n",
    "                                                    steps_per_epoch = train_generator.samples//batch_size,\n",
    "                                                    epochs = n_epochs,\n",
    "                                                    validation_data = validation_generator,\n",
    "                                                    validation_steps = validation_generator.samples//batch_size,\n",
    "                                                    callbacks =[early_exit, best_checkpoint,tensor_board_cb_1])\n",
    "    \n",
    "    mlfow.log_param(\"history\", hst_diy_model_3_custom)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9IlKhGFIY7T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MH3Vh09ZIY9w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1644755705962,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "wn0gZH5O1oGq"
   },
   "outputs": [],
   "source": [
    "diy_model_3_custom.load_weights(filepath = root_dir + \"models/diy_model_3_custom/alzheimer_model-diy-2-1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1644755706224,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "yg5LULuX1oGy"
   },
   "outputs": [],
   "source": [
    "save_model(diy_model_3_custom, \"models/diy_model_3_custom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "executionInfo": {
     "elapsed": 750,
     "status": "ok",
     "timestamp": 1644755706971,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "-7yMaXgy1oGz",
    "outputId": "218d9b15-e1d7-4498-89ed-05684afa98ad"
   },
   "outputs": [],
   "source": [
    "analyze_performances(hst_diy_model_3_custom, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 88850,
     "status": "ok",
     "timestamp": 1644755795814,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "RdtGHnvr1oGz",
    "outputId": "28f583f8-5e09-4660-9557-edd3bb74686e"
   },
   "outputs": [],
   "source": [
    "model_evaluation(diy_model_3_custom, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--lo3rFHPrjb"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Clouds idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv7C9DnUU1eM"
   },
   "source": [
    "_Let's try one of our ideas mentioned in the [Abstract](#Abstract) section._\n",
    "\n",
    "_Let's make and experiment and try turn the medical 2D images in 3D images using `point clouds` and then using the new 3D images to train the model. A 3D view of a disease in the brain such as Alzheimer's Disease might give additional insights to the model which it has been previously missing._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv7C9DnUU1eM"
   },
   "source": [
    "_You can also find the `pointcloud-experiment-notebooks` folder with some draft work on this idea, in the `Google Drive` shared folder for this project in the relevant section. This folder also includes the resulting `point cloud` file from this experiment._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Here is a function which I found on the internet for [How-to-create-a-3D-image-with-series-of-2D-Image](#How-to-create-a-3D-image-with-series-of-2D-Image) [[Reference]](#How-to-create-a-3D-image-with-series-of-2D-Image). Let's try and use it._\n",
    "\n",
    "_Below is the slightly modified version of the function, I had to adapt it and there were also a few broken, outdated bits that needed fixing._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_In this case I have made just a sample dataset for the experiment with this function in the `dataset-4-aug` directory._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Give the below function some time, it takes about 15 min to run in Google Colab.___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./\"\n",
    "work_base_dir = root_dir + \"dataset-4-aug/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# creates a point cloud file (.ply) from numpy array\n",
    "def createPointCloud(filename, arr):\n",
    "    # open file and write boilerplate header\n",
    "    file = open(filename, 'w');\n",
    "    file.write(\"ply\\n\");\n",
    "    file.write(\"format ascii 1.0\\n\");\n",
    "\n",
    "    # count number of vertices\n",
    "    num_verts = arr.shape[0];\n",
    "    file.write(\"element vertex \" + str(num_verts) + \"\\n\");\n",
    "    file.write(\"property float32 x\\n\");\n",
    "    file.write(\"property float32 y\\n\");\n",
    "    file.write(\"property float32 z\\n\");\n",
    "    file.write(\"end_header\\n\");\n",
    "\n",
    "    # write points\n",
    "    point_count = 0;\n",
    "    for point in arr:\n",
    "        # progress check\n",
    "        point_count += 1;\n",
    "        if point_count % 1000 == 0:\n",
    "            print(\"Point: \" + str(point_count) + \" of \" + str(len(arr)));\n",
    "\n",
    "        # create file string\n",
    "        out_str = \"\";\n",
    "        for axis in point:\n",
    "            out_str += str(axis) + \" \";\n",
    "        out_str = out_str[:-1]; # dump the extra space\n",
    "        out_str += \"\\n\";\n",
    "        file.write(out_str);\n",
    "    file.close();\n",
    "\n",
    "\n",
    "# extracts points from mask and adds to list\n",
    "def addPoints(mask, points_list, depth):\n",
    "    mask_points = np.where(mask == 255);\n",
    "    for ind in range(len(mask_points[0])):\n",
    "        # get point\n",
    "        x = mask_points[1][ind];\n",
    "        y = mask_points[0][ind];\n",
    "        point = [x,y,depth];\n",
    "        points_list.append(point);\n",
    "\n",
    "def main():\n",
    "    # tweakables\n",
    "    slice_thickness = .2; # distance between slices\n",
    "    xy_scale = 1; # rescale of xy distance\n",
    "\n",
    "    # load images\n",
    "    folder = work_base_dir;\n",
    "    files = os.listdir(folder);\n",
    "    images = [];\n",
    "    for file in files:\n",
    "#         if file[-4:] == \".tif\":\n",
    "        if file[-4:] == \".jpg\":\n",
    "#         if(type(file) == type(None)):\n",
    "#             print(folder + file)\n",
    "            img = cv2.imread(folder + file, cv2.IMREAD_GRAYSCALE);\n",
    "            img = cv2.resize(img, (100, 100)); # change here for more or less resolution\n",
    "            images.append(img);\n",
    "\n",
    "    # keep a blank mask\n",
    "    blank_mask = np.zeros_like(images[0], np.uint8);\n",
    "\n",
    "    # create masks\n",
    "    masks = [];\n",
    "    masks.append(blank_mask);\n",
    "    for image in images:\n",
    "        # mask\n",
    "        mask = cv2.inRange(image, 0, 100);\n",
    "\n",
    "        # show\n",
    "        cv2.imshow(\"Mask\", mask);\n",
    "        cv2.waitKey(1);\n",
    "        masks.append(mask);\n",
    "    masks.append(blank_mask);\n",
    "    cv2.destroyAllWindows();\n",
    "\n",
    "    # go through and get points\n",
    "    depth = 0;\n",
    "    points = [];\n",
    "    for index in range(1,len(masks)-1):\n",
    "        # progress check\n",
    "        print(\"Index: \" + str(index) + \" of \" + str(len(masks)));\n",
    "\n",
    "        # get three masks\n",
    "        prev = masks[index - 1];\n",
    "        curr = masks[index];\n",
    "        after = masks[index + 1];\n",
    "\n",
    "        # do a slice on previous\n",
    "        prev_mask = np.zeros_like(curr);\n",
    "        prev_mask[prev == 0] = curr[prev == 0];\n",
    "        addPoints(prev_mask, points, depth);\n",
    "\n",
    "        # # do a slice on after\n",
    "        next_mask = np.zeros_like(curr);\n",
    "        next_mask[after == 0] = curr[after == 0];\n",
    "        addPoints(next_mask, points, depth);\n",
    "\n",
    "        # get contour points (_, contours) in OpenCV 2.* or 4.*\n",
    "        # cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE\n",
    "#         _, contours, _ = cv2.findContours(curr, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE);\n",
    "        contours, _ = cv2.findContours(curr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE);        \n",
    "        for con in contours:\n",
    "            for point in con:\n",
    "                p = point[0]; # contours have an extra layer of brackets\n",
    "                points.append([p[0], p[1], depth]);\n",
    "\n",
    "        # increment depth\n",
    "        depth += slice_thickness;\n",
    "\n",
    "    # rescale x,y points\n",
    "    for ind in range(len(points)):\n",
    "        # unpack\n",
    "        x,y,z = points[ind];\n",
    "\n",
    "        # scale\n",
    "        x *= xy_scale;\n",
    "        y *= xy_scale;\n",
    "        points[ind] = [x,y,z];\n",
    "\n",
    "    # convert points to numpy and dump duplicates\n",
    "    points = np.array(points).astype(np.float32);\n",
    "    points = np.unique(points.reshape(-1, points.shape[-1]), axis=0);\n",
    "    print(points.shape);\n",
    "\n",
    "    # save to point cloud file\n",
    "    createPointCloud(\"./pointcloud-experiment-notebooks/test.ply\", points);\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyntcloud import PyntCloud\n",
    "\n",
    "pyCloud1 = PyntCloud.from_file(\"./pointcloud-experiment-notebooks/test.ply\")\n",
    "\n",
    "pyCloud1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_After putting a lot of images in the sample dataset used for this function I was hoping to get a 3D point cloud resembling a brain, however the current plot does not look like what I was expecting._\n",
    "\n",
    "_Maybe there are too many images and fewer need to be used._\n",
    "\n",
    "_Because debugging this function in Google Colab is slow, I will leave this to be developed as as future improvement of this work._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2tGt6luPrjc"
   },
   "source": [
    "### Point clouds idea additional resources\n",
    "\n",
    "_Here are some additional resources to try and help with the further development of this idea:_\n",
    "\n",
    "- [How-to-create-a-3D-image-with-series-of-2D-Image](#How-to-create-a-3D-image-with-series-of-2D-Image) [[Reference]](#How-to-create-a-3D-image-with-series-of-2D-Image)\n",
    "\n",
    "https://stackoverflow.com/questions/66699525/how-to-create-a-3d-image-with-series-of-2d-image\n",
    "\n",
    "\n",
    "- [How to convert 2D DICOM slices to 3D image in Python](#How-to-convert-2D-DICOM-slices-to-3D-image-in-Python)\n",
    "\n",
    "https://stackoverflow.com/questions/56723891/how-to-convert-2d-dicom-slices-to-3d-image-in-python\n",
    "\n",
    "\n",
    "- [pydicom](#pydicom)\n",
    "\n",
    "https://github.com/pydicom/pydicom\n",
    "\n",
    "\n",
    "- [Numpy 2D image to 3D](#Numpy-2D-image-to-3D)\n",
    "\n",
    "<https://stackoverflow.com/questions/67178372/numpy-2d-image-to-3d>\n",
    "\n",
    "\n",
    "- [Numpy point cloud to image](#Numpy-point-cloud-to-image)\n",
    "\n",
    "<https://stackoverflow.com/questions/60646028/numpy-point-cloud-to-image>\n",
    "\n",
    "\n",
    "- [Convert XYZ point cloud to grayscale image](#Convert-XYZ-point-cloud-to-grayscale-image)\n",
    "\n",
    "<https://stackoverflow.com/questions/53700089/convert-xyz-point-cloud-to-grayscale-image>\n",
    "\n",
    "\n",
    "- [Generate point cloud from depth image](#Generate-point-cloud-from-depth-image)\n",
    "\n",
    "<https://stackoverflow.com/questions/59590200/generate-point-cloud-from-depth-image>\n",
    "\n",
    "\n",
    "- [Guide to real-time visualisation of massive 3D point clouds in Python](#Guide-to-real-time-visualisation-of-massive-3D-point-clouds-in-Python)\n",
    "\n",
    "<https://towardsdatascience.com/guide-to-real-time-visualisation-of-massive-3d-point-clouds-in-python-ea6f00241ee0>\n",
    "\n",
    "\n",
    "- [Coverting point cloud data (.ply) into a range image](#Coverting-point-cloud-data-(.ply)-into-a-range-image)\n",
    "\n",
    "<https://stackoverflow.com/questions/65614088/coverting-point-cloud-data-ply-into-a-range-image>\n",
    "\n",
    "\n",
    "- [Python - Display 3D Point Cloud [closed]](#Python---Display-3D-Point-Cloud-[closed])\n",
    "\n",
    "<https://stackoverflow.com/questions/50965673/python-display-3d-point-cloud>\n",
    "\n",
    "\n",
    "- [Python plyfile vs pymesh](#Python-plyfile-vs-pymesh)\n",
    "\n",
    "<https://stackoverflow.com/questions/36920562/python-plyfile-vs-pymesh>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMfVy9a8Prjb"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzZiUIFaPrjb"
   },
   "source": [
    "## 3D Photo Inpainting idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_My next idea is instead of using point clouds, to use a technique, like the one described in this article [3D-Photo-Inpainting---Turn-Any-Picture-Into-3D-Photo-with-Deep-Learning-and-Python](https://curiousily.com/posts/3d-photo-inpainting-turn-any-picture-into-3d-photo-with-deep-learning-and-python/) [[Reference]](#3D-Photo-Inpainting---Turn-Any-Picture-Into-3D-Photo-with-Deep-Learning-and-Python) to try and get a 3D perspective of the medical images with the help of `estimated depth` images._\n",
    "\n",
    "_The idea was once we get the `estimated depth` images to feed them to a CNN and train a new model, and see if these images improve it._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Here a couple of images as examples from the article [3D-Photo-Inpainting---Turn-Any-Picture-Into-3D-Photo-with-Deep-Learning-and-Python](https://curiousily.com/posts/3d-photo-inpainting-turn-any-picture-into-3d-photo-with-deep-learning-and-python/) [[Reference]](#3D-Photo-Inpainting---Turn-Any-Picture-Into-3D-Photo-with-Deep-Learning-and-Python):_\n",
    "\n",
    "- _Original image:_\n",
    "\n",
    "![demo_inpainting.jpg](./resources/images/demo_inpainting.jpg)\n",
    "\n",
    "[[Reference]](#3D-Photo-Inpainting---Turn-Any-Picture-Into-3D-Photo-with-Deep-Learning-and-Python)\n",
    "\n",
    "- _Estimated depth image:_\n",
    "\n",
    "![dog_depth.png](./resources/images/dog_depth.png)\n",
    "\n",
    "[[Reference]](#3D-Photo-Inpainting---Turn-Any-Picture-Into-3D-Photo-with-Deep-Learning-and-Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMfVy9a8Prjb"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzZiUIFaPrjb"
   },
   "source": [
    "## 3D Convolutional Neural Network idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_My next idea from the [Abstract](#Abstract) section, is following my previous two ideas - once you have the 3D versions of the medical images or 3D point clouds, or estimated depth images from 3D picture impainting by converting a 2D image to a 3D one, feed those images to a 3D Convolutional Neural Network._\n",
    "\n",
    "_Below is an example of such 3D CNN from this article [Step by Step Implementation: 3D Convolutional Neural Network in Keras](https://towardsdatascience.com/step-by-step-implementation-3d-convolutional-neural-network-in-keras-12efbdd7b130)._\n",
    "\n",
    "[[Reference]](#Step-by-Step-Implementation:-3D-Convolutional-Neural-Network-in-Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "452pU2OBPrjd"
   },
   "source": [
    "_The code below is just an example, its not meant to be ran as part of this notebook, its more like pseudo code, of what a potential 3D Convolutional Neural Network architecture could look like._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   #if like me you do not have a lot of memory in your GPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" #then these two lines force keras to use your CPU\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "a3Dmodel = Sequential()\n",
    "a3Dmodel.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape))\n",
    "a3Dmodel.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "a3Dmodel.add(BatchNormalization(center=True, scale=True))\n",
    "a3Dmodel.add(Dropout(0.5))\n",
    "a3Dmodel.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "a3Dmodel.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "a3Dmodel.add(BatchNormalization(center=True, scale=True))\n",
    "a3Dmodel.add(Dropout(0.5))\n",
    "a3Dmodel.add(Flatten())\n",
    "a3Dmodel.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "a3Dmodel.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "a3Dmodel.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "a3Dmodel.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "a3Dmodel.summary()\n",
    "# Fit data to model\n",
    "a3Dmodel_history = model.fit(X_train, targets_train,\n",
    "            batch_size=128,\n",
    "            epochs=40,\n",
    "            verbose=1,\n",
    "            validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLlzNLodPrjc"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJkxsG2OPrjd"
   },
   "source": [
    "## Further development\n",
    "\n",
    "_Because of all of the Google Colab limitations, impediments, pain and frustration I was not able to implement all ideas mentioned in the [Abstract](#Abstract) section._\n",
    "\n",
    "_However I think we have demonstrated the concepts we set out to demonstrate and have proven that the overall concept works. Therefore I think this article can be further developed in one or more of the following ways, implementing said ideas._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWX6CHzYPrjc"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYuwBVITPrjc"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJnQiRCkPrje"
   },
   "source": [
    "_While carrying out the work and experiments in this notebook, we have achieved at least one of our main goals - to understand and demonstrate some Deep Learning (DL) basics, more specifically to understand Neural Networks (NNs) and how to improve them, so we can create models, train them, test them and extract predictions, classifications and information we might be interested in._\n",
    "\n",
    "_We have demonstrated some of the following basic but key concepts of Deep Learning:_\n",
    "\n",
    "- _Convolutional Neural Network_\n",
    "\n",
    "\n",
    "- _Building a Neural Network architecture_\n",
    "\n",
    "\n",
    "- _Compiling a model with optimizers and loss functions_\n",
    "\n",
    "\n",
    "- _Training a model_\n",
    "\n",
    "\n",
    "- _Evaluating a model_\n",
    "\n",
    "\n",
    "- _Improving a model with Transfer Learning_\n",
    "\n",
    "\n",
    "- _etc._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YmsOI8YPrjc"
   },
   "source": [
    "_Because of all of the Google Colab limitations, impediments, pain and frustration I was not able to implement all ideas mentioned in the [Abstract](#Abstract) section._ _Because of these I was not able to achieve the desired state of the art metric scores and demonstrate that the architectures and models are suitable for medical disease classifications, such as Alzheimer's disease in our case._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbEv8v3qPrjd"
   },
   "source": [
    "*Thus we can say that, using the scientific method, we have not rejected our [Null Hypothesis $(H_{0})$](#Null-hypothesis-$(H_{0})$) and we have not proved our [Alternative Hypothesis $(H_{1})$](#Alternative-hypothesis-$(H_{1})$) with the experiments carried out of training and then testing different Deep Learning algorithms, architectures and models, and seeing if they achieve state of the art accuracy and AUROC metrics which make them reliable for disease prediction and classification.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FLxkG1ePrje"
   },
   "source": [
    "_That said, there is definitely hope and potential in this project. Judging by the results achieve in this paper, MULTI-DISEASE DETECTION IN RETINAL IMAGING BASED ON ENSEMBLING HETEROGENEOUS DEEP LEARNING MODELS [[Reference]](#MULTI-DISEASE-DETECTION-IN-RETINAL-IMAGING-PDF), where they have achieved **\"AUROC of 0.95 for the disease risk classification\"** means that in a proper environment, with sufficient computing power we can achieve the same or better results._\n",
    "\n",
    "_Furthermore in this notebook, [CNN-Alzheimer-MRI-images](#CNN-Alzheimer-MRI-images), it is stated - **\"In this experiment, our model achieves very satisfactory accuracy levels, i.e., > 99%, in predicting the state of previously unseen MRI brain images.\"** [[Reference]](#CNN-Alzheimer-MRI-images), which is also very encouraging._\n",
    "\n",
    "_Having said that further research, work, improvements and implementations of the ideas in this paper, and all referenced papers should be carried out._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CzsP5OsPrjd"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHyNV6dsPrjd"
   },
   "source": [
    "## Appendix A<a id=\"AppendixA\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gj0morZSPrjd"
   },
   "source": [
    "### Glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFMWiSzbPrjd"
   },
   "source": [
    "- DL - Deep Learning\n",
    "- NN - Neural Network\n",
    "- CNN - Convolutional Neural Network\n",
    "- EDA - exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEpO4u78Prjd"
   },
   "source": [
    "### Table of Contents\n",
    "\n",
    "*In order to use a Table of Contents for this article, please use the `toc2` extension from `Nbextensions` for Jupyter Notebook. You can find instructions on how to install and use it in this <a href=\"https://stackoverflow.com/questions/21151450/how-can-i-add-a-table-of-contents-to-a-jupyter-jupyterlab-notebook\">link</a>.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7cPb6JPPrje"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnwoUE51Prje"
   },
   "source": [
    "## References <a id=\"ReferencesSection\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3DquVFFPrje"
   },
   "source": [
    "\n",
    "### mri_image_classification_using_transfer_learning\n",
    "<https://www.kaggle.com/youssefgdv/mri-image-classification-using-transfer-learning/notebook>\n",
    "\n",
    "### Alzheimer's Disease Classification - InceptionV3\n",
    "<https://www.kaggle.com/youssefgdv/alzheimer-s-disease-classification-inceptionv3/notebook>\n",
    "\n",
    "### Alzheimer MRI Model + TensorFlow 2.3 Data Loading\n",
    "<https://www.kaggle.com/amyjang/alzheimer-mri-model-tensorflow-2-3-data-loading/notebook>\n",
    "\n",
    "### TensorFlow Pneumonia Classification on X-rays\n",
    "<https://www.kaggle.com/amyjang/tensorflow-pneumonia-classification-on-x-rays>\n",
    "\n",
    "### CNN Alzheimer MRI images\n",
    "<https://www.kaggle.com/albertociacci/cnn-alzheimer-mri-images/notebook>\n",
    "\n",
    "### Alzheimer's Dataset ( 4 class of Images)\n",
    "<https://www.kaggle.com/tourist55/alzheimers-dataset-4-class-of-images>\n",
    "\n",
    "### Alzheimer's Dataset ( 4 class of Images) - Header image\n",
    "<https://storage.googleapis.com/kaggle-datasets-images/457093/861496/0e1367b46c9e96bdf3823ec7833b965d/dataset-cover.jpg?t=2019-12-26-19-14-30>\n",
    "\n",
    "---\n",
    "\n",
    "### The Alzheimer's Disease Prediction Of Longitudinal Evolution (TADPOLE) Challenge: Results after 1 Year Follow-up\n",
    "<https://paperswithcode.com/paper/the-alzheimer-s-disease-prediction-of>\n",
    "\n",
    "### The Alzheimer's Disease Prediction Of Longitudinal Evolution (TADPOLE) Challenge: Results after 1 Year Follow-up - arxiv.org\n",
    "<https://arxiv.org/pdf/2002.03419v2.pdf>\n",
    "\n",
    "### Preclinical Stage Alzheimer’s Disease Detection Using MRI Scans\n",
    "<https://github.com/sanchezgrsa/Preclinical-Stage-Alzheimers-Disease-Detection>\n",
    "\n",
    "### alzheimer's disease detection - paperswithcode.com\n",
    "<https://paperswithcode.com/task/alzheimer-s-disease-detection>\n",
    "\n",
    "---\n",
    "\n",
    "### OASIS Brains project\n",
    "<https://www.oasis-brains.org/>\n",
    "\n",
    "---\n",
    "\n",
    "### Deep Learning in Alzheimer's disease: Diagnostic Classification and Prognostic Prediction using Neuroimaging Data\n",
    "<https://arxiv.org/abs/1905.00931>\n",
    "\n",
    "### Automatic Assessment of Alzheimer's Disease Diagnosis Based on Deep Learning Techniques\n",
    "<https://arxiv.org/abs/2105.08446>\n",
    "\n",
    "### An explainable two-dimensional single model deep learning approach for Alzheimer's disease diagnosis and brain atrophy localization\n",
    "<https://arxiv.org/abs/2107.13200>\n",
    "\n",
    "### Convolutional Neural Networks for Classification of Alzheimer's Disease: Overview and Reproducible Evaluation\n",
    "<https://arxiv.org/abs/1904.07773>\n",
    "\n",
    "### Improving 3D convolutional neural network comprehensibility via interactive visualization of relevance maps: Evaluation in Alzheimer's disease\n",
    "<https://arxiv.org/abs/2012.10294>\n",
    "\n",
    "### Diagnosis of Alzheimer's Disease via Multi-modality 3D Convolutional Neural Network\n",
    "<https://arxiv.org/abs/1902.09904>\n",
    "\n",
    "### Detection of Alzheimers Disease from MRI using Convolutional Neural Networks, Exploring Transfer Learning And BellCNN\n",
    "<https://arxiv.org/abs/1901.10231>\n",
    "\n",
    "### Detecting Alzheimer's Disease Using Gated Convolutional Neural Network from Audio Data\n",
    "<https://arxiv.org/abs/1803.11344>\n",
    "\n",
    "### Deep Convolutional Neural Network based Classification of Alzheimer's Disease using MRI data\n",
    "<https://arxiv.org/abs/2101.02876>\n",
    "\n",
    "---\n",
    "\n",
    "### TensorFlow Pneumonia Classification on X-rays\n",
    "<https://www.kaggle.com/amyjang/tensorflow-pneumonia-classification-on-x-rays/notebook>\n",
    "\n",
    "### A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way\n",
    "<https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53>\n",
    "\n",
    "### tf.keras.metrics.categorical_accuracy\n",
    "<https://www.tensorflow.org/api_docs/python/tf/keras/metrics/categorical_accuracy>\n",
    "\n",
    "### tf.keras.metrics.AUC\n",
    "<https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC>\n",
    "\n",
    "---\n",
    "### MULTI-DISEASE DETECTION IN RETINAL IMAGING PDF\n",
    "<https://arxiv.org/pdf/2103.14660v1.pdf>\n",
    "\n",
    "### Multi-Disease Detection in Retinal Imaging - papers with code\n",
    "<https://paperswithcode.com/paper/multi-disease-detection-in-retinal-imaging>\n",
    "\n",
    "### Multi-Disease Detection in Retinal Imaging - GitHub\n",
    "<https://github.com/frankkramer-lab/riadd.aucmedi>\n",
    "\n",
    "### AUCMEDI - A Framework for Automated Classification of Medical Images\n",
    "<https://pypi.org/project/aucmedi/>\n",
    "\n",
    "### RETINAL FUNDUS MULTI-DISEASE IMAGE DATASET (RFMID)\n",
    "<https://ieee-dataport.org/open-access/retinal-fundus-multi-disease-image-dataset-rfmid#files>\n",
    "\n",
    "### RFMiD Train Dataset - kaggle\n",
    "<https://www.kaggle.com/awsaf49/rfmid-train-dataset>\n",
    "\n",
    "### Retinal Image Analysis for multi-Disease Detection Challenge website\n",
    "<https://riadd.grand-challenge.org/>\n",
    "\n",
    "### IEEE ISBI 2021 International Symposium on Biomedical Imaging April 13-16 2021\n",
    "<https://biomedicalimaging.org/2021/>\n",
    "\n",
    "---\n",
    "\n",
    "### 3D Photo Inpainting - Turn Any Picture Into 3D Photo with Deep Learning and Python\n",
    "<https://curiousily.com/posts/3d-photo-inpainting-turn-any-picture-into-3d-photo-with-deep-learning-and-python/>\n",
    "\n",
    "### How to create a 3D image with series of 2D Image\n",
    "<https://stackoverflow.com/questions/66699525/how-to-create-a-3d-image-with-series-of-2d-image>\n",
    "\n",
    "### How to convert 2D DICOM slices to 3D image in Python\n",
    "<https://stackoverflow.com/questions/56723891/how-to-convert-2d-dicom-slices-to-3d-image-in-python>\n",
    "\n",
    "### pydicom\n",
    "<https://github.com/pydicom/pydicom>\n",
    "\n",
    "### Numpy 2D image to 3D\n",
    "<https://stackoverflow.com/questions/67178372/numpy-2d-image-to-3d>\n",
    "\n",
    "### Numpy point cloud to image\n",
    "<https://stackoverflow.com/questions/60646028/numpy-point-cloud-to-image>\n",
    "\n",
    "### Convert XYZ point cloud to grayscale image\n",
    "<https://stackoverflow.com/questions/53700089/convert-xyz-point-cloud-to-grayscale-image>\n",
    "\n",
    "### Generate point cloud from depth image\n",
    "<https://stackoverflow.com/questions/59590200/generate-point-cloud-from-depth-image>\n",
    "\n",
    "### Guide to real-time visualisation of massive 3D point clouds in Python\n",
    "<https://towardsdatascience.com/guide-to-real-time-visualisation-of-massive-3d-point-clouds-in-python-ea6f00241ee0>\n",
    "\n",
    "### Coverting point cloud data (.ply) into a range image\n",
    "<https://stackoverflow.com/questions/65614088/coverting-point-cloud-data-ply-into-a-range-image>\n",
    "\n",
    "### Python - Display 3D Point Cloud [closed]\n",
    "<https://stackoverflow.com/questions/50965673/python-display-3d-point-cloud>\n",
    "\n",
    "### Python plyfile vs pymesh\n",
    "<https://stackoverflow.com/questions/36920562/python-plyfile-vs-pymesh>\n",
    "\n",
    "---\n",
    "\n",
    "### Step by Step Implementation: 3D Convolutional Neural Network in Keras\n",
    "<https://towardsdatascience.com/step-by-step-implementation-3d-convolutional-neural-network-in-keras-12efbdd7b130>\n",
    "\n",
    "---\n",
    "\n",
    "### Tensorflow Data augmentation\n",
    "<https://www.tensorflow.org/tutorials/images/data_augmentation>\n",
    "\n",
    "---\n",
    "\n",
    "### Deep Learning with Python\n",
    "<https://www.manning.com/books/deep-learning-with-python>\n",
    "\n",
    "### Alzheimer's disease - Wikipedia\n",
    "<https://en.wikipedia.org/wiki/Alzheimer%27s_disease#/media/File:Alzheimer's_disease_brain_comparison.jpg>\n",
    "\n",
    "### What to know about MRI scans\n",
    "<https://www.medicalnewstoday.com/articles/146309>\n",
    "\n",
    "---\n",
    "\n",
    "### Google Colab\n",
    "<https://colab.research.google.com/>\n",
    "\n",
    "### \n",
    "<>\n",
    "\n",
    "### \n",
    "<>\n",
    "\n",
    "---\n",
    "\n",
    "### Austin Powers - Live dangerously meme 1\n",
    "<https://i.kym-cdn.com/photos/images/newsfeed/000/511/991/3a5.jpg>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZxQUL-CPrje"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oy36mSslPrjf"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oy36mSslPrjf"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "executionInfo": {
     "elapsed": 12275265,
     "status": "error",
     "timestamp": 1644768071069,
     "user": {
      "displayName": "Atanas Kuzmanov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkQ5zRgLa90vqKiGMiIgsyj9hf9t6u5qTGDXfKnWE=s64",
      "userId": "16147571627289237693"
     },
     "user_tz": -120
    },
    "id": "jTIaOiiApeJS",
    "outputId": "0ebed271-f2a3-417d-9080-1f033aba9f25"
   },
   "outputs": [],
   "source": [
    "# A temporary hack, to keep the notebook from timing out. \n",
    "# Comment it out when not needed, otherwise it will cause an infinite loop.\n",
    "\n",
    "while True:pass"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "softuni-ai-dl-project-2022-v8.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
