{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to deep learning - an overview of a published paper\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "***Author:*** Atanas Kuzmanov\n",
    "\n",
    "***Date:*** 2022-February-20\n",
    "\n",
    "*This paper is a retelling and an overview of the original paper \"Introduction to deep learning\" by Lihi Shiloh-Perl and Raja Giryes.*\n",
    "\n",
    "Published: `[v1] Sat, 29 Feb 2020 14:52:28 UTC (6,344 KB)`\n",
    "\n",
    "Reference:\n",
    "\n",
    "Shiloh-Perl, L. and Giryes, R., 2020. Introduction to deep learning. arXiv preprint arXiv:2003.03253.\n",
    "\n",
    "School of Electrical Engineering, Tel Aviv University, e-mail: {lihishiloh@mail ,raja@tauex}.tau.ac.il\n",
    "\n",
    "[[Reference]](#Introduction-to-deep-learning)\n",
    "\n",
    "[[Reference]](#Introduction-to-deep-learning-PDF)\n",
    "\n",
    "[[Reference]](#Introduction-to-deep-learning-ARXIV)\n",
    "\n",
    "---\n",
    "\n",
    "*This is an article developed as a scientific notebook for an exam project assignment for a Deep Learning course from an Artificial Intelligence module.*\n",
    "\n",
    "*One of the aims of this article is to understand some Deep Learning (DL) basics and basic concepts, more specifically to understand Neural Networks (NNs) and how to improve them, so we can create models, train them, test them and extract predictions and information we might be interested in.*\n",
    "\n",
    "*I have expanded the original paper, on which this article is based on, in the [Additional contributions, expansion and further development of this paper Section](#Additional-contributions,-expansion-and-further-development-of-this-paper),by adding a real practical example of building a Convolutional Neural Network architecture, training the model, evaluating it, and then testing it with an example.*\n",
    "\n",
    "---\n",
    "\n",
    "*This paper was chosen among many considered, and here are a few of the other papers considered:*\n",
    "\n",
    "- *Artificial Neural Network: Understanding the Basic Concepts without Mathematics [[Reference]](#Artificial-Neural-Network:-Understanding-the-Basic-Concepts-without-Mathematic)*\n",
    "- *Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions [[Reference]](#Deep-Learning:-A-Comprehensive-Overview-on-Techniques,-Taxonomy,-Applications-and-Research-Directions)*\n",
    "- *Introduction to Machine Learning, Neural Networks, and Deep Learning [[Reference]](#Introduction-to-Machine-Learning,-Neural-Networks,-and-Deep-Learning)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foreword\n",
    "\n",
    "_One of the aims of this article is to understand some Deep Learning (DL) basics and basic concepts._\n",
    "\n",
    "_Because of that goal it is important to be able to train and test models multiple times, so we can determine the best hyperparameters and tune models to improve them. Unfortunately at the time of writing this article, in the year 2022, I am using my personal laptop from 2015. I thought this machine has fared rather well for it's age, and have great respect for it and what I have put it through, as we have been together through thick and thin. That was until I had to actually do DL on it for this article when I realized it is not going to fare well for this purpose. Most of the models were unable to run or finish running once I tried to train them, or once I tried to change the hyperparameters to improve them. My machine would just heat up with fans running at the highest rpms and still seem stuck on executing a cell for more than 30min. If I had carried on like this I would not have been able to finish this article, so instead most or all of the hyperparameters for the models are set to severely low or high, depending on the context, in order to reduce iterations or features of the data, so that this notebook would work and I would be able to demonstrate or give an example of the idea I am trying to explain. Please keep this in mind when going through the article._\n",
    "\n",
    "_This will be sufficient for the purpose of this article, just to demonstrate and help understand DL basics and basic concepts, but if you need to try out some of the examples and extend and improve them for actual Deep Learning keep in mind you need a powerful machine with a good GPU, or you can use a cloud platform suitable for DL, such as Google Colab._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References Notes\n",
    "\n",
    "_Any and all references, citations, resources or other materials used to understand and explain, provide examples, and build this article have been referenced in order to give credit where credit is due and avoid plagiarism._\n",
    "_If a citation is the bigger part of a section, and has been edited, added to, modified, etc. the reference to that section would be at the end of it, separated with a horizontal line, like this example:_\n",
    "\n",
    "> ---\n",
    "> [[Example Reference]](#ExampleReference)\n",
    "\n",
    "_If a citation has been inserted and is relatively short, the relevant reference will be at the end of the sentence or paragraph, for example:_\n",
    "\n",
    "> Example. [[Example Reference]](#ExampleReference)\n",
    "\n",
    "_In case a reference is missed due to human error, all references can be found in the [References](#References) section. Anything which is found in the [References](#References) should be considered as a valid reference for everything in this paper, even if not explicitly referenced._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning (DL) has made a major impact on data science in the last\n",
    "decade. This chapter introduces the basic concepts of this field. It includes both the\n",
    "basic structures used to design deep neural networks and a brief survey of some of\n",
    "its popular use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 General overview\n",
    "\n",
    "Neural Networks (NN) have revolutionized the modern day-to-day life. Their sig-\n",
    "nificant impact is present even in our most basic actions, such as ordering products\n",
    "on-line via Amazon’s Alexa or passing the time with on-line video games against\n",
    "computer agents. The NN effect is evident in many more occasions, for example,\n",
    "in medical imaging NNs are utilized for lesion detection and segmentation [40, 5],\n",
    "and tasks such as text-to-speech [38, 120] and text-to-image [101] have remarkable\n",
    "improvements thanks to this technology. In addition, the advancements they have\n",
    "caused in fields such as natural language processing (NLP) [24, 144, 77], optics\n",
    "[114, 42], image processing [110, 143] and computer vision (CV) [10, 34] are aston-\n",
    "ishing, creating a leap forward in technology such as autonomous driving [13, 79],\n",
    "face recognition [109, 134, 23], anomaly detection [64], text understanding [54] and\n",
    "art [35, 53], to name a few. Its influence is powerful and is continuing to grow.\n",
    "\n",
    "The NN journey began in the mid 1960’s with the publication of the Perceptron\n",
    "[105]. Its development was motivated by the formulation of the human neuron\n",
    "activity [80] and research regarding the human visual perception [49]. However,\n",
    "quite quickly, a deceleration in the field was experienced, which lasted for almost\n",
    "three decades. This was mainly the result of lack of theory with respect to the\n",
    "possibility of training the (single-layer) perceptron and a series of theoretical results that emphasized its limitations, where the most remarkable one is its inability to\n",
    "learn the XOR function [82]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This _NN ice age_ came to a halt in the mid 1980’s, mainly with the introduction\n",
    "of the multi-layer perceptron (MLP) and the backpropagation algorithm [107]. Fur-\n",
    "thermore, the revolutionary convolutional layer was presented [68], where one of its\n",
    "notable achievements was successfully recognizing hand-written digits [67].\n",
    "While some other significant developments have happened in the following\n",
    "decade, such as the development of the long-short memory machine (LSTM) [46],\n",
    "the field experienced another deceleration. Questions were arising with no adequate\n",
    "answers especially with respect to the non-convex nature of the used optimization ob-\n",
    "jectives, overfitting the training data, and the challenge of vanishing gradients. These\n",
    "difficulties led to a second _NN winter_ , which lasted two decades. In the meantime,\n",
    "classical machine learning techniques were developed and attracted much academic\n",
    "and industry attention. One of the prominent algorithms was the newly proposed\n",
    "Support Vector Machine (SVM) [17], which defined a convex optimization prob-\n",
    "lem with a clear mathematical interpretation [16]. These properties increased its\n",
    "popularity and usage in various applications.\n",
    "\n",
    "The 21 stcentury began with some advancements in neural networks in the areas\n",
    "of speech processing and Natural Language Processing (NLP). Hinton _et al._ [45]\n",
    "proposed a method for layer-wise initial training of neural networks, which leveraged\n",
    "some of the challenges in training networks with several layers. However, the great\n",
    "NN _tsunami_ truly hit the field with the publication of _AlexNet_ in 2012 [62]. In this\n",
    "paper, Krizhevsky _et al._ presented a neural network that achieved state-of-the-art\n",
    "performance on the ImageNet [22] challenge, where the goal is to classify images\n",
    "into 1000 categories using 1.2 Million images for training and 150000 images for\n",
    "testing. The improvement over the runner-up, which relied on hand crafted features\n",
    "and one of the best classification techniques of that time, was notable - more than\n",
    "10%. This caused the whole research community to understand that neural networks\n",
    "are way more powerful than what was thought and they bear a great potential for\n",
    "many applications. This led to a myriad of research works that applied NNs for\n",
    "various fields showing their great advantage.\n",
    "\n",
    "Nowadays, it is safe to say that almost every research field has been affected\n",
    "by this NN _tsunami_ wave, experiencing significant improvements in abilities and\n",
    "performance. Many of the tools used today are very similar to the ones used in the\n",
    "previous phase of NN. Indeed, some new regularization techniques such as batch-\n",
    "normalization [50] and dropout [121] have been proposed. Yet, the key-enablers for\n",
    "the current success is the large amounts of data available today that are essential for\n",
    "large NN training, and the developments in GPU computations that accelerate the\n",
    "training time significantly (sometimes even leading to× 100 speed-up compared to\n",
    "training on a conventional CPU). The advantages of NN is remarkable especially\n",
    "at large scales. Thus, having large amounts of data and the appropriate hardware to\n",
    "process them, is vital for their success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A major example of a tool that did not exist before is the Generative Adversarial\n",
    "Network (GAN [39]). In 2014, Goodfellow _et al._ published this novel framework for\n",
    "learning data distribution. The framework is composed of two models, a generator and a discriminator, trained as adversaries. The generator is trained to capture the\n",
    "data distribution, while the discriminator is trained to differentiate between generated\n",
    "(“fake”) data and real data. The goal is to let the generator synthesize data, which the\n",
    "discriminator fails to discriminate from the real one. The GAN architecture is used\n",
    "in more and more applications since its introduction in 2014. One such application is\n",
    "the rendering of real scene images were GANs have proved very successful [36, 151].\n",
    "For example, Brock _et al._ introduced the BigGAN [7] architecture that exhibited im-\n",
    "pressive results in creating high-resolution images, shown in Fig. 1. While most GAN\n",
    "techniques learn from a set of images, recently it has been successfully demonstrated\n",
    "that one may even train a GAN just using one image [112]. Other GAN application\n",
    "include inpainting [73, 145], retargeting [115], 3D modeling [1], semi-supervised\n",
    "learning [31], domain adaptation [47] and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BigGAN_example1.png](2003.03253v1-resources/20031.03253v1-pics/BigGAN_example1.png)\n",
    "\n",
    "Fig. 1: Class-conditional samples generated by a GAN, [7]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While neural networks are very successful, the theoretical understanding behind\n",
    "them is still missing. In this respect, there are research efforts that try to provide a\n",
    "mathematical formulation that explains various aspects of NN. For example, they\n",
    "study NN properties such as their optimization [124], generalization [52] and ex-\n",
    "pressive power [108, 88].\n",
    "\n",
    "The rest of the chapter is organized as follows. In Section 2 the basic structure\n",
    "of a NN is described, followed by details regarding popular loss functions and\n",
    "metric learning techniques used today (Section 3). We continue with an introduction\n",
    "to the NN training process in Section 4, including a mathematical derivation of\n",
    "backpropagation and training considerations. Section 5 elaborates on the different\n",
    "optimizers used during training, after which Section 6 presents a review of common\n",
    "regularization schemes. Section 7 details advanced NN architecture with state-of-\n",
    "the-art performances and Section 8 concludes the chapter by highlighting some\n",
    "current important NN challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Basic NN structure\n",
    "\n",
    "The basic building block of a NN consists of a linear operation followed by a non-\n",
    "linear function. Each building block consists of a set of parameters, termed weights\n",
    "and biases (sometimes the term weights includes also the biases), that are updated\n",
    "in the training process with the goal of minimizing a pre-defined loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume an input data $\\mathbf{x}\\in \\mathbb{R}^{d_0}$, the output of the building block is of the form \\mbox{$\\psi (\\mathbf{W}\\mathbf{x}+\\mathbf{b})$}, where $\\psi(\\cdot )$ is a non-linear function, $\\mathbf{W}\\in \\mathbb{R}^{d_1 \\times d_0}$ is the linear operation and $\\mathbf{b}\\in \\mathbb{R}^{d_1}$ is the bias. See Fig.2 for an illustration of a single building block. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![building_block.png](2003.03253v1-resources/20031.03253v1-pics/building_block.png)\n",
    "\n",
    "Fig. 2: NN building block consists of a linear and a non-linear elements. The weights\n",
    "**W** and biases **b** are the parameters of the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NN_illustraion.png](2003.03253v1-resources/20031.03253v1-pics/NN_illustraion.png)\n",
    "\n",
    "Fig. 3: NN layered structure: concatenation of N building blocks, e.g., model layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To form an NN model, such building blocks are concatenated one to another in a\n",
    "layered structure that allows the input data to be gradually processed as it propagates\n",
    "through the network. Such a process is termed the (feed-)forward pass. Following it,\n",
    "during training, a backpropagation process is used to update the NN parameters, as\n",
    "elaborated in Section 4.1. In inference time, only the forward pass is used.\n",
    "\n",
    "Fig. 3 illustrates the concatenation ofKbuilding blocks, e.g., layers. The inter-\n",
    "mediate output at the end of the model (before the “task driven block”) is termed the\n",
    "_network embedding_ and it is formulated as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Φ( x , W (^1 ), ..., W (K), b (^1 ), ..., b (K))=ψ( W (K)...ψ( W (^2 )ψ( W (^1 ) x + b (^1 ))+ b (^2 ))...+ b (K)). \\quad \\quad (1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final output (prediction) of the network is estimated from the network embedding\n",
    "of the input data using an additional task driven layer. A popular example is the case\n",
    "of classifications, where this block is usually a linear operation followed by the\n",
    "_cross-entropy_ loss function (detailed in Section 3).\n",
    "\n",
    "When approaching the analysis of data with varying length, such as sequential\n",
    "data, a variant of the aforementioned approach is used. A very popular example for\n",
    "such a neural network structure is the Recurrent Neural Network (RNN [51]). In a\n",
    "vanilla RNN model, the network receives at each time step just a single input but\n",
    "with a feedback loop calculated using the result of the same network in the previous\n",
    "time-step (see an illustration in Fig. 4). This enables the network to \"remember\"\n",
    "information and support multiple inputs and producing one or more outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex RNN structures include performing bi-directional calculations or\n",
    "adding gating to the feedback and the input received by the network. The most known\n",
    "complex RNN architecture is the Long-Term-Short-Memory (LSTM) [46, 37], which\n",
    "adds gates to the RNN. These gates decide what information from the current input\n",
    "and the past will be used to calculate the output and the next feedback, as well as\n",
    "what information to mask (i.e., causing the network to forget). This enables an easier\n",
    "combination of past and present information. It is commonly used for time-series\n",
    "data in domains such as NLP and speech processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN_series.png](2003.03253v1-resources/20031.03253v1-pics/RNN_series.png)\n",
    "\n",
    "Fig. 4: Recurrent NN (RNN) illustration for time series data. The feedback loop\n",
    "introduces time dependent characteristics to the NN model using an element-wise\n",
    "function. The weights are the same along all time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common network structure is the _Encoder-Decoder_ architecture. The\n",
    "first part of the model, the encoder, reduces the dimensions of the input to a compact\n",
    "feature vector. This vector functions as the input to the second part of the model, the\n",
    "decoder. The decoder increases its dimension, usually, back to the original input size.\n",
    "This architecture essentially learns to compress (encode) the input to an efficiently\n",
    "small vector and then decode the information from its compact representation. In\n",
    "the context of regular feedforward NN, this model is known as autoencoder [119]\n",
    "and is used for several tasks such as image denoising [102], image captioning [133],\n",
    "feature extraction [132] and segmentation [2]. In the context of sequential data, it is\n",
    "used for tasks such as translation, where the decoder generates a translated sentence\n",
    "from a vector representing the input sentence [126, 14]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Common linear layers\n",
    "\n",
    "A common basic NN building block is the Fully Connected (FC) layer. A net-\n",
    "work composed of a concatenation of such layers is termed Multi-Layer Perceptron\n",
    "(MLP) [106]. The FC layer connects every neuron in one layer to every neuron in\n",
    "the following layer, i.e. the matrix **W** is dense. It enables information propagation\n",
    "from all neurons to all the ones following them. However it may not maintain spatial\n",
    "information. Figure 5 illustrates a network with FC layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional layer [66, 68] is another very common layer. We discuss here\n",
    "the 2D case, where the extension to other dimension is straight-forward. This layer\n",
    "applies one or multiple convolution filters to its input with kernels of sizeW×H.\n",
    "The output of the convolution layer is commonly termed a _feature map_.\n",
    "\n",
    "Each neuron in a feature map receives inputs from a set of neurons from the\n",
    "previous layer, located in a small neighborhood defined by the kernel size. If we\n",
    "apply this relationship recursively, we can find the part of the input that affects each\n",
    "neuron at a given layer, i.e., the area of visible context that each neuron sees from\n",
    "the input. The size of this part is called the _receptive field_. It impacts the type and\n",
    "size of visual features each convolution layer may extract, such as edges, corners\n",
    "and even patterns. Since convolution operations maintain spatial information and are\n",
    "translation equivariant, they are very useful, namely, in image processing and CV.\n",
    "\n",
    "If the input to a convolution layer has some arbitrary third dimension, for example\n",
    "3-channels in an RGB image (C= 3 ) or someC> 1 channels from an output of a\n",
    "hidden layer in the model, the kernel of the matching convolution layer should be\n",
    "of sizeW×H×C. This corresponds to applying a different convolution for each\n",
    "input channel separately, and then summing the outputs to create one feature map.\n",
    "The convolution layer may create a multi-channel feature map by applying multiple\n",
    "filters to the input, i.e., using a kernel of sizeW×H×Cin×Cout, whereCinandCout\n",
    "are the number of channels at the input and output of the layer respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Common non-linear functions\n",
    "\n",
    "The non-linear functions defined for each layer are of great interest since they\n",
    "introduce the non-linear property to the model and can limit the propagating gradient\n",
    "from vanishing or exploding (see Section 4).\n",
    "Non-linear functions that are applied element-wise are known as _activation func-\n",
    "tions_. Common activation functions are the Rectified Linear Unit (ReLU [20]), leaky\n",
    "ReLU [141], Exponential Linear Unit (ELU) [15], hyperbolic tangent (tanh) and sig-\n",
    "moid. There is no universal rule for choosing a specific activation function, however,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLP.png](2003.03253v1-resources/20031.03253v1-pics/MLP.png)\n",
    "Fig. 5: Fully-connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLUs and ELUs are currently more popular for image processing and CV while\n",
    "sigmoid and tanh are more common in speech and NLP. Fig. 6 presents the response\n",
    "of the different activation functions and Table 1 their mathematical formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![activation_functions.jpg](2003.03253v1-resources/20031.03253v1-pics/activation_functions.jpg)\n",
    "Fig. 6: Different activation functions. Leaky ReLU with $α= 0.1$, ELU with $α= 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1: Mathematical expressions for non-linear activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellspacing=\"1\" cellpadding=\"2\" valign=\"middle\" style=\"border-collapse: collapse; border: none;\">\n",
    "    <tbody>\n",
    "        <tr style=\"border: none;\">\n",
    "            <td style=\"border: none;\">\n",
    "Function\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "Formulation $s(x)$\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "Derivative $\\frac{ds(x)}{dx}$\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "Function output\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr style=\"border: none;\">\n",
    "            <td style=\"border: none;\">\n",
    "ReLU\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$\\begin{cases}\n",
    "0, & \\text{for } x<0\\\\ \n",
    "x, & \\text{for } x\\geq 0\n",
    "\\end{cases}$$\n",
    "              </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$\\begin{cases}\n",
    "0, & \\text{for } x<0\\\\ \n",
    "1, & \\text{for } x\\geq 0\n",
    "\\end{cases}$$\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$[0,\\infty )$$\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr style=\"border: none;\">\n",
    "            <td style=\"border: none;\">\n",
    "Leaky ReLU\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$\\begin{cases}\n",
    "\\alpha x, & \\text{for } x<0\\\\ \n",
    "x, & \\text{for } x\\geq 0\n",
    "\\end{cases}$$\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$\\begin{cases}\n",
    "\\alpha, & \\text{for } x<0\\\\ \n",
    "1, & \\text{for } x\\geq 0\n",
    "\\end{cases}$$\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$(-\\infty ,\\infty )$$\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr style=\"border: none;\">\n",
    "            <td style=\"border: none;\">\n",
    "ELU\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$\\begin{cases}\n",
    "\\alpha(\\mathrm{e}^{x}-1), & \\text{for } x<0\\\\ \n",
    "x, & \\text{for } x\\geq 0\n",
    "\\end{cases}$$\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$\\begin{cases}\n",
    "\\alpha \\mathrm{e}^{x}, & \\text{for } x<0\\\\ \n",
    "1, & \\text{for } x\\geq 0\n",
    "\\end{cases}$$\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$[-\\alpha ,\\infty )$$\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr style=\"border: none;\">\n",
    "            <td style=\"border: none;\">\n",
    "Sigmoid\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$\\frac{1}{1+\\mathrm{e}^{-x}}$$\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$\\frac{\\mathrm{e}^{-x}}{(1+\\mathrm{e}^{-x})^2}$$\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$(0,1)$$\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr style=\"border: none;\">\n",
    "            <td style=\"border: none;\">\n",
    "tanh\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$\\tanh(x)=\\frac{\\mathrm{e}^{2x}-1}{\\mathrm{e}^{2x}+1}$$\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$1-\\tanh^2(x)$$\n",
    "            </td>\n",
    "            <td style=\"border: none;\">\n",
    "$$(-1,1)$$\n",
    "            </td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common non-linear operations in a NN model are the pooling functions.\n",
    "They are aggregation operations that reduce dimensionality while keeping dominant\n",
    "features. Assume a pooling size ofqand an input vector to a hidden layer of size\n",
    "d, $z =[z 1 ,z 1 , ...,zd]$. For every $m ∈ [ 1 ,d]$, the subset of the input vector $z ̃ =\n",
    "[zm,zm+ 1 , ...,zq+m]$ may undergo one of the following popular pooling operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max pooling: $g(\\mathbf{\\tilde{z}})=\\max_i \\mathbf{\\tilde{z}}$\n",
    "\n",
    "Mean pooling: $g(\\mathbf{\\tilde{z}})=\\frac{1}{q}\\sum_{i=m}^{q+m}z_i$\n",
    "\n",
    "$\\ell_p$ pooling: $g(\\mathbf{\\tilde{z}})=\\sqrt[p]{\\sum_{i=m}^{q+m} z^p_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All pooling operations are characterized by a stride, $s$, that effectively defines the output dimensions. Applying pooling with a stride $s$, is equivalent to applying the pooling with no stride (i.e., $s=1$) and then sub-sampling by a factor of $s$. It is common to add zero padding to $\\mathbf{z}$ such that its length is divisible by $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very common non-linear function is the $\\textit{softmax}$, which normalizes vectors into probabilities. The output of the model, the embedding, may undergo an additional linear layer to transform it to a vector of size $1 \\times N$, termed $\\textit{logits}$, where $N$ is the number of classes. The logits, here denoted as $\\mathbf{v}$, are the input to the softmax operation defined as follows: \n",
    "\\begin{equation}\\label{eq:softmax}\n",
    "    \\text{softmax}(v_i)=\\frac{\\mathrm{e}^{v_i}}{\\sum_{j=1}^{N}\\mathrm{e}^{v_j}}, ~~~~~ i\\in[1,...,N]. \\quad \\quad (2)\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the loss function of the model, denoted as $\\mathcal{L}$, is critical and usually chosen based on the characteristics of the dataset and the task at hand. \n",
    "Though datasets can vary, tasks performed by NN models can be divided into two coarse groups: (1) regression tasks and (2) classification tasks.\n",
    "\n",
    "A regression problem aims at approximating a mapping function from input variables to a continuous output variable(s). \n",
    "For NN tasks, the output of the network should predict a continues value of interest. %, as opposed to discrete values. \n",
    "Common NN regression problems include image denoising[148], deblurring [84], inpainting [142] and more.\n",
    "In these tasks, it is common to use the Mean Squared Error (MSE), Structural SIMilarity (SSIM) or $\\ell_1$ loss as the loss function. \n",
    "The MSE ($\\ell_2$ error) imposes a larger penalty for larger errors, compared to the $\\ell_1$ error which is more robust to outliers in the data. \n",
    "The SSIM, and its multiscale version [149], help improving the perceptual quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the _classification_ task, the goal is to identify the correct class of a given\n",
    "sample from pre-defined $N$ classes. A common loss function for such tasks is the _cross-entropy_  loss. \n",
    "It is implemented based on a normalized vector of probabilities corresponding to a list of potential outcomes. This normalized vector is calculated by the softmax non-linear function (Eq. (2)). The cross-entropy loss is defined as:\n",
    "\n",
    "\\begin{equation}\\label{eq:cross-entropy}\n",
    "\\mathcal{L}_{CE}=-\\sum_{i=1}^{N}y_i\\log(p_i), \\quad \\quad (3)\n",
    "\\end{equation}\n",
    "\n",
    "where $y_i$ is the ground-truth probability (the label) of the input to belong to class $i$ and $p_i$ is the  model prediction score for this class. The label is usually binary, i.e., it contains $1$ in a single index (corresponding to the true class). This type of representation is known as _one-hot encoding_. The class is predicted in the network by selecting the largest probability and the log-loss is used to increase this probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that a network may provide multiple outputs per input data-point. For example, in the problem of image semantic segmentation, the network predicts a class for each pixel in the image. In the task of object detection, the network outputs a list of objects, where each is defined by a bounding box (found using a regression loss) and a class (found using a classification loss). Section 7.1 details these different tasks.\n",
    "Since in some problems, the labeled data are imbalanced, one may use weighted softmax (that weigh less frequent classes) or the focal loss [72]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Metric Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting property of the log-loss function used for classification is that it implicitly cluster classes in the network embedding space during training. However, for a clustering task, these vanilla distance criteria often produce unsatisfactory performance as different class clusters can be positioned closely in the embedding space and may cause miss-classification for samples that do not reside in the specific training set distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, different metric learning techniques have been developed to produce an embedding space that brings closer intra-class samples and increases inter-class distances. This results in better accuracy and robustness of the network. It allows the network to be able to distinguish between two data samples if they are from the same class or not, just by comparing their embeddings, even if their classes have not been present at training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric learning is very useful for tasks such as face recognition and identification, where the number of subjects to be tested are not known at training time and new identities that were not present during training should also be identified/recognized (e.g., given two images the network should decide whether these correspond to the same or different persons). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example for a popular metric loss is the _triplet loss_ [109]. It enforces a margin between instances of the same class and other classes in the embedding feature space. This approach increases performance accuracy and robustness due to the large separation between class clusters in the embedding space.\n",
    "The triplet loss can be used in various tasks, namely detection, classification, recognition and other tasks of unknown number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, three instances are used in each training step $i$: an anchor $\\mathbf{x}_i^a$, another instance $\\mathbf{x}_i^p$ from the same class of the anchor (positive sample), and a sample $\\mathbf{x}_i^n$ from a different class (negative class).\n",
    "They are required to obey the following inequality:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\left\\Vert \\Phi(\\mathbf{x}_i^a)-\\Phi(\\mathbf{x}_i^p) \\right\\Vert_2^2+\\alpha<\\left\\Vert \\Phi(\\mathbf{x}_i^a)-\\Phi(\\mathbf{x}_i^n)\\right\\Vert_2^2, \\quad \\quad (4)\n",
    "\\end{equation}\n",
    "where $\\alpha<0$ enforces the wanted margin from other classes.\n",
    "Thus, the triplet loss is defined by:\n",
    "\\begin{equation}\n",
    "    \\mathcal{L}=\\sum_i\\left\\Vert \\Phi(\\mathbf{x}_i^a)-\\Phi(\\mathbf{x}_i^p)\\right\\Vert_2^2-\\left\\Vert \\Phi(\\mathbf{x}_i^a)-\\Phi(\\mathbf{x}_i^n)\\right\\Vert_2^2+\\alpha. \\quad \\quad (5)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig. 7 presents a  schematic illustration of the triplet loss influence on samples in the embedding space. \n",
    "This illustration also exhibits a specific triplet example, where the positive examples are relatively far from the anchor while negative examples are relatively near the anchor. Finding such examples that violate the triplet condition is desirable during training. They may be found by on-line or off-line searches known as \\textit{hard negative mining}. A preprocessing of the instances in the embedding space is performed to find violating examples for training the network.\n",
    "\n",
    "Finding the \"best\" instances for training can, evidently, aid in achieving improved convergence. However, searching for them is often time consuming and therefore alternative techniques are being explored. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![triplet.png](2003.03253v1-resources/20031.03253v1-pics/triplet.png)\n",
    "\n",
    "Fig. 7: Triplet loss: minimizes the distance between two similar class examples (anchor and positive), and maximizes the distance between two different class examples\n",
    "(anchor and negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An intriguing metric learning approach relies on 'classification'-type loss functions, where the network is trained given a fixed number of classes. Yet, these losses are designed to create good embedding space that creates margin between classes, which in turn provides good prediction of similarity between two inputs. Popular examples include the Cos-loss [134], Arc-loss [23] and SphereFace [76]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a loss function, the weights of the neural network are updated to minimize it for a given training set. The training process of a neural network requires a large database due to the nature of the network (structure and amount of parameters) and GPUs for efficient training implementation.\n",
    "\n",
    "In general, training methods can be divided into supervised and unsupervised training. The former consists of labeled data that are usually very expensive and time consuming to obtain. Whereas the latter is the more common case and does not assume known ground-truth labels.\n",
    "However, supervised training usually achieves significantly better network performance compared to the unsupervised case. Therefore, a lot of resources are invested in labeling datasets for training. Thus, we focus here mainly on the supervised setting. \n",
    " \n",
    "In neural networks, regardless of the model task, all training phases have the same goal: to minimize a pre-defined error function, also denoted as the loss/cost function. \n",
    "This is done in two stages: (a) a feed-forward pass of the input data through all the network layers, calculating the error using the predicted outputs and their ground-truth labels (if available); followed by (b) backpropogation of the errors through the network to update their weights, from the last layer to the first. \n",
    "This process is performed continuously to find the optimized values for the weights of the network. \n",
    "\n",
    "The backpropagation algorithm provides the gradients of the error with respect to the network weights. These gradients are used to update the weights of the network. Calculating them based on the whole input data is computationally demanding and therefore, the common practice is to use subsets of the training set, termed $\\textit{mini-batches}$, and cycle over the entire training set multiple times. Each cycle of training over the whole dataset is termed an $\\textit{epoch}$ and in every cycle the data samples are used in a random order to avoid biases.\n",
    "The training process ends when convergence in the loss function is obtained. Since most NN problems are not convex, an optimal solution is not assured. We turn now to describe in more details the training process using backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Backpropogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example.png](2003.03253v1-resources/20031.03253v1-pics/example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The backpropagation process is performed to update all the parameters of the model, with the goal of decreasing the loss function value. \n",
    "The process starts with a feed-forward pass of input data, $\\mathbf{x}$, through all the network layers. After which the loss function value is calculated and denoted as $\\mathcal{L}(\\mathbf{x},{\\bf W})$, where ${\\bf W}$ are the model parameters (including the model weights and biases, for formulation convenience). \n",
    "Then the backpropagation is initiated by computing the value of:~$\\frac{\\partial \\mathcal{L}}{\\partial {\\bf W}}$, followed by the update of the network weights. All the weights are updated recursively by calculating the gradients of every layer, from the final one to the input layer, using the chain rule.\n",
    "\n",
    "Denote the output of layer $l$ as ${\\bf z}^{(l)}$. Following the chain rule, the gradients of a given layer $l$ with parameters ${\\bf W}^{(l)}$ with respect to its input ${\\bf z}^{(l)}$ are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial {\\bf z}^{(l-1)}}=\\frac{\\partial \\mathcal{L}}{\\partial {\\bf z}^{(l)}}\\cdot\\frac{\\partial {\\bf z}^{(l)}({\\bf W}^{(l)},{\\bf z}^{(l-1)})}{\\partial {\\bf z}^{(l-1)}}, \\quad (6)\n",
    "\\end{equation}\n",
    "and the gradients with respect to the parameters are:\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial {\\bf W}^{(l)}}=\\frac{\\partial \\mathcal{L}}{\\partial {\\bf z}^{(l)}}\\cdot\\frac{\\partial {\\bf z}^{(l)}({\\bf W}^{(l)},{\\bf z}^{(l-1)})}{\\partial {\\bf W}^{(l)}}. \\quad (7)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two formulas of the backpropagation algorithm dictate the gradients calculation with respect to the parameters for each layer in the network and, therefore, the optimization can be performed using gradient-based optimizers (see Section 5 for more details).\n",
    "\n",
    "To demonstrate the use of the backpropagation technique for the calculation of the network gradients, we turn to consider an example of a simple classification model with two-layers: a fully-connected layer with a ReLU activation function followed by another fully-connected layer with softmax function and log-loss. See Fig. 8 for the model illustration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denote by ${\\bf z}^{(3)}$ the output of the softmax layer and assume that the input $\\mathbf{x}$ belongs to class $k$ (using one-hot encoding $y_k=1$). The log-loss in this case is:\n",
    "\\begin{equation}\n",
    "    \\mathcal{L}=-\\sum_i\\log\\big(z_i^{(3)}\\big)y_i=-\\log\\Bigg(\\frac{\\exp\\big(z^{(2)}_k\\big)}{\\sum_i\\exp\\big(z^{(2)}_i\\big)}\\Bigg)=-z^{(2)}_k+\\log\\Big(\\sum_j \\exp{z^{(2)}_j}\\Big).\n",
    "    \\quad(8)\n",
    "\\end{equation}\n",
    "For all $i\\neq k$, the gradient of the error with respect to the softmax input $z_i^{(2)}$ is \n",
    "\\begin{equation}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial z^{(2)}_i}=\\frac{\\exp\\big({z^{(2)}_i}\\big)}{\\sum_j\\exp\\big(z^{(2)}_j\\big)}\\equiv g_i.\n",
    "    \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(9)\n",
    "\\end{equation}\n",
    "Notice that this implies that we need to decrease the value of  $z_i^{(2)}$ (the $i^{\\text{th}}$-logit)  proportionally to the probability the network provides to it. \n",
    "While for the correct label, $i=k$, the derivative is:\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial z^{(2)}_k}=-1+\\frac{\\exp\\big({z^{(2)}_k}\\big)}{\\sum_j\\exp\\big(z^{(2)}_j\\big)}= g_k-1,\n",
    "    \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(10)\n",
    "\\end{equation}\n",
    "which implies that the value of the logit element associated with the true label should be increased proportionally to the mistake the network is currently doing in the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output ${\\bf z}^{(2)}$ is a product of a fully-connect layer. Therefore, it can be formulated as follows:\n",
    "\\begin{equation}\n",
    "    {\\bf z}^{(2)}={\\bf W}^{(2)}\\tilde{{\\bf z}}^{(1)},\n",
    "    \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(11)\n",
    "\\end{equation}\n",
    "where $\\tilde{{\\bf z}}^{(1)}$ is the output of the ReLu function. \n",
    "Following the backpropagation rules we get that for this layer, the derivative with respect to its input is:\n",
    "\\begin{equation}\\label{eq:backprop_fc2}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial \\tilde{{\\bf z}}^{(1)}}=\\frac{\\partial \\mathcal{L}}{\\partial {\\bf z}^{(2)}}\\cdot\\frac{\\partial {\\bf z}^{(2)}({\\bf W}^{(2)},\\tilde{{\\bf z}}^{(1)})}{\\partial \\tilde{{\\bf z}}^{(1)}}=\\frac{\\partial \\mathcal{L}}{\\partial {\\bf z}^{(2)}}\\cdot{\\bf W}^{(2)},\n",
    "    \\quad\\quad\\quad\\quad\\quad\\quad(12)\n",
    "\\end{equation}\n",
    "whereas, the derivative with respect to its parameters is:\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial {\\bf W}^{(2)}}=\\frac{\\partial \\mathcal{L}}{\\partial {\\bf z}^{(2)}}\\cdot\\frac{\\partial {\\bf z}^{(2)}({\\bf W}^{(2)},\\tilde{{\\bf z}}^{(1)})}{\\partial {\\bf W}^{(1)}}=\\frac{\\partial \\mathcal{L}}{\\partial {\\bf z}^{(2)}}\\cdot \\tilde{{\\bf z}}^{(1)}. \\quad\\quad\\quad\\quad\\quad\\quad(13)\n",
    "\\end{equation}\n",
    "The ReLU operation has no weight to update, but affects the gradients. The derivative of this stage follows:\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial {\\bf z}^{(1)}}=\\frac{\\partial \\mathcal{L}}{\\partial \\tilde{{\\bf z}}^{(1)}}\\cdot\\frac{\\partial \\tilde{{\\bf z}}^{(1)}({\\bf W}^{(1)},I)}{\\partial {\\bf z}^{(1)}}=\\begin{cases}\n",
    "0, &\\text{if } {\\bf z}^{(1)}<0\\\\\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\tilde{{\\bf z}}^{(1)}}, &\\text{otherwise}. \\quad\\quad\\quad\\quad(14)\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "The final derivative with respect to the input $\\partial \\mathcal{L}/\\partial \\mathbf{x}$ is calculated similar to Eq. (12)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several considerations that should be addressed when training a NN. \n",
    "The most infamous is the $\\textit{overfitting}$, i.e., when the model too closely fits to the training dataset but does not generalize well to the test set. \n",
    "When this occurs, high training data precision is achieved, while the precision on the test data (not used during training) is low [129]. \n",
    "For this purpose, various regularization techniques have been proposed. We discuss some of them in Section 6.\n",
    "\n",
    "A second consideration is the vanishing/exploding gradients occurring during training.\n",
    "Vanishing gradients are a result of multiplications with values smaller than one during their calculation in the backpropagation recursion. This can be resolved using activation functions and batch normalization detailed in Section 6.\n",
    "On the other hand, the gradients might also explode due to derivatives that are significantly larger than one in the backpropogation calculation. This makes the training unstable and may imply the need for re-designing the model (e.g., replace a vanilla RNN with a gated architecture such as LSTMs) or the use of gradient clipping [91].\n",
    "\n",
    "Another important issue is the requirement that the training dataset must represent the true distribution of the task at hand. This usually enforces very large annotated datasets, which necessitate significant funding and manpower to obtain. In this case, considerable efforts must be invested to train the network using these large datasets, commonly with multiple GPUs for several days [62, 58]. One may use techniques such as domain adaptation [138] or transfer learning [128] to use already existing networks or large datasets for new tasks. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Training optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training neural networks is done by applying an optimizer to reach an optimal solution for the defined loss function. \n",
    "Its goal is to find the parameters of the model, e.g., weights and biases, which achieve minimum error for the training set samples: $(\\mathbf{x}_i, y_i)$, where $y_i$ is the label for the instance $\\mathbf{x}_i$. For a loss function $\\mathcal{L}(\\cdot)$, the objective reads as:\n",
    "\\begin{equation}\n",
    "\\label{eq:training_error}\n",
    "    \\sum_i{\\mathcal{L}(\\Phi(\\mathbf{x}_i,\\mathbf{W}),y_i)}, \\quad\\quad\\quad\\quad\\quad\\quad(15)\n",
    "\\end{equation}\n",
    "for ease of notation, all model parameters are denoted as $\\mathbf{W}$.\n",
    "A variety of optimizers have been proposed and implemented for minimizing Eq. 15. Yet, \n",
    "due to the size of the network and training dataset, mainly first-order methods are being considered, i.e. strategies that rely only on the gradients (and not on second-order derivatives such as the Hessian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several gradient based optimizers are commonly used for updating the parameters of the model. \n",
    "These NN parameters are updated in the opposite direction of the objective function's gradient, $g_{\\{\\text{GD},\\mathcal{T}(t)\\}}$, where $\\mathcal{T}(t)$ is a randomly chosen subgroup of size $n'<n$ training samples used in iteration $t$ ($n$ is the size of the training dataset). Namely, at iteration $t$ the weights are calculated as\n",
    "\\begin{equation}\\label{eq:update_weights}\n",
    "\\mathbf{W}(t)=\\mathbf{W}(t-1)-\\eta \\cdot g_{\\{\\text{GD},\\mathcal{T}(t)\\}}, \\quad\\quad\\quad\\quad\\quad\\quad(16)\n",
    "\\end{equation}\n",
    "where $\\eta$ is the learning rate that determines the size of the steps taken to reach the (local) minimum and the gradient step, $g_{\\text{\\{GD},\\mathcal{T}(t)\\}}$ is computed using the samples in $\\mathcal{T}(t)$ as\n",
    "\\begin{equation}\\label{eq:GD}\n",
    "g_{\\text{\\{GD},\\mathcal{T}(t)\\}} = \\frac{1}{n'}\\sum_{i\\in \\mathcal{T}(t)}\\nabla _{W}\\mathcal{L}(\\mathbf{W} (t);\\mathbf{x}_i;y_i), \\quad\\quad\\quad\\quad\\quad(17)\n",
    "\\end{equation}\n",
    "where the pair $(\\mathbf{x}_i,y_i)$ is a training example and its corresponding label in the training set, and $\\mathcal{L}$ is the loss function. \n",
    "However, needless to say that calculating the gradient on the whole dataset is computationally demanding. \n",
    "To this end, Stochastic Gradient Descent (SGD) is more popular, since it calculates the gradient in Eq. 17 for only one randomly chosen example from the data, i.e., $n'=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since the update by SGD depends on a different sample at each iteration, it has a high variance that causes the loss value to fluctuate. \n",
    "While this behavior may enable it to jump to a new and potentially better local minima, it might ultimately complicates convergence, as SGD may keep overshooting. \n",
    "To improve convergence and exploit parallel computing power, mini-batch SGD is proposed in which the gradient in Eq. 17 is calculated with $n'>1$ (but not all the data).\n",
    "\n",
    "An acceleration in convergence may be obtained by using the history of the last gradient steps, in order to stabilize the optimization. One such approach uses adaptive momentum instead of a fixed step size. This is calculated based on exponential smoothing on the gradients, i.e:\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    M(t)&=\\beta\\cdot M(t-1)+(1-\\beta)\\cdot g_{\\{\\text{SGD},\\mathcal{T}(t)\\}},\\\\\n",
    "    \\mathbf{W}(t)&=\\mathbf{W}(t-1)-\\eta M(t), \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad (18)\n",
    "\\end{aligned}\n",
    "\\end{equation}    \n",
    "where $M(t)$ approximates the $1^\\text{st}$ moment of $g_{\\{\\text{SGD},\\mathcal{T}(t)\\}}$. A typical value for the constant is $\\mbox{$\\beta\\sim 0.9$}$, which implies taking into account the last $10$ gradient steps in the momentum variable $M(t)$ [95]. \n",
    "\n",
    "A well-known variant of Momentum proposed by Nestrov $\\textit{et al.}$ [85] is the Nestrov Accelerated Gradient (NAG). It is similar to Momentum but calculates the gradient step as if the network weights have been already updated with the current Momentum direction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Another popular technique is the Adaptive Moment Estimation (ADAM) [61], which also computes adaptive learning rates. In addition to storing an exponentially decaying average of past squared gradients, $V(t)$, ADAM also keeps an exponentially decaying average of past gradients, $M(t)$, in the following way:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "M(t)&=\\beta_1M(t-1)+(1-\\beta_1)g_t, \\\\\n",
    "V(t)&=\\beta_2V(t-1)+(1-\\beta_2)g_t^2, \\quad \\quad (19)\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "where $g_t$ is the gradient of the current batch, $\\beta_1$ and $\\beta_2$ are ADAM's hyperparameters, usually set to 0.9 and 0.999 respectively, and $M(t)$ and $V(t)$ are estimates of the first moment (the mean) and the second moment (the uncentered variance) of the gradients respectively. Hence the name of the method - Adaptive Moment Estimation.\n",
    "As $M(t)$ and $V(t)$ are initialized as vectors of 0’s, the authors of ADAM observe that they are biased towards zero, especially during the initial time steps. To counteract these biases, a bias-corrected first and second moment are used: $\\mbox{$\\hat{M}(t)=M(t)/(1-\\beta_1(t))$}$ and $\\mbox{$\\hat{V}(t)=V(t)/(1-\\beta_2(t))$}$. Therefore, the ADAM update rule is as follows:\n",
    "\\begin{equation}\n",
    "\\mathbf{W}(t+1)=\\mathbf{W}(t)-\\frac{\\eta}{\\sqrt{\\hat{V}(t)+\\epsilon}}\\hat{M}(t). \\quad \\quad (20)\n",
    "\\end{equation}\n",
    "ADAM has two popular extensions: AdamW by Loshchilov $\\textit{et al.}$ [78] and AMSGrad by Redddi $\\textit{et al.}$ [97]. \n",
    "There are several additional common optimizers that have adaptive momentum, such as AdaGrad [29], AdaDelta [146] or RMSprop [21].\n",
    "It must be noted that since the NN optimization is non-convex, the minimal error point reached by each optimizer is rarely the same. Thus, speedy convergence is not always favored. In particular, it has been observed that Momentum leads to better generalization than ADAM, which usually converges faster [60]. Thus, the common practice is to make the development with ADAM and then make the final training with Momentum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cat_crop.png](2003.03253v1-resources/20031.03253v1-pics/cat_crop.png)\n",
    "\n",
    "![cat_flip.png](2003.03253v1-resources/20031.03253v1-pics/cat_flip.png)\n",
    "\n",
    "![cat_noised.png](2003.03253v1-resources/20031.03253v1-pics/cat_noised.png)\n",
    "\n",
    "![cat.png](2003.03253v1-resources/20031.03253v1-pics/cat.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig. 9: Different image augmentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Training regularizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great advantageous of NN is their ability to generalize, i.e., correctly predict unseen data [52]. This must be ensured during the training process and is accomplished by several regularization methods, detailed here. \n",
    "The most common are weight decay [63], dropout [121], batch normalization [50] and the use of data augmentation [166]. \n",
    "\n",
    "$\\textit{Weight decay}$ is a basic tool to limit the growth of the weights by adding a regularization term to the cost function for large weights, which is  the sum of squares of all the weights, i.e., $\\sum_i |W_i|^2$. \n",
    "\n",
    "The key idea in $\\textit{dropout}$ is to randomly drop units (along with their connections) from the neural network during training and thus prevent units from co-adapting too much. The percentage of dropped units is critical since a large amount will result in poor learning. Common values are $20\\%-50\\%$ dropped units. \n",
    "\n",
    "$\\textit{Batch normalization}$ is a mean to deal with changes in the distribution of the model's parameters during training. The layers need to adapt to these (often noisy) changes between instances during training. Batch normalization causes the features of each training batch to have a mean of 0 and a variance of 1 in the layer it is being applied.\n",
    "To normalize a value across a batch, i.e. to batch normalize the value, the batch mean, $\\mu _B$, is subtracted and the result is divided by the batch standard deviation, $\\sqrt{\\sigma _B^2+\\epsilon}$. Note that a small constant $\\epsilon$ is added to the variance in order to avoid dividing by zero. The batch normalizing transform of a given input, $\\mathbf{x}$, is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{BN}(\\mathbf{x})=\\gamma \\Bigg( \\frac{\\mathbf{x}-\\mu_B}{\\sqrt{\\sigma _B^2+\\epsilon}}\\Bigg)+\\beta. \\quad (21)\n",
    "\\end{equation}\n",
    "\n",
    "Notice the (learnable) scale and bias parameters $\\gamma$ and $\\beta$, which provides the NN with freedom to deviate from the zero mean and unit variance.\n",
    "BN is less effective when used with small batch sizes since in this case the statistics calculated per each is less accurate. Thus, techniques such as group normalization [139] or Filter Response Normalization (FRN) [118] have been proposed.\n",
    "\n",
    "$\\textit{Data augmentation}$ is a very common strategy used during training to artificially \"increase\" the size of the training data and make the network robust to transformations that do not change the input label. \n",
    "For example, in the task of classification a shifted cat is still a cat; see Fig. 9 for more similar augmentation. In the task of denoising, flipped noisy input should result in a flipped clean output. Thus, during training the network is trained also with the transformed data to improve its performance. \n",
    "\n",
    "Common augmentations are randomly flipping, rotating, scaling, cropping, translating, or adding noise to the data. Other more sophisticated techniques that lead to a significant improvement in network performance include mixup [147], cutout [26] and augmentations that are learned automatically [18, 71, 19]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Advanced NN architectures\n",
    "\n",
    "The basic building blocks, which compose the NN model architecture, are used in frequently innovative structures.\n",
    "In this section, such known architectures with state-of-the-art performance are presented, divided by tasks and data types: detection and segmentation  tasks are described in Section 7.1, sequential data handling is elaborated in Section 7.2 and processing data on irregular grids is presented in Section 7.3. Clearly, there are many other use-cases and architectures, which are not mentioned here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Deep learning for detection and segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many research works focus on detecting multiple objects in a scene, due to its numerous applications. This problem can be divided into four sub-tasks as follows, where we refer here to image datasets although the same concept can be applied to different domains as well.\n",
    "\n",
    "\n",
    "1. $\\textit{Classification and localization}$: The main object in the image is detected and then localized by a surrounding bounding box and classified from a pre-known set.\n",
    "2. $\\textit{Object detection}$: Detection of all objects in a scene that belong to a pre-known set and then classifying and providing a bounding box for each of them.\n",
    "3. $\\textit{Semantic segmentation}$:  Partitioning the image into coherent parts by assigning each pixel in the image with its own classification label (associated with the object the pixel belongs to). For example, having a pixel-wise differentiation between animals, sky and background (generic class for all object that no class is assigned to) in an image.\n",
    "4. $\\textit{Instance segmentation}$: Multiple objects segmentation and classification from a pre-known set (similar to object detection but for each object all its pixels are identified instead of providing a bounding box for it).\n",
    "\n",
    "\n",
    "Today, state-of-the-art object detection performance is achieved with architectures such as Faster-RCNN [103, 135],, You Only Look Once (YOLO)  [98, 99, 100], Single Shot Detector (SSD) [75] and Fully Convolutional One-Stage Object Detection (FCOS) [150].\n",
    "The object detection models provide a list of detected bounding boxes with the class of each of them.\n",
    "\n",
    "Segmentation tasks are mostly implemented using fully convolutional network. Known segmentation models include UNet [104], Mask-RCNN [44] and Deeplab [11]. These architecture have the same input/output spatial size since the output represents the segmentation map of the input image. \n",
    "\n",
    "Both object detection and segmentation tasks are analyzed via the Intersection over Union (IoU) metric. The IoU is defined as the ratio between the intersection area of the object's ground-truth pixels, $B_g$, with the corresponding predicted pixels, $B_p$, and the union of these group of pixels. The IoU is formulated as:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{IoU}=\\frac{\\text{Area}\\{B_g\\cap B_p\\}}{\\text{Area}\\{B_g\\cup B_p\\}}. \\quad \\quad (22)\n",
    "\\end{equation} \n",
    "\n",
    "As this measure evaluate only the quality of the bounding box, a mean Average Precision (mAP) is commonly used to evaluate the models performance. \n",
    "The mAP is defined as the ratio of the correctly detected (or segmented) objects, where an object is considered to be detected correctly if there is a bounding box for it with the correct class and a  IoU greater than 0.5 (or another specified constant). \n",
    "\n",
    "Another common evaluation metric is the F1 score, which is the harmonic average of the precision and the recall values. See Eq. (24) below. They are calculated using the following definitions that are presented for the case of semantic segmentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- True Positive (TP): the predicted class of a pixel matches it ground-truth label.\n",
    "- False Positive (FP): the predicted pixel of an object was falsely determined.\n",
    "- False Negative (FN): a ground-truth pixel of an object was not predicted.\n",
    "\n",
    "Now that they are defined, the precision, recall and F1 are given by:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{precision}=\\frac{\\text{TP}}{\\text{TP}+\\text{FP}},\\hspace{10pt}\n",
    "    \\text{recall}=\\frac{\\text{TP}}{\\text{TP}+\\text{FN}}\n",
    "    \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(23)\n",
    "\\end{equation}\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\\begin{equation}\\label{eq:F1_score}\n",
    "    \\text{F1}=2\\cdot\\frac{\\text{precision}\\cdot\\text{recall}}{\\text{precision}+\\text{recall}}.    \n",
    "    \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(24)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Deep learning on sequential data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential data are composed of time-sensitive signals such as the output of different sensors, audio recordings, NLP sentences or any signal that its order is of importance. Therefore, this data must be processed accordingly. \n",
    "\n",
    "Initially, sequential data was processed with Recurrent NN (RNN) [51] that has recurrent (feedback) connections, where outputs of the network at a given time-step serve as input to the model (in addition to the input data) at the next time-step. This introduces the time dependent feature of the NN. A RNN is illustrated in Fig. 4. \n",
    "\n",
    "However, it was quickly realized that during training, vanilla RNNs suffer from vanishing/exploding gradients. This phenomena, originated from the use of finite-precision back-propagation process, limits the size of the sequence. \n",
    "\n",
    "To this end, a corner stone block is used: the Long-Short-Term-Memory (LSTM [46]). Mostly used for NLP tasks, the LSTM is a RNN block with gates. \n",
    "During training, these gates learn which part of the sentence to forget or to memorize. \n",
    "The gating allow some of the gradients to backpropagate unchanged, which aids the vanishing gradient symptom.\n",
    "Notice that RNNs (and LSTMs) can process a sentence in a bi-directional mode, i.e., process a sentence in two directions, from the beginning to the end and vice verse. This mechanism allows a better grasp of the input context by the network.\n",
    "Examples for popular research tasks in NLP data include question answering [96], translation [65] and  text generation [41]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\bf Sentences processing.}$ An important issue in NLP is representing words in preparation to serve as network input.\n",
    "The use of straight forward indices is not effective since there are thousands of words in a language. \n",
    "Therefore, it is common to process text data via $\\textit{word embedding}$, which is a vector representation of each word in some fixed dimension. This method enables to encapsulate relationships between words. \n",
    "\n",
    "A classic methodology to calculate the word embedding is $\\textit{Word2Vec}$ [81], in which these vector representations are calculated using a NN model that learn their context. \n",
    "More advanced options for creating efficient word representations include BERT [25], ELMO [92], RoBERTa [77] and XLNet [144].\n",
    "\n",
    "${\\bf Audio processing.}$ Audio recordings are used for multiple interesting tasks, such as speech to text, text to speech and speech processing. \n",
    "In the audio case, the common input to speech systems is the Mel Frequency Cepstral Coefficient (MFCC) or a Short Time Fourier Transform (STFT) image, as opposed to the audio raw-data.\n",
    "A milestone example for speech processing NN architecture is the $\\textit{wavenet}$ [89]. This architecture is an autoregressive model that synthesizes speech or audio signals. It is based on dilated convolutional layers that have large receptive fields, that allow efficient processing. Another prominent synthesis model for sequential data is the Tacotron [113].\n",
    "\n",
    "${\\bf The attention model.}$\n",
    "As mentioned in Section 2, one may use RNN for translation using the encoder decoder model, which encodes a source sentence into a vector, which is then decoded to a target language. \n",
    "Instead of relying on a compressed vector, which may lose information, the $\\textit{attention models}$ learn where or what to focus on from the whole input sequence. \n",
    "Introduced in 2015 [3], attention models have shown superior performance over encoder-decoder architectures in tasks such as translation, text to speech and image captioning.\n",
    "Recently, it has been suggested to replace the recurrent network structure totally by the attention mechanism, which results with the $\\textit{transformers network}$ models [131]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Deep learning on irregular grids\n",
    "\n",
    "A wide variety of data acquisition mechanisms do not represent the data on a grid as is common with images data. A prominent example is 3D imaging (e.g. using LIDAR), where the input data are represented as points in a 3D space with or without color information. \n",
    "Processing such data is not trivial as standard network components, such as convolutions, assume a grid of the data. Therefore, they cannot be applied as is and custom operations are required. We focus our discussion here on the case of NN for 3D data.\n",
    "\n",
    "Today, real-time processing of 3D scenes can be achieved with advanced NN models that are customized to these irregular grids. The different processing techniques for these irregular grid data can be divided by the type of representation used for the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ${\\bf Points processing.}$ 3D data points are processed as points in space, i.e., a list of the point coordinates is given as the input to the NN. A popular network for this representation is  $\\textit{PointNet}$ [93]. It is the first to efficiently achieve satisfactory results directly on the point cloud. Yet, it is limited by the number of points that can be analyzed, computational time and performance. Some more recent models that improves its performance include PointNet++ [94], PointCNN [69], DGCNN [136]. Strategies to improve its efficiency have been proposed in learning to sample [28] and RandLA-Net [48].\n",
    "\n",
    "\n",
    "2. ${\\bf Multi-view 2D projections.}$ 3D data points are projected (from various angles) to the 2D domain so that known 2D processing techniques can be used [70, 56]. \n",
    "\n",
    "\n",
    "3. ${\\bf Volumetric (voxels).}$ 3D data points are represented in a grid-based $\\textit{voxel}$ representation. This is analogous to a 2D representation and is therefore advantageous. However, it is computationally exhaustive [140] and losses resolution.\n",
    "\n",
    "\n",
    "4. ${\\bf Meshes.}$ Mesh represents the 3D domain via a graph that defines the connectivity between the different points. Yet, this graph has a special structure such that it creates the surface of the 3D shape (in the common case of triangular mesh, the shape surface is presented by a set of triangles connected to each other).\n",
    "    In 2015 Masci $\\textit{et al.}$ [6] have shown it is possible to learn features using DL on meshes. Since then, a significant advancement has been made in mesh processing [43, 83].\n",
    "\n",
    "\n",
    "5. ${\\bf Graphs.}$ Graph representations are common for representing non-linear structured data. Some works have proposed efficient NN models for 3D data points on a grid-based graph structure [122, 86]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter provided a general survey of the basic concepts in neural networks. As\n",
    "this field is expanding very fast, the space is too short to describe all the developments\n",
    "in it, even though most of them are from the past eight years. Yet, we briefly mention\n",
    "here few important problems that are currently being studied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. ${\\bf Domain adaptation and transfer learning.}$ As many applications necessitate data that is very difficult to obtain, some methods aim at training models based on scarce datasets.\n",
    "    A popular methodology for dealing with insufficient annotated data is $\\textit{domain adaptation}$, in which a robust and high performance NN model, trained on a source distribution, is used to aid the training of a similar model (usually with the same goal, e.g., in classification the same classes are searched for) on data from a target distribution that are either  unlabelled or small in number [33, 90, 117]. \n",
    "    An example is adapting a NN trained on simulation data to real-life data with the same labels  [130, 47]. \n",
    "    On a similar note, $\\textit{transfer learning}$ [128, 27] can also be used in similar cases, where in addition to the difference in the data, the input and output tasks are not the same but only similar (in domain adaptation the task is the same and only the distributions are different). One such example, is using a network trained on natural images to classify medical  data [4]. \n",
    "\n",
    "\n",
    "2. ${\\bf Few shot learning.}$ A special case of learning with small datasets is $\\textit{few-shot learning}$ [137], where one is provided either with just semantic information of the target classes (zero-shot learning), only one labelled example per class (1-shot learning) or just few samples (general few-shot learning). \n",
    "    Approaches developed for these problems have shown great success in many applications, such as image classification [125, 111, 123], object detection [57] and segmentation [8].\n",
    "    \n",
    "\n",
    "3. ${\\bf On-line learning.}$ Various deep learning challenges occur due to new distributions or class types introduced to the model during a continuous operation of the system (post-training), and now must be learnt by the model. The model can update its weights to incorporate these new data using $\\textit{on-line learning}$ techniques. \n",
    "    There is a need for special training in this case, as  systems that just learn based on the new examples may suffer from a reduced performance on the original data. This phenomena is known as catastrophic forgetting [59]. Often, the model tends to forget the representation of part of the distribution it already learned and thus it develops a bias towards the new data. \n",
    "    A specific example of on-line learning is $\\textit{incremental learning}$ [9], where the new data is of different classes than the original ones.   \n",
    "\n",
    "\n",
    "4. ${\\bf AutoML.}$ When approaching real-life problems, there is an inherent pipeline of tasks to be preformed before using DL tools, such as problem definition, preparing the data and processing it.\n",
    "    Commonly, these tasks are preformed by specialists and require deep system understating. \n",
    "    To this end, the $\\textit{autoML}$ paradigm attempts to generalize this process by automatically learning and tuning the model used [32]. \n",
    "    A particular popular task in autoML is $\\textit{Neural  Architecture Search (NAS)}$ [30]. This is of interest since the NN architecture restricts its performance. \n",
    "    However, searching for the optimal architecture for a specific task, and from a set of pre-defined operations, is computationally exhaustive when performed in a straight forward manner. \n",
    "    Therefore, on-going research attempts to overcome this limitation. An example is the DARTS [74] strategy and its extensions [87, 12] where the key contribution is finding, in a differentiable manner, the connections between network operations that form a NN architecture. This framework decreases the search time and improves the final accuracy.\n",
    "\n",
    "\n",
    "5. ${\\bf Reinforcement Learning.}$ To date, the most effective training method for decision based actions, such as robot movement and video games, is $\\textit{Reinforcement Learning}$ (RL) [55, 127]. In RL, the model tries to maximize some pre-defined award score by learning which action to take, from a set of defined actions in specific scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, being able to efficiently train deep neural networks has revolutionized almost every aspect of the modern day-to-day life. Examples span from bio-medical applications through computer graphics in movies and videos to international scale applications of big companies, such as Google, Amazon, Microsoft, Apple and Facebook.\n",
    "Evidently, this theory is drawing much attention and we believe there is still much to unravel, including exploring and understanding the NN's potential abilities and limitations.\n",
    "\n",
    "The next chapters detail Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), generative models and autoencoders. All are very important paradigms that are used in numerous applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References from original paper <a id=\"ReferencesOGPaper\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "1. Achlioptas, P., Diamanti, O., Mitliagkas, I., Guibas, L.: Learning representations and generative models for 3D point clouds. In: J. Dy, A. Krause (eds.) Proceedings of the 35th\n",
    "International Conference on Machine Learning, Proceedings of Machine Learning Research,\n",
    "vol. 80, pp. 40–49. PMLR, StockholmsmÃďssan, Stockholm Sweden (2018)\n",
    "2. Atlason, H.E., AskellLove, Sigurdsson, S., Gudnason, V., Ellingsen, L.M.: Unsupervised brain\n",
    "lesion segmentation from mri using a convolutional autoencoder. In: Medical Imaging 2019:\n",
    "Image Processing, vol. 10949, p. 109491H. International Society for Optics and Photonics\n",
    "(2019)\n",
    "3. Bahdanau, D., Cho, K., Bengio, Y.: Neural machine translation by jointly learning to align\n",
    "and translate. In: 3rd International Conference on Learning Representations, ICLR (2015)\n",
    "4. Bar, Y., Diamant, I., Wolf, L., Greenspan, H.: Deep learning with non-medical training used\n",
    "for chest pathology identification. In: Medical Imaging 2015: Computer-Aided Diagnosis,\n",
    "vol. 9414, pp. 215 – 221. International Society for Optics and Photonics, SPIE (2015)\n",
    "5. Ben-Cohen, A., Diamant, I., Klang, E., Amitai, M., Greenspan, H.: Fully convolutional\n",
    "network for liver segmentation and lesions detection. In: Deep learning and data labeling for\n",
    "medical applications, pp. 77–85. Springer (2016)\n",
    "6. Boscaini, D., Masci, J., Melzi, S., Bronstein, M.M., Castellani, U., Vandergheynst, P.: Learning class-specific descriptors for deformable shapes using localized spectral convolutional\n",
    "networks. Comput. Graph. Forum 34, 13–23 (2015)\n",
    "7. Brock, A., Donahue, J., Simonyan, K.: Large scale GAN training for high fidelity natural\n",
    "image synthesis. In: International Conference on Learning Representations (ICLR) (2019)\n",
    "8. Caelles, S., Maninis, K.K., Pont-Tuset, J., Leal-Taixé, L., Cremers, D., Van Gool, L.: One-shot\n",
    "video object segmentation. In: Proceedings of the IEEE conference on computer vision and\n",
    "pattern recognition, pp. 221–230 (2017)\n",
    "9. Castro, F.M., Marín-Jiménez, M.J., Guil, N., Schmid, C., Alahari, K.: End-to-end incremental\n",
    "learning. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 233–\n",
    "248 (2018)\n",
    "10. Chen, L.C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H.: Encoder-decoder with atrous\n",
    "separable convolution for semantic image segmentation. In: Proceedings of the European\n",
    "conference on computer vision (ECCV), pp. 801–818 (2018)\n",
    "11. Chen, L.C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H.: Encoder-decoder with atrous\n",
    "separable convolution for semantic image segmentation. In: ECCV (2018)\n",
    "12. Chen, X., Xie, L., Wu, J., Tian, Q.: Progressive darts: Bridging the optimization gap for nas\n",
    "in the wild. arXiv preprint arXiv:1912.10952 (2019)\n",
    "13. Chen, Z., Zhang, J., Tao, D.: Progressive lidar adaptation for road detection. IEEE/CAA\n",
    "Journal of Automatica Sinica 6(3), 693–702 (2019)\n",
    "14. Cho, K., van Merriënboer, B., Bahdanau, D., Bengio, Y.: On the properties of neural machine\n",
    "translation: Encoder–decoder approaches. In: Workshop on Syntax, Semantics and Structure\n",
    "in Statistical Translation, pp. 103–111. Association for Computational Linguistics (2014)\n",
    "15. Clevert, D.A., Unterthiner, T., Hochreiter, S.: Fast and accurate deep network learning by\n",
    "exponential linear units (elus). CoRR (2015)\n",
    "16. Cortes, C., Vapnik, V.: Support vector networks. Machine Learning 20, 273–297 (1995)\n",
    "17. Cristianini, N., Shawe-Taylor, J.: An Introduction to Support Vector Machines and Other\n",
    "Kernel-based Learning Methods. Cambridge University Press (2000). DOI 10.1017/\n",
    "CBO9780511801389\n",
    "18. Cubuk, E.D., Zoph, B., Mane, D., Vasudevan, V., Le, Q.V.: Autoaugment: Learning augmentation strategies from data. In: The IEEE Conference on Computer Vision and Pattern\n",
    "Recognition (CVPR) (2019)\n",
    "19. Cubuk, E.D., Zoph, B., Shlens, J., Le, Q.V.: Randaugment: Practical automated data augmentation with a reduced search space. arXiv (2019)\n",
    "20. Dahl, G.E., Sainath, T.N., Hinton, G.E.: Improving deep neural networks for lvcsr using\n",
    "rectified linear units and dropout. In: ICASSP, pp. 8609–8613. IEEE (2013)\n",
    "21. Dauphin, Y.N., de Vries, H., Chung, J., Bengio, Y.: Rmsprop and equilibrated adaptive\n",
    "learning rates for non-convex optimization. CoRR (2015)\n",
    "22. Deng, J., Dong, W., Socher, R., jia Li, L., Li, K., Fei-fei, L.: Imagenet: A large-scale hierarchical image database. CVPR (2009)\n",
    "23. Deng, J., Guo, J., Xue, N., Zafeiriou, S.: Arcface: Additive angular margin loss for deep face\n",
    "recognition. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n",
    "(2019)\n",
    "24. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of deep bidirectional\n",
    "transformers for language understanding (2018)\n",
    "25. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of deep bidirectional\n",
    "transformers for language understanding. In: NAACL-HLT (2019)\n",
    "26. DeVries, T., Taylor, G.W.: Improved regularization of convolutional neural networks with\n",
    "cutout. arXiv (2017)\n",
    "27. Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell, T.: Decaf: A\n",
    "deep convolutional activation feature for generic visual recognition. In: E.P. Xing, T. Jebara\n",
    "(eds.) Proceedings of the 31st International Conference on Machine Learning, Proceedings\n",
    "of Machine Learning Research, vol. 32, pp. 647–655. PMLR, Bejing, China (2014)\n",
    "28. Dovrat, O., Lang, I., Avidan, S.: Learning to sample. In: The IEEE Conference on Computer\n",
    "Vision and Pattern Recognition (CVPR) (2019)\n",
    "29. Duchi, J., Hazan, E., yORAM Singer: Adaptive subgradient methods for online learning and\n",
    "stochastic optimization. J. Mach. Learn. Res. 12, 2121–2159 (2011)\n",
    "30. Elsken, T., Metzen, J.H., Hutter, F.: Neural architecture search: A survey. J. Mach. Learn.\n",
    "Res. 20, 55:1–55:21 (2018)\n",
    "31. van Engelen, J.E., Hoos, H.H.: A survey on semi-supervised learning. Machine Learning (2019). DOI 10.1007/s10994-019-05855-6. URL https://doi.org/10.1007/\n",
    "s10994-019-05855-6\n",
    "32. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F.: Efficient and robust automated machine learning. In: C. Cortes, N.D. Lawrence, D.D. Lee,\n",
    "M. Sugiyama, R. Garnett (eds.) Advances in Neural Information Processing Systems 28,\n",
    "pp. 2962–2970. Curran Associates, Inc. (2015). URL http://papers.nips.cc/paper/\n",
    "5872-efficient-and-robust-automated-machine-learning.pdf\n",
    "33. Ganin, Y., Lempitsky, V.: Unsupervised domain adaptation by backpropagation. arXiv\n",
    "preprint arXiv:1409.7495 (2014)\n",
    "34. Gao, C., Gu, D., Zhang, F., Yu, Y.: Reconet: Real-time coherent video style transfer network.\n",
    "In: Asian Conference on Computer Vision, pp. 637–653. Springer (2018)\n",
    "35. Gatys, L.A., Ecker, A.S., Bethge, M.: Image style transfer using convolutional neural networks.\n",
    "In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2414–\n",
    "2423 (2016)\n",
    "36. Gatys, L.A., Ecker, A.S., Bethge, M.: Image style transfer using convolutional neural networks.\n",
    "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) pp. 2414–2423\n",
    "(2016)\n",
    "37. Gers, F.A., Schmidhuber, J., Cummins, F.: Learning to forget: Continual prediction with lstm.\n",
    "ICANN (1999)\n",
    "38. Gibiansky, A., Arik, S., Diamos, G., Miller, J., Peng, K., Ping, W., Raiman, J., Zhou, Y.: Deep\n",
    "voice 2: Multi-speaker neural text-to-speech. In: Advances in neural information processing\n",
    "systems, pp. 2962–2970 (2017)\n",
    "39. Goodfellow, I., Jean Pouget-Abadieand, M.M., Xu, B., Warde-Farley, D., Ozair, S., Courville,\n",
    "A., Bengio, Y.: Generative adversarial nets. In: Z. Ghahramani, M. Welling, C. Cortes, N.D.\n",
    "Lawrence, K.Q. Weinberger (eds.) Advances in Neural Information Processing Systems 27,\n",
    "pp. 2672–2680. Curran Associates, Inc. (2014)\n",
    "40. Greenspan, H., van Ginneken, B., Summers, R.M.: Guest editorial deep learning in medical\n",
    "imaging: Overview and future promise of an exciting new technique. CVPR 35, 1153 – 1159\n",
    "(2016)\n",
    "41. Guo, J., Lu, S., Cai, H., Zhang, W., Yu, Y., Wang, J.: Long text generation via adversarial training with leaked information. In: Thirty-Second AAAI Conference on Artificial Intelligence\n",
    "(2018)\n",
    "42. Haim, H., Elmalem, S., Giryes, R., Bronstein, A.M., Marom, E.: Depth estimation from a\n",
    "single image using deep learned phase coded mask. IEEE Transactions on Computational\n",
    "Imaging 4(3), 298–310 (2018)\n",
    "43. Hanocka, R., Hertz, A., Fish, N., Giryes, R., Fleishman, S., Cohen-Or, D.: Meshcnn: A\n",
    "network with an edge. ACM Transactions on Graphics (TOG) 38(4), 90 (2019)\n",
    "44. He, K., Gkioxari, G., Dollár, P., Girshick, R.B.: Mask r-cnn. IEEE International Conference\n",
    "on Computer Vision (ICCV) pp. 2980–2988 (2017)\n",
    "45. Hinton, G.E., Osindero, S., Teh, Y.W.: A fast learning algorithm for deep belief nets. Neural\n",
    "Comput. 18(7), 1527–1554 (2006). DOI 10.1162/neco.2006.18.7.1527. URL http://dx.\n",
    "doi.org/10.1162/neco.2006.18.7.1527\n",
    "46. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Comput. 9(8), 1735–1780\n",
    "(1997). DOI 10.1162/neco.1997.9.8.1735\n",
    "47. Hoffman, J., Tzeng, E., Park, T., Zhu, J.Y., Isola, P., Saenko, K., Efros, A., Darrell, T.:\n",
    "CyCADA: Cycle-consistent adversarial domain adaptation. In: J. Dy, A. Krause (eds.) Proceedings of the 35th International Conference on Machine Learning, Proceedings of Machine\n",
    "Learning Research, vol. 80, pp. 1989–1998. PMLR, StockholmsmÃďssan, Stockholm Sweden\n",
    "(2018)\n",
    "48. Hu, Q., Yang, B., Xie, L., Rosa, S., Guo, Y., Wang, Z., Trigoni, N., Markham, A.: Randla-net:\n",
    "Efficient semantic segmentation of large-scale point clouds. arXiv preprint arXiv:1911.11236\n",
    "(2019)\n",
    "49. Hubel, D.H., Wiesel, T.N.: Receptive fields of single neurons in the cat’s striate cortex. Journal\n",
    "of Physiology 148, 574–591 (1959)\n",
    "50. Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing\n",
    "internal covariate shift. In: Proceedings of the 32nd International Conference on Machine\n",
    "Learning, vol. 37, pp. 448–456 (2015)\n",
    "51. Jain, L.C., Medsker, L.R.: Recurrent Neural Networks: Design and Applications, 1st edn.\n",
    "CRC Press, Inc., Boca Raton, FL, USA (1999)\n",
    "52. Jakubovitz, D., Giryes, R., Rodrigues, M.R.D.: Generalization Error in Deep Learning, pp.\n",
    "153–193. Springer International Publishing, Cham (2019)\n",
    "53. Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and superresolution. In: European conference on computer vision, pp. 694–711. Springer (2016)\n",
    "54. Kadlec, R., Schmid, M., Bajgar, O., Kleindienst, J.: Text understanding with the attention sum\n",
    "reader network. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 908–918. Association for Computational\n",
    "Linguistics, Berlin, Germany (2016). DOI 10.18653/v1/P16-1086\n",
    "55. Kaelbling, L.P., Littman, M.L., Moore, A.W.: Reinforcement learning: A survey. Journal of\n",
    "artificial intelligence research 4, 237–285 (1996)\n",
    "56. Kalogerakis, E., Averkiou, M., Maji, S., Chaudhuri, S.: 3d shape segmentation with projective\n",
    "convolutional networks. 2017 IEEE Conference on Computer Vision and Pattern Recognition\n",
    "(CVPR) pp. 6630–6639 (2016)\n",
    "57. Karlinsky, L., Shtok, J., Harary, S., Schwartz, E., Aides, A., Feris, R., Giryes, R., Bronstein,\n",
    "A.M.: Repmet: Representative-based metric learning for classification and few-shot object\n",
    "detection. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n",
    "(2019)\n",
    "58. Karras, T., Aila, T., Laine, S., Lehtinen, J.: Progressive growing of GANs for improved\n",
    "quality, stability, and variation. In: International Conference on Learning Representations\n",
    "(2018). URL https://openreview.net/forum?id=Hk99zCeAb\n",
    "59. Kemker, R., McClure, M., Abitino, A., Hayes, T.L., Kanan, C.: Measuring catastrophic\n",
    "forgetting in neural networks. In: Thirty-second AAAI conference on artificial intelligence\n",
    "(2018)\n",
    "60. Keskar, N.S., Socher, R.: Improving generalization performance by switching from adam to\n",
    "sgd. arXiv preprint arXiv:1712.07628 (2017)\n",
    "61. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. CoRR (2014)\n",
    "62. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional\n",
    "neural networks. In: F. Pereira, C.J.C. Burges, L. Bottou, K.Q. Weinberger (eds.) Advances in\n",
    "Neural Information Processing Systems 25, pp. 1097–1105. Curran Associates, Inc. (2012)\n",
    "63. Krogh, A., Hertz, J.A.: A simple weight decay can improve generalization. In: J.E.\n",
    "Moody, S.J. Hanson, R.P. Lippmann (eds.) Advances in Neural Information Processing Systems 4, pp. 950–957. Morgan-Kaufmann (1992). URL http://papers.nips.cc/paper/\n",
    "563-a-simple-weight-decay-can-improve-generalization.pdf\n",
    "64. Kwon, D., Kim, H., Kim, J., Suh, S.C., Kim, I., Kim, K.J.: A survey of deep learningbased network anomaly detection. Cluster Computing 22(1), 949–961 (2019). DOI 10.1007/\n",
    "s10586-017-1117-8\n",
    "65. Lample, G., Conneau, A., Denoyer, L., Ranzato, M.: Unsupervised machine translation using\n",
    "monolingual corpora only. arXiv preprint arXiv:1711.00043 (2017)\n",
    "66. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.:\n",
    "Backpropagation applied to handwritten zip code recognition. Neural Comput. 1(4), 541–\n",
    "551 (1989). DOI 10.1162/neco.1989.1.4.541. URL http://dx.doi.org/10.1162/neco.\n",
    "1989.1.4.541\n",
    "67. LeCun, Y., Boser, B.E., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.E., Jackel,\n",
    "L.D.: Hand-written digit recognition with a back-propagation network. NIPS (1990)\n",
    "68. Lecun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document\n",
    "recognition. In: Proceedings of the IEEE, pp. 2278–2324 (1998)\n",
    "69. Li, Y., Bu, R., Sun, M., Wu, W., Di, X., Chen, B.: Pointcnn: Convolution on x-transformed\n",
    "points. In: NeurIPS (2018)\n",
    "70. Li, Y., Pirk, S., Su, H., Qi, C.R., Guibas, L.J.: Fpnn: Field probing neural networks for 3d data. In: D.D. Lee, M. Sugiyama, U.V. Luxburg, I. Guyon,\n",
    "R. Garnett (eds.) Advances in Neural Information Processing Systems 29, pp.\n",
    "307–315. Curran Associates, Inc. (2016). URL http://papers.nips.cc/paper/\n",
    "6416-fpnn-field-probing-neural-networks-for-3d-data.pdf\n",
    "71. Lim, S., Kim, I., Kim, T., Kim, C., Kim, S.: Fast autoaugment. In: Advances in Neural\n",
    "Information Processing Systems (NeurIPS) (2019)\n",
    "72. Lin, T.Y., Goyal, P., Girshick, R., He, K., Dollár, P.: Focal loss for dense object detection. In:\n",
    "Proceedings of the IEEE international conference on computer vision, pp. 2980–2988 (2017)\n",
    "73. Liu, G., Reda, F.A., andx Ting-Chun Shih, K.J.S., Tao, A., Catanzaro, B.: Image inpainting\n",
    "for irregular holes using partial convolutions. In: The European Conference on Computer\n",
    "Vision (ECCV) (2018)\n",
    "74. Liu, H., Simonyan, K., Yang, Y.: DARTS: Differentiable architecture search. In: International\n",
    "Conference on Learning Representations (2019)\n",
    "75. Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S.E., Fu, C.Y., Berg, A.C.: Ssd: Single\n",
    "shot multibox detector. In: ECCV (2016)\n",
    "76. Liu, W., Wen, Y., Yu, Z., Li, M., Raj, B., Song, L.: Sphereface: Deep hypersphere embedding\n",
    "for face recognition. 2017 IEEE Conference on Computer Vision and Pattern Recognition\n",
    "(CVPR) pp. 6738–6746 (2017)\n",
    "77. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer,\n",
    "L., Stoyanov, V.: Roberta: A robustly optimized bert pretraining approach. arXiv preprint\n",
    "arXiv:1907.11692 (2019)\n",
    "78. Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. In: ICLR (2017)\n",
    "79. Ma, W.C., Wang, S., Hu, R., Xiong, Y., Urtasun, R.: Deep rigid instance scene flow. In:\n",
    "CVPR (2019)\n",
    "80. McCulloch, W.S., Pitts, W.: A logical calculus of the ideas immanent in nervous activity. The\n",
    "bulletin of mathematical biophysics 5(4), 115–133 (1943). DOI 10.1007/BF02478259\n",
    "81. Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J.: Distributed representations of words and phrases and their compositionality. In: C.J.C.\n",
    "Burges, L. Bottou, M. Welling, Z. Ghahramani, K.Q. Weinberger (eds.)\n",
    "Advances in Neural Information Processing Systems 26, pp. 3111–3119. Curran Associates, Inc. (2013). URL http://papers.nips.cc/paper/\n",
    "5021-distributed-representations-of-words-and-phrases-and-their-compositionality.\n",
    "pdf\n",
    "82. Minsky, M., Papert, S.: Perceptrons: An Introduction to Computational Geometry. MIT Press,\n",
    "Cambridge, MA, USA (1969)\n",
    "83. Monti, F., Boscaini, D., Masci, J., Rodolà, E., Svoboda, J., Bronstein, M.M.: Geometric\n",
    "deep learning on graphs and manifolds using mixture model cnns. In: IEEE Conference on\n",
    "Computer Vision and Pattern Recognition, CVPR, pp. 5425–5434 (2017). DOI 10.1109/\n",
    "CVPR.2017.576\n",
    "84. Nah, S., Kim, T.H., Lee, K.M.: Deep multi-scale convolutional neural network for dynamic\n",
    "scene deblurring. In: Proceedings of the IEEE Conference on Computer Vision and Pattern\n",
    "Recognition, pp. 3883–3891 (2017)\n",
    "85. Nesterov, Y.E.: A method for solving the convex programming problem with convergence\n",
    "rate o (1/kˆ 2). In: Dokl. akad. nauk Sssr, vol. 269, pp. 543–547 (1983)\n",
    "86. Niepert, M., Ahmed, M., Kutzkov, K.: Learning convolutional neural networks for graphs. In:\n",
    "Proceedings of the 33rd International Conference on International Conference on Machine\n",
    "Learning - Volume 48, ICML’16, pp. 2014–2023. JMLR.org (2016). URL http://dl.acm.\n",
    "org/citation.cfm?id=3045390.3045603\n",
    "87. Noy, A., Nayman, N., Ridnik, T., Zamir, N., Doveh, S., Friedman, I., Giryes, R., Zelnik-Manor,\n",
    "L.: Asap: Architecture search, anneal and prune. arXiv preprint arXiv:1904.04123 (2019)\n",
    "88. Ongie, G., Willett, R., Soudry, D., Srebro, N.: A function space view of bounded norm\n",
    "infinite width re{lu} nets: The multivariate case. In: International Conference on Learning\n",
    "Representations (ICLR) (2020)\n",
    "89. van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner,\n",
    "N., Senior, A., Kavukcuoglu, K.: Wavenet: A generative model for raw audio. In: Arxiv (2016).\n",
    "URL https://arxiv.org/abs/1609.03499\n",
    "90. Pan, S.J., Tsang, I.W., Kwok, J.T., Yang, Q.: Domain adaptation via transfer component\n",
    "analysis. IEEE Transactions on Neural Networks 22(2), 199–210 (2010)\n",
    "91. Pascanu, R., Mikolov, T., Bengio, Y.: On the difficulty of training recurrent neural networks.\n",
    "In: S. Dasgupta, D. McAllester (eds.) Proceedings of the 30th International Conference on\n",
    "Machine Learning, Proceedings of Machine Learning Research, vol. 28, pp. 1310–1318.\n",
    "PMLR, Atlanta, Georgia, USA (2013)\n",
    "92. Peters, M.E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., Zettlemoyer, L.: Deep\n",
    "contextualized word representations. In: Proc. of NAACL (2018)\n",
    "93. Qi, C.R., Su, H., Mo, K., Guibas, L.J.: Pointnet: Deep learning on point sets for 3d classification and segmentation. 2017 IEEE Conference on Computer Vision and Pattern Recognition\n",
    "(CVPR) pp. 77–85 (2016)\n",
    "94. Qi, C.R., Yi, L., Su, H., Guibas, L.J.: Pointnet++: Deep hierarchical feature learning on point\n",
    "sets in a metric space. arXiv preprint arXiv:1706.02413 (2017)\n",
    "95. Qian, N.: On the momentum term in gradient descent learning algorithms. Neural Networks\n",
    "12(1), 145–151 (1999)\n",
    "96. Radford, A., Sutskever, I.: Improving language understanding by generative pre-training. In:\n",
    "arxiv (2018)\n",
    "97. Reddi, S.J., Kale, S., Kumar, S.: On the convergence of adam and beyond. In: International\n",
    "Conference on Learning Representations (ICLR) (2018)\n",
    "98. Redmon, J., Divvala, S.K., Girshick, R.B., Farhadi, A.: You only look once: Unified, realtime object detection. 2016 IEEE Conference on Computer Vision and Pattern Recognition\n",
    "(CVPR) pp. 779–788 (2015)\n",
    "99. Redmon, J., Farhadi, A.: Yolo9000: Better, faster, stronger. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) pp. 6517–6525 (2016)\n",
    "100. Redmon, J., Farhadi, A.: Yolov3: An incremental improvement. ArXiv abs/1804.02767\n",
    "(2018)\n",
    "101. Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., Lee, H.: Generative adversarial text\n",
    "to image synthesis. In: Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48, ICMLâĂŹ16, p. 1060âĂŞ1069. JMLR.org\n",
    "(2016)\n",
    "102. Remez, T., Litany, O., Giryes, R., Bronstein, A.M.: Class-aware fully convolutional gaussian\n",
    "and poisson denoising. IEEE Transactions on Image Processing 27(11), 5707–5722 (2018)\n",
    "103. Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with\n",
    "region proposal networks. In: C. Cortes, N.D. Lawrence, D.D. Lee, M. Sugiyama, R. Garnett\n",
    "(eds.) Advances in Neural Information Processing Systems 28, pp. 91–99. Curran Associates,\n",
    "Inc. (2015)\n",
    "104. Ronneberger, O., P.Fischer, Brox, T.: U-net: Convolutional networks for biomedical image\n",
    "segmentation. In: Medical Image Computing and Computer-Assisted Intervention (MICCAI),\n",
    "LNCS, vol. 9351, pp. 234–241. Springer (2015)\n",
    "105. Rosenblatt, F.: The perceptron: A probabilistic model for information storage and organization\n",
    "in the brain. Psychological Review pp. 65–386 (1958)\n",
    "106. Ruck, D.W., Rogers, S.K.: Feature Selection Using a Multilayer Perceptron. Journal of Neural\n",
    "Network Computing 2(July 1993), 40–48 (1990)\n",
    "107. Rumelhart, D.E., Hinton, G.E.,Williams, R.J.: Learning Representations by Back-propagating\n",
    "Errors. Nature 323(6088), 533–536 (1986). DOI 10.1038/323533a0\n",
    "108. Safran, I., Eldan, R., Shamir, O.: Depth separations in neural networks: What is actually being\n",
    "separated? In: Conference on Learning Theory (COLT), pp. 2664–2666. PMLR (2019)\n",
    "109. Schroff, F., Kalenichenko, D., Philbin, J.: Facenet: A unified embedding for face recognition\n",
    "and clustering. CVPR pp. 815–823 (2015)\n",
    "110. Schwartz, E., Giryes, R., Bronstein, A.M.: Deepisp: Toward learning an end-to-end image\n",
    "processing pipeline. IEEE Transactions on Image Processing 28(2), 912–923 (2019). DOI\n",
    "10.1109/TIP.2018.2872858\n",
    "111. Schwartz, E., Karlinsky, L., Shtok, J., Harary, S., Marder, M., Kumar, A., Feris, R., Giryes,\n",
    "R., Bronstein, A.: Delta-encoder: an effective sample synthesis method for few-shot object\n",
    "recognition. In: S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, R. Garnett (eds.) Advances in Neural Information Processing Systems 31, pp. 2845–2855. Curran\n",
    "Associates, Inc. (2018)\n",
    "112. Shaham, T.R., Dekel, T., Michaeli, T.: Singan: Learning a generative model from a single\n",
    "natural image. In: The IEEE International Conference on Computer Vision (ICCV) (2019)\n",
    "113. Shen, J., Pang, R., Weiss, R.J., Schuster, M., Jaitly, N., Yang, Z., Chen, Z., Zhang, Y., Wang,\n",
    "Y., Skerrv-Ryan, R., Saurous, R.A., Agiomvrgiannakis, Y., Wu, Y.: Natural tts synthesis\n",
    "by conditioning wavenet on mel spectrogram predictions. In: International Conference on\n",
    "Acoustics, Speech and Signal Processing (ICASSP), pp. 4779–4783 (2018)\n",
    "114. Shiloh, L., Eyal, A., Giryes, R.: Efficient processing of distributed acoustic sensing data using\n",
    "a deep learning approach. J. Lightwave Technol. 37(18), 4755–4762 (2019)\n",
    "115. Shocher, A., Bagon, S., Isola, P., Irani, M.: Ingan: Capturing and retargeting the \"dna\" of a\n",
    "natural image. In: The IEEE International Conference on Computer Vision (ICCV) (2019)\n",
    "116. Shorten, C., Khoshgoftaar, T.M.: A survey on image data augmentation for deep learning.\n",
    "Journal of Big Data 6(1), 60 (2019). DOI 10.1186/s40537-019-0197-0\n",
    "117. Shu, R., Bui, H.H., Narui, H., Ermon, S.: A DIRT-T approach to unsupervised domain\n",
    "adaptation. In: 6th International Conference on Learning Representations, ICLR (2018)\n",
    "118. Singh, S., Krishnan, S.: Filter response normalization layer: Eliminating batch dependence\n",
    "in the training of deep neural networks. arXiv (2019)\n",
    "119. Sønderby, C.K., Raiko, T., Maaløe, L., Sønderby, S.K., Winther, O.: Ladder variational\n",
    "autoencoders. In: Advances in neural information processing systems, pp. 3738–3746 (2016)\n",
    "120. Sotelo, J., Mehri, S., Kumar, K., Santos, J.F., Kastner, K., Courville, A.C., Bengio, Y.:\n",
    "Char2wav: End-to-end speech synthesis. In: ICLR (2017)\n",
    "121. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.: Dropout: A\n",
    "simple way to prevent neural networks from overfitting. J. Mach. Learn. Res. 15(1), 1929–\n",
    "1958 (2014)\n",
    "122. Such, F.P., Sah, S., Domínguez, M., Pillai, S., Zhang, C., Michael, A., Cahill, N.D., Ptucha,\n",
    "R.W.: Robust spatial filtering with graph convolutional neural networks. IEEE Journal of\n",
    "Selected Topics in Signal Processing 11, 884–896 (2017)\n",
    "123. Sun, Q., Liu, Y., Chua, T.S., Schiele, B.: Meta-transfer learning for few-shot learning. In: The\n",
    "IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019)\n",
    "124. Sun, R.: Optimization for deep learning: theory and algorithms. arXiv preprint\n",
    "arXiv:1912.08957 (2019)\n",
    "125. Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P.H., Hospedales, T.M.: Learning to compare:\n",
    "Relation network for few-shot learning. In: Proceedings of the IEEE Conference on Computer\n",
    "Vision and Pattern Recognition, pp. 1199–1208 (2018)\n",
    "126. Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural networks. In:\n",
    "Advances in Neural Information Processing Systems, pp. 3104–3112. Curran Associates, Inc.\n",
    "(2014)\n",
    "127. Sutton, R.S., Barto, A.G.: Reinforcement learning: An introduction. MIT press (2018)\n",
    "128. Tan, C., Sun, F., Kong, T., Zhang, W., Yang, C., Liu, C.: A survey on deep transfer learning.\n",
    "In: V. Kůrková, Y. Manolopoulos, B. Hammer, L. Iliadis, I. Maglogiannis (eds.) Artificial\n",
    "Neural Networks and Machine Learning – ICANN 2018, pp. 270–279. Springer International\n",
    "Publishing, Cham (2018)\n",
    "129. Tetko, I.V., Livingstone, D.J., Luik, A.I.: Neural network studies. 1. comparison of overfitting\n",
    "and overtraining. Journal of chemical information and computer sciences 35(5), 826–833\n",
    "(1995)\n",
    "130. Tzeng, E., Hoffman, J., Saenko, K., Darrell, T.: Adversarial discriminative domain adaptation.\n",
    "IEEE Conference on Computer Vision and Pattern Recognition (CVPR) pp. 2962–2971\n",
    "(2017)\n",
    "131. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L.u.,\n",
    "Polosukhin, I.: Attention is all you need. In: I. Guyon, U.V. Luxburg, S. Bengio, H. Wallach,\n",
    "R. Fergus, S. Vishwanathan, R. Garnett (eds.) Advances in Neural Information Processing\n",
    "Systems 30, pp. 5998–6008. Curran Associates, Inc. (2017). URL http://papers.nips.\n",
    "cc/paper/7181-attention-is-all-you-need.pdf\n",
    "132. Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.A.: Extracting and composing robust\n",
    "features with denoising autoencoders. In: Proceedings of the 25th international conference\n",
    "on Machine learning, pp. 1096–1103 (2008)\n",
    "133. Vinyals, O., Toshev, A., Bengio, S., Erhan, D.: Show and tell: A neural image caption\n",
    "generator. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n",
    "(2015)\n",
    "134. Wang, H., Wang, Y., Zhou, Z., Ji, X., Li, Z., Gong, D., Zhou, J., Liu, W.: Cosface: Large\n",
    "margin cosine loss for deep face recognition. In: IEEE/CVF Conference on Computer Vision\n",
    "and Pattern Recognition (2018)\n",
    "135. Wang, X., Shrivastava, A., Gupta, A.: A-fast-rcnn: Hard positive generation via adversary for\n",
    "object detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern\n",
    "Recognition, pp. 2606–2615 (2017)\n",
    "136. Wang, Y., Sun, Y., Liu, Z., Sarma, S.E., Bronstein, M.M., Solomon, J.M.: Dynamic graph\n",
    "cnn for learning on point clouds. ACM Transactions on Graphics (TOG) (2019)\n",
    "137. Wang, Y., Yao, Q.: Generalizing from a few examples: A survey on few-shot learning. ArXiv\n",
    "(2019)\n",
    "138. Wilson, G., Cook, D.J.: A survey of unsupervised deep domain adaptation. In: arxiv (2018)\n",
    "139. Wu, Y., He, K.: Group normalization. In: The European Conference on Computer Vision\n",
    "(ECCV) (2018)\n",
    "140. Wu, Z., Song, S., Khosla, A., Yu, F., Zhang, L., Tang, X., Xiao, J.: 3d shapenets: A deep\n",
    "representation for volumetric shapes. 2015 IEEE Conference on Computer Vision and Pattern\n",
    "Recognition (CVPR) pp. 1912–1920 (2014)\n",
    "141. Xu, B., Wang, N., Chen, T., Li, M.: Empirical evaluation of rectified activations in convolutional network. ArXiv (2015)\n",
    "142. Yang, C., Lu, X., Lu, Z., Shechtman, E., Wang, O., Li, H.: High-resolution image inpainting\n",
    "using multi-scale neural patch synthesis. In: Proceedings of the IEEE Conference on Computer\n",
    "Vision and Pattern Recognition, pp. 6721–6729 (2017)\n",
    "143. Yang, W., Zhang, X., Tian, Y., Wang, W., Xue, J., Liao, Q.: Deep learning for single image\n",
    "super-resolution: A brief review. IEEE Transactions on Multimedia 21(12), 3106–3121\n",
    "(2019). DOI 10.1109/TMM.2019.2919431\n",
    "144. Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., Le, Q.V.: Xlnet: Generalized\n",
    "autoregressive pretraining for language understanding (2019)\n",
    "145. Yu, J., Lin, Z., Yang, J., Shen, X., Lu, X., Huang, T.S.: Free-form image inpainting with gated\n",
    "convolution. In: The IEEE International Conference on Computer Vision (ICCV) (2019)\n",
    "146. Zeiler, M.D.: Adadelta: An adaptive learning rate method. ArXiv abs/1212.5701 (2012)\n",
    "147. Zhang, H., Cisse, M., Dauphin, Y.N., Lopez-Paz, D.: mixup: Beyond empirical risk\n",
    "minimization. In: International Conference on Learning Representations (2018). URL\n",
    "https://openreview.net/forum?id=r1Ddp1-Rb\n",
    "148. Zhang, K., Zuo, W., Chen, Y., Meng, D., Zhang, L.: Beyond a gaussian denoiser: Residual\n",
    "learning of deep cnn for image denoising. IEEE Transactions on Image Processing 26(7),\n",
    "3142–3155 (2017)\n",
    "149. Zhao, H., Gallo, O., Frosio, I., Kautz, J.: Loss functions for image restoration with neural\n",
    "networks. IEEE Transactions on Computational Imaging 3, 47–57 (2017)\n",
    "150. Zhi Tian Chunhua Shen, H.C., He, T.: Fcos: Fully convolutional one-stage object detection.\n",
    "In: Proceedings of the IEEE International Conference on Computer Vision (ICCV), ICCV\n",
    "’19. IEEE Computer Society (2019)\n",
    "151. Zhu, J.Y., Park, T., Isola, P., Efros, A.A.: Unpaired image-to-image translation using cycleconsistent adversarial networks. 2017 IEEE International Conference on Computer Vision\n",
    "(ICCV) pp. 2242–2251 (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional contributions, expansion and further development of this paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_As an additional contribution and further development of this paper I would like to add some Deep Learning basic examples._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Below is an example inspired from the `Module: Artificial Intelligence 2021, SoftUni` [[Reference]](#SoftUni-Module:-Artificial-Intelligence---February-2021). It is a simple Convolutional Neural Network (CNN) which is trained on the mnist dataset [[Reference]](#THE-MNIST-DATABASE-of-handwritten-digits) [[Reference]](#mnist). Then the network is asked to try and predict an image and classify it as one of the numbers from 0 to 9 on which it was trained._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A check to list what physical devices you are using, whether its CPU or GPU:\n",
    "\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing the session, comment it out if you want to:\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Loading the mnist dataset:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the mnist dataset:\n",
    "\n",
    "(attributes_train, labels_train), (attributes_test, labels_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the test attributes, 10000 images, 28x28 pixels each:\n",
    "\n",
    "attributes_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]]\n"
     ]
    }
   ],
   "source": [
    "attributes_train_expanded = np.expand_dims(attributes_train, 3)\n",
    "print(attributes_train_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "\n",
      "---------\n",
      "\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the RGB codes by dividing it to the max RGB value: 255\n",
    "\n",
    "attributes_test_expanded = np.expand_dims(attributes_test, 3)\n",
    "attributes_test_expanded = attributes_test_expanded / 255.0\n",
    "print(attributes_test_expanded[0 : 3])\n",
    "\n",
    "print(\"\\n---------\\n\")\n",
    "\n",
    "attributes_train_expanded = attributes_train_expanded / 255.0\n",
    "print(attributes_train_expanded[0 : 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Here we are building the Convolutional Neural Network (CNN) model architecture._\n",
    "\n",
    "_It's a small model but we only need it for an example._\n",
    "\n",
    "_Using this model, we are demonstrating concepts from this paper, such as `dropout`, `dense layer`, `ReLu`, `Softmax`, etc._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Convolutional Neural Network (CNN) model architecture:\n",
    "\n",
    "cnn = Sequential([\n",
    "    Input(shape = (28, 28, 1)),\n",
    "    Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\"),\n",
    "    Conv2D(32, (3, 3), padding = \"same\", activation = \"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(32, (3, 3), padding = \"same\", activation = \"relu\"),\n",
    "    Conv2D(16, (3, 3), padding = \"same\", activation = \"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(64, activation = \"relu\"),\n",
    "    Dropout(0.05),\n",
    "    Dense(10, activation = \"softmax\")    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 83,866\n",
      "Trainable params: 83,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The Convolutional Neural Network (CNN) model summary:\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Below we are compiling the model, and we are using it to demonstrate other concepts from this paper, such as `Adam optimizer`, `cross-entropy (crossentropy)` for the `loss function`, `metrics`, such as `accuracy`, etc._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model with some parameters, such as ADAM optimizer etc:\n",
    "\n",
    "cnn.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Here we are training the model on the training part of the dataset._\n",
    "\n",
    "_Due to the reasons explained in the [[Foreword]](#Foreword) section we are training a small model and we are training it very little - only one epoch, and we are limiting the steps per epoch._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 151s 300ms/step - loss: 0.5606 - accuracy: 0.8091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x104711d30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model, this is an example of training it only a little, as we are just using it for example:\n",
    "\n",
    "cnn.fit(attributes_train_expanded, labels_train, steps_per_epoch = 500, epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_As we can see while the model is training the `loss function` is decreasing while the `accuracy` is increasing, which is the correct thing to happen._\n",
    "\n",
    "_We are receiving values similar to:_\n",
    "\n",
    "```\n",
    "loss: 0.3468\n",
    "accuracy: 0.8854\n",
    "```\n",
    "\n",
    "...\n",
    "\n",
    "```\n",
    "loss: 0.5606\n",
    "accuracy: 0.8091\n",
    "```\n",
    "\n",
    "_As mentioned, a few sentences back, we are training a small model and we are training it very little, but if we had more processing power and time we could have trained it to achieve better results and higher `accuracy`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 28, 28, 1]), TensorShape([None, 28, 28, 64]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shapes of the input and the output layers:\n",
    "\n",
    "cnn.layers[0].input.shape, cnn.layers[0].output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 64) dtype=float32, numpy=\n",
       "array([[[[ 9.11146775e-02,  6.58011064e-02,  9.38120764e-03,\n",
       "           1.06287107e-01, -5.36887124e-02, -2.05025766e-02,\n",
       "           1.06712822e-02, -9.10094231e-02, -4.83714826e-02,\n",
       "           2.04702597e-02,  3.21879797e-03, -5.93592599e-02,\n",
       "           1.65572137e-01,  1.44944966e-01, -5.53226173e-02,\n",
       "           6.54253885e-02,  7.02179736e-03, -5.77826425e-02,\n",
       "          -7.26372749e-02,  5.28353779e-03,  2.40466427e-02,\n",
       "           1.45409271e-01,  2.29364056e-02,  4.09230441e-02,\n",
       "           2.93590594e-02,  6.99883178e-02, -2.11466663e-02,\n",
       "           1.03005216e-01, -5.50956689e-02, -5.28403409e-02,\n",
       "           1.06129587e-01,  1.03776664e-01,  7.85399824e-02,\n",
       "          -6.48844019e-02, -7.22897574e-02, -1.09015964e-03,\n",
       "          -6.15423992e-02,  1.49982395e-02,  2.36085448e-02,\n",
       "           1.00403540e-01,  1.25266790e-01,  5.78709580e-02,\n",
       "           1.46019921e-01, -7.92784318e-02,  1.33188903e-01,\n",
       "          -1.80854183e-02, -1.34593276e-02,  5.43874577e-02,\n",
       "           2.66626496e-02, -2.99256127e-02,  1.43034698e-03,\n",
       "          -5.20615978e-03, -7.44219869e-02, -9.88757610e-02,\n",
       "           1.41540915e-01, -5.61656207e-02, -5.67651913e-03,\n",
       "           1.14941277e-01,  1.17212586e-01, -1.72476508e-02,\n",
       "           1.24610357e-01, -4.02698182e-02,  1.71432327e-02,\n",
       "          -3.12705450e-02]],\n",
       "\n",
       "        [[ 1.41965961e-02, -1.72632784e-02,  7.69343823e-02,\n",
       "          -6.18838519e-02,  7.51005560e-02, -1.35101154e-01,\n",
       "           2.89513320e-02, -8.41527358e-02,  1.58357639e-02,\n",
       "          -1.13896921e-01, -1.11152977e-02, -5.29567450e-02,\n",
       "           5.27854860e-02,  4.74008918e-02, -1.00383289e-01,\n",
       "           2.88111391e-03, -1.28159106e-01,  1.19215511e-01,\n",
       "           6.78980798e-02,  1.04481578e-01, -1.80472545e-02,\n",
       "           7.64761493e-02,  8.75591561e-02,  5.55407815e-02,\n",
       "           9.35534239e-02,  3.02989185e-02, -2.76046414e-02,\n",
       "           9.77922454e-02, -1.95262134e-02,  8.85931030e-02,\n",
       "           6.36575967e-02,  8.71403366e-02, -8.96229893e-02,\n",
       "          -4.09011059e-02,  3.90529260e-02, -7.71452338e-02,\n",
       "           2.43067462e-02,  1.87028274e-02, -2.22109407e-02,\n",
       "          -3.19868401e-02,  1.25740588e-01,  3.32592167e-02,\n",
       "          -1.22616356e-02,  8.07557777e-02,  2.43527759e-02,\n",
       "           3.05542946e-02, -9.89024863e-02,  1.57505739e-02,\n",
       "           6.29305989e-02,  7.90457353e-02,  8.15357491e-02,\n",
       "          -6.04206920e-02,  5.11107817e-02, -4.38426845e-02,\n",
       "           7.78794885e-02,  1.07405916e-01, -6.04607128e-02,\n",
       "           7.59070856e-04,  4.36788388e-02, -5.74261956e-02,\n",
       "           9.11851302e-02, -8.46913010e-02, -5.44587597e-02,\n",
       "           3.05977128e-02]],\n",
       "\n",
       "        [[-1.36911094e-01, -1.24746658e-01,  1.26682252e-01,\n",
       "          -1.34259656e-01,  1.21528357e-01, -1.34277627e-01,\n",
       "           3.63077000e-02,  3.62357832e-02,  1.16280377e-01,\n",
       "          -2.16389145e-03, -6.88333064e-02,  5.34022301e-02,\n",
       "           4.55134250e-02, -3.80977523e-03,  1.48755565e-01,\n",
       "           1.30625233e-01, -5.94109371e-02,  7.41226375e-02,\n",
       "           8.12278464e-02,  7.54810646e-02, -1.67312578e-03,\n",
       "           4.11941074e-02, -9.68316793e-02,  1.22479061e-02,\n",
       "          -5.60274497e-02,  7.58650824e-02, -1.36244223e-01,\n",
       "           1.52060822e-01,  4.91369888e-02, -4.46963534e-02,\n",
       "           8.20407793e-02,  9.96810272e-02,  1.10832066e-03,\n",
       "          -2.58008670e-02,  4.05366644e-02,  1.05663918e-01,\n",
       "          -4.50075157e-02, -4.65616994e-02,  1.13478266e-01,\n",
       "          -1.48960121e-03,  1.48587003e-02,  1.24227054e-01,\n",
       "          -9.80267078e-02, -6.91101551e-02,  1.43803909e-01,\n",
       "           1.10967204e-01, -1.38709217e-01,  9.98900607e-02,\n",
       "           1.70914739e-01,  6.43670261e-02,  2.24890281e-02,\n",
       "          -1.03849344e-01,  1.02126442e-01,  9.98805538e-02,\n",
       "           1.02884904e-01,  3.14704329e-02, -2.72016157e-03,\n",
       "          -2.70146299e-02,  1.04605325e-01, -1.91942602e-02,\n",
       "           5.21968864e-03, -8.81330892e-02,  4.26551141e-02,\n",
       "          -9.04875696e-02]]],\n",
       "\n",
       "\n",
       "       [[[-3.89169306e-02, -1.35643855e-01,  1.47612199e-01,\n",
       "          -5.61879799e-02,  4.55686077e-02,  8.19016993e-02,\n",
       "           8.80289748e-02, -1.06885009e-01,  1.11047528e-03,\n",
       "          -3.90785597e-02,  8.67276341e-02,  1.30587146e-01,\n",
       "          -5.08113056e-02,  9.43807438e-02, -1.33392096e-01,\n",
       "          -3.09114531e-02,  4.44885576e-03,  1.01709038e-01,\n",
       "          -4.11048345e-02,  8.30224976e-02, -2.59463210e-02,\n",
       "          -5.92193268e-02,  7.53510147e-02,  4.20404114e-02,\n",
       "           7.36828819e-02,  1.00105137e-01, -1.26664918e-02,\n",
       "           2.02854294e-02,  1.13183975e-01,  1.43039301e-01,\n",
       "          -2.38177981e-02, -3.01080495e-02,  3.95769253e-02,\n",
       "           1.07613444e-01,  4.59664352e-02, -7.68264458e-02,\n",
       "          -6.96488619e-02,  1.19186435e-02,  6.73772097e-02,\n",
       "          -6.48017377e-02,  1.39885275e-02,  5.16789779e-02,\n",
       "           1.12087019e-01, -3.20069008e-02, -2.53408514e-02,\n",
       "           3.52039672e-02, -4.03964077e-05,  1.30755424e-01,\n",
       "          -6.22358508e-02, -2.85982806e-02,  7.64275566e-02,\n",
       "          -6.56516524e-03,  1.79270040e-02, -8.76587182e-02,\n",
       "          -2.98458207e-02,  8.68780911e-02, -8.07397217e-02,\n",
       "           6.37022331e-02, -4.46202494e-02, -1.16355389e-01,\n",
       "           5.91578633e-02, -3.00049484e-02, -8.85553882e-02,\n",
       "          -1.09216161e-01]],\n",
       "\n",
       "        [[ 1.46015752e-02, -1.04812626e-02,  9.82646272e-02,\n",
       "          -1.36881113e-01,  1.24406509e-01,  8.28338880e-03,\n",
       "           1.35385677e-01,  7.18438104e-02,  1.21247873e-01,\n",
       "           8.52319002e-02,  7.57909492e-02,  4.92251925e-02,\n",
       "          -7.86538050e-02, -5.02769463e-02, -8.21158886e-02,\n",
       "          -5.10385213e-03,  5.09198830e-02,  1.18241245e-02,\n",
       "           1.36763290e-01, -4.57970649e-02, -6.39923438e-02,\n",
       "          -3.21760736e-02,  1.22033052e-01,  1.15096509e-01,\n",
       "          -5.95849007e-02,  8.16202238e-02,  8.95015970e-02,\n",
       "          -5.94939142e-02,  1.23872794e-01,  1.27263814e-01,\n",
       "           3.09762917e-02, -3.73464823e-02, -4.94557396e-02,\n",
       "           1.10148408e-01,  4.45455760e-02,  6.16425648e-02,\n",
       "           6.44152611e-02,  2.67459266e-02,  1.16005920e-01,\n",
       "           1.00860849e-01,  1.15909986e-01,  6.12997375e-02,\n",
       "           1.09559834e-01,  6.96008578e-02, -5.92759401e-02,\n",
       "           1.76784471e-02, -7.45370868e-04,  1.33175820e-01,\n",
       "           1.03561580e-01,  3.46627571e-02,  1.24962233e-01,\n",
       "          -3.11377682e-02, -5.69946505e-02,  4.69286442e-02,\n",
       "          -5.13348989e-02,  3.67648825e-02, -5.97067773e-02,\n",
       "           1.42820012e-02,  2.83604078e-02,  1.01331249e-02,\n",
       "           9.03340727e-02, -7.96349049e-02, -1.24988426e-02,\n",
       "           6.08279221e-02]],\n",
       "\n",
       "        [[-1.44094095e-01,  5.23752533e-02,  1.05529159e-01,\n",
       "           1.93044730e-02, -4.16078120e-02,  7.91302919e-02,\n",
       "           5.33289500e-02,  1.97072327e-02,  6.37725145e-02,\n",
       "           9.58185643e-02, -1.15202636e-01,  1.28470268e-02,\n",
       "           5.94904944e-02, -8.57359096e-02,  1.60962254e-01,\n",
       "          -1.01190537e-01,  1.63058072e-01,  1.27403423e-01,\n",
       "          -1.51102357e-02, -1.11242145e-01, -8.67897049e-02,\n",
       "          -5.66803738e-02,  5.51004969e-02,  1.31115958e-01,\n",
       "          -1.12468436e-01, -1.63767338e-02, -3.52329649e-02,\n",
       "           7.56026357e-02,  1.35392547e-01, -3.24336737e-02,\n",
       "           1.14308698e-02, -4.27824557e-02,  6.64862469e-02,\n",
       "          -1.55132636e-03,  5.89475371e-02,  1.41700000e-01,\n",
       "           5.67428358e-02,  1.32454932e-01,  6.00285316e-03,\n",
       "           1.35121718e-01, -5.57356328e-03, -7.50084147e-02,\n",
       "           1.54422205e-02,  1.30505145e-01,  5.56245111e-02,\n",
       "          -4.17933948e-02, -2.42031906e-02,  1.01214290e-01,\n",
       "          -1.78397037e-02,  5.47866598e-02,  1.05035774e-01,\n",
       "          -7.83422738e-02, -6.15676045e-02,  6.48520589e-02,\n",
       "           6.72644079e-02,  1.21862613e-01, -7.29176998e-02,\n",
       "          -1.23630442e-01,  7.45607689e-02,  1.02230042e-01,\n",
       "           1.32320389e-01, -6.37651905e-02, -1.08583346e-02,\n",
       "           9.57804695e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.53285235e-01, -2.72421874e-02, -2.40159295e-02,\n",
       "          -4.49359454e-02, -1.10311061e-01,  9.92145017e-02,\n",
       "          -8.72104019e-02,  4.64079976e-02,  1.22978188e-01,\n",
       "           3.96896116e-02,  9.13647339e-02,  1.13228597e-01,\n",
       "          -2.72511542e-02,  2.38933577e-03, -9.40524489e-02,\n",
       "          -9.65014622e-02,  2.25190781e-02,  1.16533767e-02,\n",
       "           1.14928789e-01, -5.36835305e-02,  7.01508746e-02,\n",
       "          -1.17602423e-01,  4.43184450e-02, -5.11914212e-03,\n",
       "           6.34981319e-02,  5.05387187e-02,  5.91015443e-02,\n",
       "           4.82274517e-02, -3.07391137e-02,  1.09321274e-01,\n",
       "          -1.04447819e-01, -1.59760237e-01,  1.29325718e-01,\n",
       "           4.02358733e-03,  8.03742185e-02, -1.35068791e-02,\n",
       "           1.19004540e-01,  7.73945972e-02, -1.47651106e-01,\n",
       "           1.20585784e-01,  1.11124061e-01, -1.44340783e-01,\n",
       "           1.00329354e-01,  1.40606582e-01,  5.67927323e-02,\n",
       "           6.72757775e-02,  4.52401899e-02,  1.24119617e-01,\n",
       "          -1.77404329e-01,  5.15023693e-02,  3.40299271e-02,\n",
       "           6.95756897e-02,  8.55449587e-02, -4.27555703e-02,\n",
       "          -1.29888356e-01,  8.96818191e-02,  9.78931785e-02,\n",
       "           1.14487343e-01, -1.06538936e-01, -1.48047814e-02,\n",
       "           4.38092873e-02, -2.25309506e-02,  8.69771987e-02,\n",
       "          -6.20420501e-02]],\n",
       "\n",
       "        [[ 1.24311551e-01, -3.77809675e-03, -4.83419886e-03,\n",
       "          -7.61841610e-02, -5.45424782e-02,  7.79853016e-02,\n",
       "          -7.35068619e-02,  1.50502965e-01,  7.42811430e-03,\n",
       "           1.13388803e-02, -4.59729545e-02,  8.91116187e-02,\n",
       "          -3.41750011e-02,  3.30888666e-02, -9.98155251e-02,\n",
       "          -5.41784540e-02, -3.05494610e-02, -2.29367148e-02,\n",
       "           1.61454622e-02, -9.51689407e-02,  1.95874736e-01,\n",
       "          -7.87763223e-02,  8.99844803e-03,  5.19534908e-02,\n",
       "           4.37800586e-02,  8.81565455e-03,  1.69067636e-01,\n",
       "          -1.99469421e-02,  6.54922202e-02,  2.93813739e-02,\n",
       "          -1.03319965e-01, -1.93170439e-02,  4.60530594e-02,\n",
       "          -1.16481431e-01,  1.18013859e-01, -1.50102913e-01,\n",
       "           1.48880139e-01, -1.32389115e-02, -9.81282219e-02,\n",
       "          -1.57787241e-02,  7.34089166e-02, -9.92098749e-02,\n",
       "          -1.93251688e-02,  2.14373283e-02, -9.08560455e-02,\n",
       "           8.69319066e-02,  1.74007028e-01,  5.35792038e-02,\n",
       "          -1.04793422e-01, -4.11840044e-02,  6.58182651e-02,\n",
       "           1.39954612e-01,  4.29559648e-02,  7.79466704e-02,\n",
       "          -1.03203297e-01, -1.49495127e-02,  1.18716501e-01,\n",
       "          -2.14261487e-02, -9.52004194e-02,  1.63804159e-01,\n",
       "          -8.36026371e-02, -6.77115172e-02,  1.58010826e-01,\n",
       "           1.16840325e-01]],\n",
       "\n",
       "        [[-3.14482749e-02,  7.44616017e-02, -7.74732605e-02,\n",
       "          -1.28214836e-01,  9.23547372e-02,  3.46081592e-02,\n",
       "           1.09399587e-01,  1.04182340e-01, -5.52606434e-02,\n",
       "           5.98051064e-02, -3.15739820e-03, -3.83832417e-02,\n",
       "          -1.31239578e-01, -1.05963558e-01, -5.14076324e-04,\n",
       "          -4.25153524e-02,  1.58879772e-01,  6.20388091e-02,\n",
       "           8.21142271e-02, -1.77056866e-03, -2.69709397e-02,\n",
       "          -1.12900287e-02, -3.05683035e-02, -2.66832095e-02,\n",
       "          -2.72582397e-02, -1.10907368e-02,  1.59857407e-01,\n",
       "          -2.39228159e-02, -7.40068704e-02,  1.19752735e-01,\n",
       "          -1.08021893e-01, -1.40113845e-01,  1.06570803e-01,\n",
       "          -1.14937425e-01, -4.58655097e-02, -5.73066920e-02,\n",
       "           1.51719213e-01,  1.31278425e-01,  3.88679318e-02,\n",
       "           3.10291369e-02,  9.66243669e-02,  6.90574422e-02,\n",
       "          -6.23153225e-02,  1.38618484e-01, -9.72762480e-02,\n",
       "           1.13949478e-01,  9.06291753e-02, -6.63793925e-03,\n",
       "           6.24848194e-02, -2.82461308e-02,  9.88117903e-02,\n",
       "           1.02089949e-01,  3.62423025e-02,  5.91154173e-02,\n",
       "           4.79351468e-02,  1.30629325e-02,  7.31344149e-02,\n",
       "          -7.21488595e-02, -9.04956013e-02,  1.44088760e-01,\n",
       "           8.11779499e-02, -9.00822431e-02,  6.19680583e-02,\n",
       "           1.53063998e-01]]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing some wieghts for visibility:\n",
    "\n",
    "cnn.layers[0].weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Printing out a few of the filters used for the convolutions, just to get an idea:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Printing out a few of the filters, just to get an idea:\n",
    "\n",
    "for i in range(10):\n",
    "    filter_contents = tf.squeeze(cnn.layers[0].kernel[:, :, :, 0]).numpy()\n",
    "    plt.imshow(filter_contents, cmap = \"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Printing out a few of the images, just to get an idea of the dataset:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOaElEQVR4nO3df6zddX3H8eerTMOCDgodUBCpcyzuR1g1Ddlit7FZCRATyhKJuJgSzUo2NbqMpYyRiFm24ZhuxKlbCT+NoiTIIM5MXcMPlw5DMQyrLcqaIoWuHUECZEsY3Pf+uKd6ud7zveX8vL2f5yO5Oed+P9/z/b570tf9fL7ne77fT6oKScvfimkXIGkyDLvUCMMuNcKwS40w7FIjDLvUCMO+TCTZm2TDYa5bSX5+wP0M/FpNl2HX2CS5KMn2JP+T5J5p19O6n5p2AVrWngb+DngT8DvTLUX27MtQkrOS/HuSZ5LsT/L3SV49b7Xzk+xJ8lSSa5KsmPP69ybZleSHSb6a5PRB6qiqf62q24Anh/n3aDQM+/L0EvBHwCrg14G3AX84b50LgXXAW4ALgPcCJNkIXAH8LvCzwDeAWxfaSZJ3J3l49OVrHAz7MlRVD1bV/VX1YlXtBf4R+K15q32sqp6uqh8wO9S+uLf8UuCvqmpXVb0I/CWwdqHevao+X1Vnju0fopEy7MtQkl9I8uUk/5XkWWYDu2reao/Pef4YcErv+enAtb1DgGeYPe4OcOqYy9aYGfbl6TPAbuCMqvoZZoflmbfOaXOev54fH1c/DlxaVcfN+fnpqto+9qo1VoZ9eXot8CzwfJI3AX+wwDp/kmRlktOADwFf7C3/B+BPk/wyQJJjk7xzkCKSHJXkaGbP+qxIcnSSVw2yLQ3PsC9PlwHvBp4DruPHQZ7rTuBB4CHgn4HrAarqDuBjwBd6hwA7gfMW2kmS30vynY463gP8L7Mjjd/oPb/ulf9zNArx5hVSG+zZpUYYdqkRhl1qhGGXGjHRC2GS+GmgNGZVNf87FcCQPXuSc5M8kuTRJJcPsy1J4zXwqbckRwHfA94O7AMeAC6uqu92vMaeXRqzcfTsZwGPVtWeqnoB+AKzV09JWoKGCfupvPxiin0scLFEks1JdiTZMcS+JA1pmA/oFhoq/MQwvaq2AlvBYbw0TcP07Pt4+ZVTr8M7kkhL1jBhfwA4I8kberc8ehdw12jKkjRqAw/jq+rFJB8AvgocBdxQVV1XQEmaoole9eYxuzR+Y/lSjaQjh2GXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qxMBTNkvjduWVV3a2f/SjH+1sX7Gif1929tlnd7723nvv7Ww/Eg0V9iR7geeAl4AXq2rdKIqSNHqj6Nl/u6qeGsF2JI2Rx+xSI4YNewFfS/Jgks0LrZBkc5IdSXYMuS9JQxh2GP/WqnoyyYnA15Psrqr75q5QVVuBrQBJasj9SRrQUD17VT3ZezwI3AGcNYqiJI3ewGFPckyS1x56DpwD7BxVYZJGa5hh/EnAHUkObefzVfUvI6lKTbjkkks627ds2dLZPjMzM/C+q9o7ohw47FW1B/jVEdYiaYw89SY1wrBLjTDsUiMMu9QIwy41wktcNTWnn356Z/vRRx89oUraYM8uNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjPM+usdqwYUPftg9+8INDbXv37t2d7e94xzv6th04cGCofR+J7NmlRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqE59k1lPXr13e233jjjX3bjj322KH2fc0113S2P/bYY0Ntf7mxZ5caYdilRhh2qRGGXWqEYZcaYdilRhh2qRGeZ9dQNm3a1Nl+yimnDLzte+65p7P9lltuGXjbLVq0Z09yQ5KDSXbOWXZ8kq8n+X7vceV4y5Q0rMMZxt8EnDtv2eXAtqo6A9jW+13SErZo2KvqPuDpeYsvAG7uPb8Z2DjasiSN2qDH7CdV1X6Aqtqf5MR+KybZDGwecD+SRmTsH9BV1VZgK0CSGvf+JC1s0FNvB5KsBug9HhxdSZLGYdCw3wUcOueyCbhzNOVIGpdUdY+sk9wKnA2sAg4AHwH+CbgNeD3wA+CdVTX/Q7yFtuUw/gizatWqzvbF7r8+MzPTt+2ZZ57pfO1FF13U2X733Xd3treqqrLQ8kWP2avq4j5NbxuqIkkT5ddlpUYYdqkRhl1qhGGXGmHYpUZ4iWvj1qxZ09l+++23j23fn/zkJzvbPbU2WvbsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wvPsjTv33Pn3En25M888c6jtb9u2rW/btddeO9S29crYs0uNMOxSIwy71AjDLjXCsEuNMOxSIwy71IhFbyU90p15K+mJ27hxY2f7TTfd1Nl+zDHHdLZv3769s73rdtCL3YZag+l3K2l7dqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGuH17MtA173fx3nfd4A9e/Z0tnsufelYtGdPckOSg0l2zll2VZInkjzU+zl/vGVKGtbhDONvAha6ncnfVtXa3s9XRluWpFFbNOxVdR/w9ARqkTRGw3xA94EkD/eG+Sv7rZRkc5IdSXYMsS9JQxo07J8B3gisBfYDH++3YlVtrap1VbVuwH1JGoGBwl5VB6rqpaqaAa4DzhptWZJGbaCwJ1k959cLgZ391pW0NCx6nj3JrcDZwKok+4CPAGcnWQsUsBe4dHwlajFbtmzp2zYzMzPWfV999dVj3b5GZ9GwV9XFCyy+fgy1SBojvy4rNcKwS40w7FIjDLvUCMMuNcJLXI8Aa9eu7Ww/55xzxrbvO++8s7P9kUceGdu+NVr27FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcIpm48ABw8e7GxfubLvXcEWdf/993e2n3feeZ3tzz///MD71ng4ZbPUOMMuNcKwS40w7FIjDLvUCMMuNcKwS43wevYjwAknnNDZPsztoj/96U93tnseffmwZ5caYdilRhh2qRGGXWqEYZcaYdilRhh2qRGHM2XzacAtwMnADLC1qq5NcjzwRWANs9M2X1RVPxxfqcvXjTfe2Nm+YsX4/iZv3759bNvW0nI4/4teBP64qn4R+DXg/Ul+Cbgc2FZVZwDber9LWqIWDXtV7a+qb/WePwfsAk4FLgBu7q12M7BxTDVKGoFXND5MsgZ4M/BN4KSq2g+zfxCAE0denaSROezvxid5DXA78OGqejZZ8DZXC71uM7B5sPIkjcph9exJXsVs0D9XVV/qLT6QZHWvfTWw4F0Rq2prVa2rqnWjKFjSYBYNe2a78OuBXVX1iTlNdwGbes83Ad3TfUqaqsMZxr8VeA/w7SQP9ZZdAVwN3JbkfcAPgHeOpcJlYLEplzds2NDZvtglrC+88ELftk996lOdrz1w4EBnu5aPRcNeVf8G9DtAf9toy5E0Ln6DTmqEYZcaYdilRhh2qRGGXWqEYZca4a2kJ+C4447rbD/55JOH2v4TTzzRt+2yyy4battaPuzZpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhNezT8Du3bs72xebNnn9+vWjLEeNsmeXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRqaruFZLTgFuAk4EZYGtVXZvkKuD3gf/urXpFVX1lkW1170zS0KpqwSnWDyfsq4HVVfWtJK8FHgQ2AhcBz1fV3xxuEYZdGr9+YV/0G3RVtR/Y33v+XJJdwKmjLU/SuL2iY/Yka4A3A9/sLfpAkoeT3JBkZZ/XbE6yI8mO4UqVNIxFh/E/WjF5DXAv8BdV9aUkJwFPAQX8ObND/fcusg2H8dKYDXzMDpDkVcCXga9W1ScWaF8DfLmqfmWR7Rh2acz6hX3RYXySANcDu+YGvffB3SEXAjuHLVLS+BzOp/HrgW8A32b21BvAFcDFwFpmh/F7gUt7H+Z1bcueXRqzoYbxo2LYpfEbeBgvaXkw7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjJj1l81PAY3N+X9VbthQt1dqWal1gbYMaZW2n92uY6PXsP7HzZEdVrZtaAR2Wam1LtS6wtkFNqjaH8VIjDLvUiGmHfeuU999lqda2VOsCaxvURGqb6jG7pMmZds8uaUIMu9SIqYQ9yblJHknyaJLLp1FDP0n2Jvl2koemPT9dbw69g0l2zll2fJKvJ/l+73HBOfamVNtVSZ7ovXcPJTl/SrWdluTuJLuSfCfJh3rLp/reddQ1kfdt4sfsSY4Cvge8HdgHPABcXFXfnWghfSTZC6yrqql/ASPJbwLPA7ccmloryV8DT1fV1b0/lCurassSqe0qXuE03mOqrd8045cwxfdulNOfD2IaPftZwKNVtaeqXgC+AFwwhTqWvKq6D3h63uILgJt7z29m9j/LxPWpbUmoqv1V9a3e8+eAQ9OMT/W966hrIqYR9lOBx+f8vo+lNd97AV9L8mCSzdMuZgEnHZpmq/d44pTrmW/Rabwnad4040vmvRtk+vNhTSPsC01Ns5TO/721qt4CnAe8vzdc1eH5DPBGZucA3A98fJrF9KYZvx34cFU9O81a5lqgrom8b9MI+z7gtDm/vw54cgp1LKiqnuw9HgTuYPawYyk5cGgG3d7jwSnX8yNVdaCqXqqqGeA6pvje9aYZvx34XFV9qbd46u/dQnVN6n2bRtgfAM5I8oYkrwbeBdw1hTp+QpJjeh+ckOQY4ByW3lTUdwGbes83AXdOsZaXWSrTePebZpwpv3dTn/68qib+A5zP7Cfy/wn82TRq6FPXzwH/0fv5zrRrA25ldlj3f8yOiN4HnABsA77fezx+CdX2WWan9n6Y2WCtnlJt65k9NHwYeKj3c/6037uOuibyvvl1WakRfoNOaoRhlxph2KVGGHapEYZdaoRhlxph2KVG/D+9eG6VqjbGFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Printing out a few of the images, just to get an idea of the dataset:\n",
    "\n",
    "for i in range(10):\n",
    "    plt.imshow(attributes_train[i], cmap = \"gray\")\n",
    "    plt.title(f\"label: {labels_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Here we are loading an example image to pass to the model and ask to classify it as one of the numbers it was trained on:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We select the image of a handwritten `3` from our testing set and we can see that indeed our CNN predicts correctly that it is the number `3`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image to predict: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Predicted:  3\n"
     ]
    }
   ],
   "source": [
    "# Loading an example image to pass to the model and ask to classify it as one of the numbers it was trained on:\n",
    "\n",
    "image_index = 369\n",
    "test_image = attributes_test[image_index].reshape(28, 28)\n",
    "print(\"Image to predict: \")\n",
    "plt.imshow(test_image, cmap='Greys')\n",
    "plt.show()\n",
    "test_image = tf.keras.preprocessing.image.img_to_array(test_image)\n",
    "test_image = tf.expand_dims(test_image, 0)\n",
    "predictions = cnn.predict(test_image)\n",
    "print(\"CNN Predicted: \", predictions.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Let's print out the predictions for the example number in a more readable way:_\n",
    "\n",
    "_We can see that our model is indeed pretty certain that the predicted number is classified as the number `3`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  0.00 \n",
      "1  0.00 \n",
      "2  0.00 \n",
      "3  100.00 \n",
      "4  0.00 \n",
      "5  0.00 \n",
      "6  0.00 \n",
      "7  0.00 \n",
      "8  0.00 \n",
      "9  0.00 \n"
     ]
    }
   ],
   "source": [
    "# Printing out the predictions for the example number:\n",
    "\n",
    "predictions = predictions.flatten()\n",
    "for i in range(0, 10):\n",
    "    print(i , \" %.2f \" % (100 * predictions[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Finally we can evaluate our trained model with the test part of the data set:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0520 - accuracy: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05202137306332588, 0.983299970626831]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(attributes_test_expanded, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We achieved about ~$98.0\\%$ accuracy with such a basic model. To be honest, in many image classification cases (e.g. for autonomous cars), we cannot tolerate even a 0.1% error since, as an analogy, it will cause 1 accident in every 1000 cases. However, for the example purposes of this paper, the results of this model are still pretty good, considering everything so far._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_In this article we have achieved our goal, which was to understand some Deep Learning (DL) basics and basic concepts, more specifically to understand Neural Networks (NNs) and how to improve them, so we can create models, train them, test them and extract predictions and information we might be interested in._\n",
    "\n",
    "_I have expanded the original paper, on which this article is based on, by adding a real practical example of building a Convolutional Neural Network architecture, training the model, evaluating it, and then testing it with an example._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future improvements\n",
    "\n",
    "_This article and this paper can be further improved by expanding them with more examples of the Deep Learning concepts mentioned in the paper, and training those examples on more powerful machines or on Deep Learning cloud platforms._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "***Module: Artificial Intelligence 2021, SoftUni*** [[Reference]](#SoftUni-Module:-Artificial-Intelligence---February-2021)\n",
    "- *Course: Math Concepts for Developers 2021* [[Reference]](#SoftUni-Course:-Math-Concepts-for-Developers---February-2021)\n",
    "- *Course: Data Science 2021* [[Reference]](#SoftUni-Course:-Data-Science---June-2021)\n",
    "- *Course: Machine Learning 2021* [[Reference]](#SoftUni-Course:-Machine-Learning---September-2021)\n",
    "- *Course: Deep Learning 2021* [[Reference]](#SoftUni-Course:-Deep-Learning---December-2021)\n",
    "\n",
    "***Other references:***\n",
    "- *Image classification from scratch [[Reference]](#Image-classification-from-scratch)*\n",
    "- *Basic classification: Classify images of clothing [[Reference]](#Basic-classification:-Classify-images-of-clothing)*\n",
    "- *Image Classification in 10 Minutes with MNIST Dataset [[Reference]](#Image-Classification-in-10-Minutes-with-MNIST-Dataset)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to deep learning\n",
    "<https://paperswithcode.com/paper/introduction-to-deep-learning>\n",
    "\n",
    "### Introduction to deep learning PDF\n",
    "<https://arxiv.org/pdf/2003.03253v1.pdf>\n",
    "\n",
    "### Introduction to deep learning ARXIV\n",
    "<https://arxiv.org/abs/2003.03253v1>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Artificial Neural Network: Understanding the Basic Concepts without Mathematics\n",
    "<https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6428006/pdf/dnd-17-83.pdf>\n",
    "\n",
    "### Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions\n",
    "<https://link.springer.com/content/pdf/10.1007/s42979-021-00815-1.pdf>\n",
    "\n",
    "### Introduction to Machine Learning, Neural Networks, and Deep Learning\n",
    "<https://tvst.arvojournals.org/article.aspx?articleid=2762344>\n",
    "\n",
    "---\n",
    "\n",
    "### SoftUni Module: Artificial Intelligence - February 2021\n",
    "<https://softuni.bg/modules/111/artificial-intelligence-february-2021/1276>\n",
    "\n",
    "### SoftUni Course: Math Concepts for Developers - February 2021\n",
    "<https://softuni.bg/trainings/3282/math-concepts-for-developers-february-2021>\n",
    "\n",
    "### SoftUni Course: Data Science - June 2021\n",
    "<https://softuni.bg/trainings/3283/data-science-june-2021>\n",
    "\n",
    "### SoftUni Course: Machine Learning - September 2021\n",
    "<https://softuni.bg/trainings/3284/machine-learning-september-2021>\n",
    "\n",
    "### SoftUni Course: Deep Learning - December 2021\n",
    "<https://softuni.bg/trainings/3285/deep-learning-december-2021>\n",
    "\n",
    "---\n",
    "\n",
    "### THE MNIST DATABASE of handwritten digits\n",
    "<http://yann.lecun.com/exdb/mnist/>\n",
    "\n",
    "### mnist\n",
    "<https://www.tensorflow.org/datasets/catalog/mnist>\n",
    "\n",
    "---\n",
    "\n",
    "### Image classification from scratch\n",
    "<https://keras.io/examples/vision/image_classification_from_scratch/>\n",
    "\n",
    "### Basic classification: Classify images of clothing\n",
    "<https://www.tensorflow.org/tutorials/keras/classification>\n",
    "\n",
    "### Image Classification in 10 Minutes with MNIST Dataset\n",
    "<https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "691.2px",
    "left": "148px",
    "top": "304.925px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
